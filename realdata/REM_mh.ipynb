{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T13:14:15.822957Z",
     "start_time": "2021-01-05T13:14:13.377581Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import gym\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "from itertools import permutations\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from multiprocessing import set_start_method\n",
    "import multiprocessing as mp\n",
    "\n",
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "\n",
    "from seal.agents.default_config import DEFAULT_CONFIG as config\n",
    "# from seal.agents.dqn import DQNAgent\n",
    "# from seal.agents.qr_dqn import QuantileAgent\n",
    "from seal.agents.multi_head_dqn import MultiHeadDQNAgent\n",
    "# from seal.agents.discrete_bcq import DiscreteBCQAgent\n",
    "\n",
    "from seal.algos.kfold import CVS, KFoldCV\n",
    "from seal.algos.advantage_learner import AdvantageLearner\n",
    "from seal.algos.behavior_cloning import BehaviorCloning\n",
    "from seal.algos.density_ratio import VisitationRatioModel\n",
    "from seal.algos.fqe import FQE\n",
    "\n",
    "def one_step(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    path = './data/mh/rem/trajs_mh.pkl'\n",
    "    nfolds = 5\n",
    "    n_splits = 5\n",
    "    ckpts = (np.arange(10) + 1)*5000\n",
    "    \n",
    "    num_actions = 5\n",
    "    # configures\n",
    "    config['online'] = False\n",
    "    config['lr'] = 5e-4\n",
    "    config['decay_steps'] = 50000\n",
    "    config['max_training_steps'] = 50000\n",
    "    config['training_steps_to_checkpoint'] = 5000\n",
    "    config['training_steps_to_eval'] = 100000\n",
    "    config['hiddens'] = [64,64]\n",
    "    config['double'] = False\n",
    "    config['dueling'] = False\n",
    "    config['num_heads'] = 200\n",
    "\n",
    "    index = pd.MultiIndex.from_product([np.arange(nfolds), ckpts])\n",
    "    columns = ['dqn',  'seal']\n",
    "    rets = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "    print('-'*20, 'start', '-'*20)\n",
    "    cvs = CVS(path, n_splits=nfolds, random_state=seed)\n",
    "    cvs.split()\n",
    "    for fold in range(nfolds):\n",
    "        train_path = cvs.train_paths[fold] + 'trajs.pkl'\n",
    "        kf = KFoldCV(train_path, n_trajs=None, n_splits=n_splits, shuffle=False, random_state=seed)\n",
    "        kf.split()\n",
    "\n",
    "        print('-'*20, 'training agent', '-'*20)\n",
    "        # agent\n",
    "        config['persistent_directory'] = kf.agent_path\n",
    "        config['checkpoint_path'] = kf.ckpt_path\n",
    "        agent = MultiHeadDQNAgent(num_actions=num_actions, config=config)\n",
    "        agent.learn()\n",
    "\n",
    "        print('-'*20, 'training agents', '-'*20)\n",
    "        # agent_1, ..., agent_K\n",
    "        for idx in range(kf.n_splits):\n",
    "            config_idx = copy.deepcopy(config)\n",
    "            config_idx['persistent_directory'] = kf.agent_paths[idx]\n",
    "            config_idx['checkpoint_path'] = kf.ckpt_paths[idx]\n",
    "            agent_idx = MultiHeadDQNAgent(num_actions=num_actions, config=config_idx)\n",
    "            agent_idx.learn()\n",
    "\n",
    "        # fitted q evaluation\n",
    "        test_path = cvs.test_paths[fold] + 'trajs.pkl'\n",
    "        with open(test_path, 'rb') as f:\n",
    "            trajs = pickle.load(f)\n",
    "\n",
    "        print('-'*20, 'behavior cloning', '-'*20)\n",
    "        # behavior cloning\n",
    "        bc = BehaviorCloning(num_actions=num_actions)\n",
    "        states  = np.array([transition[0] for traj in kf.trajs for transition in traj])\n",
    "        actions = np.array([transition[1] for traj in kf.trajs for transition in traj])\n",
    "        bc.train(states, actions)\n",
    "\n",
    "        for ckpt in ckpts:\n",
    "            print('-'*20, 'ckpt: ', ckpt, '-'*20)\n",
    "            agent = MultiHeadDQNAgent(num_actions=num_actions, config=config)\n",
    "            agent.load(kf.ckpt_path + 'offline_rem_{}.ckpt'.format(ckpt))\n",
    "\n",
    "            agents = []\n",
    "            for idx in range(kf.n_splits):\n",
    "                config_idx = copy.deepcopy(config)\n",
    "                config_idx['persistent_directory'] = kf.agent_paths[idx]\n",
    "                config_idx['checkpoint_path'] = kf.ckpt_paths[idx]\n",
    "                agent_idx = MultiHeadDQNAgent(num_actions=num_actions, config=config_idx)\n",
    "                agent_idx.load(kf.ckpt_paths[idx] + 'offline_rem_{}.ckpt'.format(ckpt))\n",
    "                agents.append(agent_idx)\n",
    "            states, qvalues, qtildes = kf.update_q(agents, bc)\n",
    "\n",
    "            print('-'*20, 'adv learner', '-'*20)\n",
    "#             advs1 = qvalues - qvalues.mean(axis=1, keepdims=True)\n",
    "#             agent1 = AdvantageLearner(num_actions=num_actions)\n",
    "#             agent1._train(states, advs1)\n",
    "            \n",
    "            advs2 = qtildes - qtildes.mean(axis=1, keepdims=True)\n",
    "            agent2 = AdvantageLearner(num_actions=num_actions)\n",
    "            agent2._train(states, advs2)\n",
    "\n",
    "            print('-'*20, 'fqe on dqn & seal', '-'*20)\n",
    "            fqe_dqn = FQE(agent.greedy_actions, num_actions=num_actions, activation='tanh', hiddens=config['hiddens'], max_iter=100, eps=0.0015)\n",
    "            fqe_dqn.train(trajs)\n",
    "#             fqe_dml = FQE(agent1.greedy_actions, num_actions=num_actions)\n",
    "#             fqe_dml.train(trajs)\n",
    "            fqe_seal = FQE(agent2.greedy_actions, num_actions=num_actions, activation='tanh', hiddens=config['hiddens'], max_iter=100, eps=0.0015)\n",
    "            fqe_seal.train(trajs)\n",
    "\n",
    "            rets.loc[(fold, ckpt), 'dqn'] = fqe_dqn.values\n",
    "#             rets.loc[(fold, ckpt), 'dml'] = fqe_dml.values\n",
    "            rets.loc[(fold, ckpt), 'seal'] = fqe_seal.values\n",
    "            \n",
    "    return rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-07T01:46:22.881034Z",
     "start_time": "2021-01-05T13:14:16.694795Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- --------------------start -------------------- start -------------------- --------------------\n",
      "start\n",
      " --------------------\n",
      "----------------------------------------  startstart -------------------- --------------------\n",
      "\n",
      "-------------------- training agent --------------------\n",
      "-------------------- training agent --------------------\n",
      "-------------------- training agent --------------------\n",
      "-------------------- training agent ----------------------------------------\n",
      " training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!Refresh buffer every 1000000 sampling!\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/ckpt/offline_rem_50000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9202571609792677 values:  -61.34012 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0016609803550102654 values:  -61.320644 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0015292132037053843 values:  -61.33202 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002267017803475619 values:  -61.333652 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020777405994332207 values:  -61.299202 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001913044007160621 values:  -61.233246 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026343501325762782 values:  -61.231804 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020800115725638194 values:  -61.25136 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024747221155071437 values:  -61.257946 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015591112311077945 values:  -61.171673 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0029738141484000314 values:  -61.22189 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0022526343083037886 values:  -61.254097 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning -----iteration: --------------------\n",
      " 12 target diff:  0.0017541669220693119 values:  -61.293365 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0015752791401675277 values:  -61.384663 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002610994910610741 values:  -61.371296 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0022017565788602605 values:  -61.293427 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  16 target diff:  0.00224316136058628 values:  -61.361748 ----- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  17 target diff:  0.001683310854369299 values:  -61.370728 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0016355767026037693 values:  -61.33631 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019287278269995865 values:  -61.448383 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0025208574849264116 values:  -61.368504 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002343095530805969 values:  -61.465107 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0030134214315077667 values:  -61.400078 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "-----iteration:  23 target diff:  0.00238518376311341 values:  -61.462612 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0019553070018780965 values:  -61.45622 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001720620390676484 values:  -61.455585 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0020805172972570823 values:  -61.391773 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0021561531061131227 values:  -61.402702 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002204877288112399 values:  -61.468468 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0027060540792322265 values:  -61.443207 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  30 target diff:  0.0020382977543883674 values:  -61.46534 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9220395480180481 values:  -57.750732 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0027891501800663887 values:  -61.442543 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0018425424173104188 values:  -57.77773 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002254838391681455 values:  -57.81228 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0020240319118046803 values:  -61.41198 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016821367793845438 values:  -57.751392 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0022450225291168165 values:  -61.462593 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017443935905397518 values:  -57.78324 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0024505507598988974 values:  -61.444996 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0028347414754623735 values:  -57.797577 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017897459909669352 values:  -57.812614 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020179245468848234 values:  -57.771458 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002348871934960168 values:  -61.362217 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017299418503085786 values:  -57.74017 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017414553876600688 values:  -57.751152 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0030220166579591648 values:  -61.3205 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019416763090101526 values:  -57.70959 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0024904986053302025 values:  -61.26634 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023235634888917702 values:  -57.705967 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0025306181383141996 values:  -57.79826 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0018144851775686293 values:  -61.15559 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.001983533446820381 values:  -61.060337 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0028753462333193326 values:  -57.77994 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001668344307506945 values:  -57.792812 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0021678876711263393 values:  -60.992405 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0025825352765488623 values:  -57.790806 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0025495408531641056 values:  -57.79638 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0023305304260383755 values:  -60.84118 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019742594900722128 values:  -57.80552 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002280193297859327 values:  -60.667652 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002699299318448924 values:  -57.80268 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0024748879346261164 values:  -60.62759 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0024134828981587507 values:  -57.751446 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002310898644359896 values:  -60.583706 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0018190026103586663 values:  -60.532192 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002535017932629309 values:  -57.750122 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0016691549439934192 values:  -60.468506 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018612793158457944 values:  -57.72962 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018475223604392788 values:  -60.36612 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0022827467645002942 values:  -57.681946 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0019793623459176137 values:  -60.289577 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0021169367708956965 values:  -57.679356 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002090875891440686 values:  -60.248142 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0018037717687771119 values:  -60.07694 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0020953749303134228 values:  -57.69207 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002639817085553878 values:  -60.01382 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0018361992411848407 values:  -59.864525 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0020654318783091285 values:  -57.716316 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.001958852051892858-----iteration:  53  target diff:  0.0021553799211050397 values: values:  -59.840935 -----  \n",
      "\n",
      "-57.705444 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0016880606586302906 values:  -59.7672 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018528780425798913 values:  -57.722626 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  55 target diff:  0.0016225317868218713 values:  -59.78351 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018549486600132595 values:  -57.7539 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0021587052404319507 values:  -59.740974 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.001818238687153038 values:  -57.78732 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0019684212555070428 values:  -59.747795 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0019659157162475963 values:  -57.795322 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0013567386783156232 values:  -59.691303 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0016726550992586053 values:  -57.809685 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  32 target diff:  0.0015312785347397614 values:  -57.727 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.003302375719345188 values:  -57.749424 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0019375925749385559 values:  -57.812836 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0027984382756134885 values:  -57.776432 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0024031169519236526 values:  -57.75586 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  37 target diff:  0.0015087388604045262 values:  -57.709923 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0019549751351737848 values:  -57.72284 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0023469744515458297 values:  -57.7245 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9187729085005809 values:  -61.347557 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.001408200548577314 values:  -57.73565 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021701299221282898 values:  -61.364815 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001365475171753681 values:  -61.408566 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  0 target diff:  0.9203932222386775 values:  -57.816494 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026230329439439117 values:  -57.868893 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002560468705284604 values:  -57.884342 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001630632947172444 values:  -57.87026 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002730488281019071 values:  -57.894802 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00203181781443406 values:  -57.9181 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.00182056138463777 values:  -57.949833 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0020824930689781053 values:  -57.993614 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0027138430129218134 values:  -58.030552 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9198891863935947 values:  -60.298424 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018964940838552683 values:  -58.027596 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019129827455278059 values:  -58.042145 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019325031575639544 values:  -58.057434 ----- \n",
      "-----iteration:  1\n",
      " target diff:  0.0020019451796481993 values:  -60.301617 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016131537325718768 values:  -58.074818 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002183654218263478 values:  -60.27907 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0017298108660914443 values:  -58.106853 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0024514485817825164 values:  -58.18532 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020072788377821717 values:  -60.26661 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0025132554291714673 values:  -58.261044 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0016498752835397547 values:  -60.270653 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0023166207721383716 values:  -58.299953 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0015273558678496934 values:  -60.268158 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0035576221699547164 values:  -60.26383 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018806571832868275 values:  -58.27381 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0024025743868808925 values:  -60.301056 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001152648809770348 values:  -60.2935 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0031587078663698072 values:  -58.288765 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002116050433953519 values:  -58.331524 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002281137399806382 values:  -58.36075 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018362897293367683 values:  -58.40661 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019505281654247392 values:  -58.442257 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0022240101082758373 values:  -58.470562 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  24 target diff:  0.0021315139398071937 values:  -58.51294 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.920675943375772 values:  -60.26784 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0018684811372197963 values:  -58.547695 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0024758365614649964 values:  -60.24054 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0020366410274219485 values:  -58.618263 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020595861176983827 values:  -60.24306 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002395871546619951 values:  -58.651302 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018503602986283266 values:  -60.22894 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002462860027969369 values:  -58.691982 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017827024486164861 values:  -60.25025 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  -----iteration: 0.002493416555961578  5 target diff:  values: 0.0020451691065763527 values:  -60.339027 ----- \n",
      "\n",
      " -58.70484 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0023039043244444907 values:  -58.751736 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0034243299929427266 values:  -60.39618 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0020640443485662884 values:  -58.742912 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001962781344056898 values:  -60.41941 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0016044315188822665 values:  -58.76635 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002160828424538906 values:  -60.343018 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0018731555713147005 values:  -58.765797 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017888184108429365 values:  -60.416737 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.001780430850604686 values:  -58.755157 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020291030445824675 values:  -60.54888 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023636367274827825 values:  -60.560925 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018656958348250087 values:  -60.566303 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0021287827588515867 values:  -58.73492 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0022099550043583956 values:  -58.7843 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018864797868462229 values:  -60.520657 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0016306742816189544 values:  -58.820305 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.00226713780641907 values:  -60.512886 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0022636312529696694 values:  -58.822548 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0016091150651464906 values:  -60.55018 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0018288697897834534 values:  -58.85923 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016042828606458795 values:  -60.537655 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.001579506195807104 values:  -58.875668 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0016146416248314476 values:  -58.868263 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002143855059911849 values:  -60.554966 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002138741870585018 values:  -58.90107 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0027149557692072975 values:  -58.933647 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0034558897153290783 values:  -60.530205 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0019636528982148673 values:  -58.94894 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0021693552139272396 values:  -60.48322 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0016435626762472777 values:  -58.93797 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0026045487718078333 values:  -60.47469 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.00233355278563682 values:  -59.00137 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0023365762376953603 values:  -60.523933 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0023225847722268818 values:  -58.988483 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0020175198857540046 values:  -60.5418 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0018376332078294758 values:  -59.058136 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019150419141351733 values:  -60.550774 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002300297423695304 values:  -59.07028 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002806407580469622 values:  -60.532112 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0015860784587158705 values:  -59.05242 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  25 target diff:  0.0024833439458527293 values:  -60.617283 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0018593455394680177 values:  -58.949497 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0029575425810411783 values:  -58.955532 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002788698431927137 values:  -60.623722 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0017048069875908714 values:  -58.96209 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0016437984679717123 values:  -58.95609 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0015092051685619006 values:  -58.947838 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003029822025459828 values:  -60.58183 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0013704532098610088 values:  -58.9469 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl! \n",
      "28 Refresh buffer every 1000000 sampling!target diff: \n",
      " 0.003082995606881926 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "-60.56815 ----- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  29 target diff:  0.003016805235603603 values:  -60.522453 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0027395281950122093 values:  -60.55297 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0024275034887600564 values:  -60.56391 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  32 target diff:  0.0031984256440093332 values:  -60.614876 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0036720064305189714 values:  -60.56618 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0032953093375793566 values:  -60.538033 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003201816710934175 values:  -60.481792 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  36 target diff:  0.0031370433299506427 values:  -60.496784 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002654827785047544 values:  -60.489826 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.921008818742901 values:  -58.87724 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002999274870240092 values:  -60.392178 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002711410657554239 values:  -58.934193 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0026753034045035175 values:  -60.340675 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003156607434761436 values:  -58.982166 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0015315586635462682 values:  -59.00898 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002394203486330366 values:  -60.19145 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019879893649973317 values:  -59.05953 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0037313082793101093 values:  -60.041706 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022147647112954823 values:  -59.080555 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.004092244914764325 values:  -59.907917 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001866787582465499 values:  -59.091396 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001861510964311605 values:  -59.098145 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0032199703367812504 values:  -59.68936 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  44 target diff:  0.003676941934821067 values:  -59.596226 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001550600515198319 values:  -59.079346 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020466598228731916 values:  -59.13101 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  45 target diff:  0.0027671914420537365 values:  -59.49516 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0028459064228675574 values:  -59.420025 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0016175881011064191 values:  -59.100727 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0024246615131417004 values:  -59.314365 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  -----iteration: 0.0020505788836102257  --------------------48values:    -59.164604ckpt: target diff:   ----- 5000 0.00263432758923145  \n",
      "--------------------values: \n",
      "\n",
      " -59.26309 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  49 target diff:  0.002152563588369262 values:  -59.21296 -----WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  12 target diff:  0.0021481424357140417 values:  -59.24698 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0021489199766684987 values:  -59.22541 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  13 target diff:  0.0017471250202085735 values:  -59.29062Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl! \n",
      "-----Refresh buffer every 1000000 sampling! \n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  51 target diff:  0.002185418251007991 values:  -59.11621 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  52 target diff:  0.002218866457965763 values:  -59.107178 ----- \n",
      "-----iteration: \n",
      " 14 target diff:  0.001899772959628175 values:  -59.342712 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002638861553686879 values:  -59.0337 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0037923901570190125 values:  -59.36527 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0021276740622409064 values:  -58.978336 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.00206029639350052 values:  -59.422253 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  -----iteration: 0.0016787707400460984  55values:   target diff: -59.446953 0.0022289920295954593  -----values:  -58.91818  \n",
      "----- \n",
      "\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "-----iteration:  56 target diff:  0.0024317812166414618 values:  -58.941746 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0019733836646797015 values:  -59.513054 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0026023999456071443 values:  -58.930244 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "-----iteration:  19 target diff:  0.001954368237673525 values:  -59.565777 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0018766497995170628 values:  -58.891853 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0022767572608033554 values:  -58.943817 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0016333794817450559 values:  -59.579357 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002742611960925388 values:  -58.904522 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017913578819374865 values:  -59.619488 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002322180499620082 values:  -58.937443 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0021992113316091377 values:  -59.610115 ----- \n",
      "\n",
      "-----iteration:  saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/ckpt/offline_rem_50000.ckpt62 \n",
      "target diff: --------------------  behavior cloning --------------------0.002378925013124478\n",
      " values:  -58.895874 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0021797541288528996 values:  -58.882793 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018113060125247264 values:  -59.62649 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002376891402605527 values:  -58.959652 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  24 target diff:  0.0022535686531445155 values:  -59.650208 ----- \n",
      "\n",
      "-----iteration:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "65\n",
      " target diff:  0.002188230555312522 values:  -58.8782 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0019411604338291362 values:  -59.665474 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0021810088614161254 values:  -58.923225 ----- \n",
      "-----iteration: \n",
      " 0 target diff:  0.9232276169365378 values:  -53.064278 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9206207049854432 values:  -55.479195 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018867662968635943 values:  -59.67334 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020823441462083834 values:  -53.041138 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  67 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!target diff:  \n",
      "Refresh buffer every 1000000 sampling!0.002289800448543274\n",
      " values:  -58.97086 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "-----iteration: Refresh buffer every 1000000 sampling! \n",
      "1 target diff:  0.0015190141863114309 values:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-55.640068 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  -----iteration: 27  68target diff:   0.0017651277171709717 values: target diff:   0.0024860145847291604-59.673492  values: ----- -58.983585  \n",
      "\n",
      "----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  2 target diff:  0.0030446253824663676 values:  -55.75779 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0017681150976479537 values:  -58.925232 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0014420779350617528 values:  -52.93372 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0026157689904225878 values:  -59.705635 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024787351940984905 values:  -55.741558 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0018460679527425288 values:  -58.89259 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023633804620985304 values:  -55.69654 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0021975426624182646 values:  -58.870293 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0020016711591772525 values:  -59.688755 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023860944670493363 values:  -55.707355 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002281683011006573 values:  -58.87686 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0019026013065033395 values:  -59.70982 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017517968184398282 values:  -55.781536 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "-----iteration:  73 target diff:  0.0022570827679141516 values:  -58.96596 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002406143940841874 values:  -55.793644 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0027330021352303456 values:  -59.717304 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0016809289767521327 values:  -58.885876 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002803154129004777 values:  -55.960705 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0022693343981248517 values:  -59.74107 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0017701250930465596 values:  -58.82022 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0028139099307552696 values:  -55.97672 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0018401445121200124 values:  -59.759087 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.00247109673926874 -----iteration: values:   -55.9127976  target diff: -----  0.0016717083595923666\n",
      " values: \n",
      " -58.80808 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  34 target diff:  0.0017604979195321936 values:  -59.734097 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0017156831020440075 values:  -58.77548 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00225016258487122 values:  -55.97626 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0019471309745158997 values:  -58.78262-----iteration:   -----12  \n",
      "target diff:  \n",
      "0.0018898073757138182 values:  -56.064636 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0022457643113540666 values:  -59.720554 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9220708912811919 values:  -53.3489 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0016154580644505182 values:  -58.766987 ----- \n",
      "\n",
      "-----iteration:  13-----iteration:  target diff:   10.0026946972879097184  values: target diff:   -56.052770.002381153516243427  -----values:   \n",
      "-53.36566 \n",
      "----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0016496185428788862 values:  -59.73059 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  80 target diff:  0.0017004573016656567 values:  -58.718452 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.001301518206676068 values:  -59.71384 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0020240004317521572 values:  -56.02899 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020639663289917344 values:  -53.38862 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.001770975662527874 values:  -58.641827 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017865573509810411 values:  -53.32963 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  -----iteration: 0.9200235159694726  15values:   target diff: -51.58861  -----0.0014964574497088364  values: \n",
      " -56.105682\n",
      " ----- \n",
      "\n",
      "-----iteration: -----iteration:  82  4target diff:   0.0016255282341569957target diff:  values:   -58.5692560.0016966756396373354 ----- values:   -53.27978\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002250244467804483 values:  -51.63901 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0017661003011666578 values:  -58.59799 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018560875889195336 -----iteration:  values:  2-53.322292  -----target diff:   \n",
      "0.0019568075486338715 \n",
      "values:  -51.700565 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0016794264472315041 values:  -58.567146 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022360923267093764 values:  -53.362835 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002040959625713489 values:  -51.753265 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0012822988300081396 values:  -58.54195 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias4\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "0.0020878028411891944WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      " -51.748264WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "-----iteration: Refresh buffer every 1000000 sampling! \n",
      "7 target diff:  0.0023593703090583275 values:  -53.497044 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "target diff: \n",
      " 0.001612564501494242 values:  -51.79881 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.002101990108549304 values:  -51.891228 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  8 target diff:  0.002527385399862898 values:  -53.534554 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015958234789767605 values:  -53.420406 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017862099182861793 values:  -51.97962 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.922346066371538 values:  -58.44663 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002216530329407719 values:  -53.423504 ----- \n",
      "\n",
      "-----iteration:  1WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " target diff: \n",
      " 0.0039220592922810295 values:  -58.525494 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001412653166096684 values:  -53.269024 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "8Refresh buffer every 1000000 sampling! \n",
      "target diff:  0.0023297131424918583 values:  -51.997784 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.0023390097476992835 values:  -58.585285 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasRefresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  0 target diff:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202410993439233\n",
      " values:  -53.237576 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.001366238522785834 values:  -52.06861 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.001983573489257728 values:  -58.681866 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002157136260847672 values:  -53.209534 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021958203024561324 values:  -58.743694 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020301215617429627 values:  -53.31905 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002308515735931936 values:  -58.760994 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018113159299123329 values:  -53.33164 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021481549369600445 values:  -53.447838 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002040891375114563 values:  -58.782707 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018458954985005232 values:  -53.412006 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001621376360449367 values:  -58.858418 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020808183502566487 values:  -----iteration: -53.406483  8-----  target diff:  \n",
      "0.0020234241560948907\n",
      " values:  -58.89618 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  9 target diff:  0.0018849049006156987 values:  -58.950253 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0017904787595525897 values:  -53.419117 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8 target diff:  0.0018729269133065454 values:  -53.524334 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.003215742941883629 values:  -58.965282 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9227005499158812 values:  -54.441853 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002388959733023293 values:  -59.026035 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003244643418476055 values:  -54.478916 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021928288929400014 values:  -59.048424 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017503795125728314 values:  -53.478577 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00220097875505739 values:  -54.48679 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0028331222679715494 values:  -59.113544 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020732797899264853 values:  -53.53759 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9192192108240551 values:  -60.89777 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002167163093664369 values:  -54.515812 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002319471564491426 values:  -59.13404 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001825967524943867 values:  -53.568718 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018165618927572346 values:  -54.574306 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002529011355002106 values:  -59.147213 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034498893429274497 values:  -60.939373 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002201066565612377 values:  -54.623108 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021353159325414916 values:  -53.571056 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0021904511319522867 values:  -59.2516 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.0021405015569973458 values:  -54.61017 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002191511930796902 values:  -60.973232 ----- \n",
      "\n",
      "-----iteration:  13-----iteration:   target diff: 17  0.0015497271015294317target diff:  values:  0.0028327793951949264  values: -53.702892  -59.312202 ----- \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  7 target diff:  0.002403008601534965 values:  -54.64631 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0022176282981507442-----iteration:   values:  0-53.682312  target diff: -----  0.9220750683685063\n",
      " \n",
      "values:  -53.810665 ----- \n",
      "\n",
      "-----iteration:  18 target diff: -----iteration:   0.00213791493477257953  target diff: values:   -59.297040.0023024183531670374  values: ----- \n",
      "\n",
      " -60.952904 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002246848452691656 values:  -54.659588 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003744891639196737 values:  -53.74911 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018356907223347732 values:  -60.96099 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001825752575013413 values:  -53.63305 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0025233118462068 values:  -54.70963 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0029135406057415867 values:  -59.35558 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003067932727966657 values:  -53.81042 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.001594208147179923 values:  -53.752758 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002175590696547461 values:  -54.714397 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003031691502645752 values:  -59.362125 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002753274993659474 values:  -60.96706 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021529431677425365 values:  -53.905457 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001887822468864997 values:  -53.694904 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018940057700768758 values:  -54.76572 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017909033911950984 values:  -59.404236 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001413698702609564 values:  -60.986565 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018973888293526858 values:  -53.877785 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0020613640666834127 values:  -54.794094 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.00234305480882253 values:  -53.67458 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0021452049758557516 values:  -59.382057 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023132356410425787 values:  -53.994198 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002439790291896427 values:  -53.684177 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0013863416005289303 values:  -54.887188 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "-----iteration:  -----iteration: 23 6  target diff:  target diff: 0.002119198805150661  0.0026679054095139227values:   values: -59.380745  -53.798088 ---------- \n",
      " \n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "20WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "target diff:  0.002059191237591772 values:  -53.727093 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl! \n",
      "7Refresh buffer every 1000000 sampling! target diff: \n",
      " 0.0036988172319207253 values:  -53.852276 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  24 target diff:  0.002183290230523393 values:  -59.431904 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  21 target diff:  0.0017366934592403197 values:  -53.69219 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0023353038770572076 values:  -59.436707 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016758555757811478 values: -----iteration:  22  target diff:  0.0021657705421676693-53.888866  -----values:   \n",
      "\n",
      "-53.71562 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022572218992057283 values:  -59.44587 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022744437937180697 values:  -53.75544 ----- \n",
      "-----iteration: \n",
      " 23 target diff:  0.0014579770168483914 values:  -53.81233 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----iteration: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "27 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias0.0018501729114956973\n",
      " values: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-59.459435 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "-----iteration: Refresh buffer every 1000000 sampling! \n",
      "10 target diff:  0.0021028295265316135 values:  -53.868965 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.0016980448888207795 values:  -59.458492 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "--------------------\n",
      " adv learner --------------------\n",
      "-----iteration:  11 target diff:  0.0016558429217187823 values:  -53.927727 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0020925572645369337 values:  ---------------------59.482117  ----- \n",
      "\n",
      "fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  30 target diff:  0.002013606165017045 values:  -59.48383 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.00386954872346143 values:  -53.91196 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002313950588831114 values:  -59.52825 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9195861208860503 values:  -61.666565 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001832818251157028 values:  -53.845787 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002326248208490128 values:  -59.546963 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  33 target diff:  0.0024847806627216534 values:  -59.522747 ----------iteration:   14 target diff: \n",
      "\n",
      " 0.0020969874434604682 values:  -53.74427 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0033846628920118356 values:  -61.679142 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002088074037851392 values:  -59.490856 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001812295283881145 values:  -53.76939 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0021471846871964906 values:  -61.727722 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001703748887635815 values:  -59.529552 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016453152092607587 values:  -53.65806 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0026106078115269334 values:  -59.556652 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0016071843668204516 values:  -53.657715 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014792639340834763 values:  -61.75121 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----iteration:  37 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "target diff:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel0.001960886735732529\n",
      " values:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "-59.578194WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-----\n",
      " \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  38 target diff:  0.0017335978967709898 values:  -59.535156 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  18 target diff:  0.0013825036133761264 values:  -53.69532 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0016908574163217584 values:  -59.53692 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020965656332032514 values:  -59.56788 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9214032110733874 values:  -53.433647 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0020566716362226426 values:  -59.5968 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026703385946380883 values:  -53.437527 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018590283878721799 values: -----iteration:   -59.613920  target diff:  -----0.9198229510183571  values: \n",
      " -53.422993\n",
      " ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019304249591557453 values:  -53.47813 ----- \n",
      "\n",
      "-----iteration:  1 -----iteration: target diff:   430.002834861640119422  target diff:  values: 0.0020514716706024343  values: -53.46252  -59.66724-----  ----- \n",
      "\n",
      "\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  3 target diff:  0.002386903630694239 values:  -53.48419 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0018429382367336198 values:  -59.65534 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0021542370404684505 values:  -53.60728 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019000169732954902 values:  -----iteration: -53.55249  45 ----- target diff: \n",
      " \n",
      "0.0017065946226201727 values:  -59.66217 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020561504885815217 values:  -53.63848 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002414440139804723 values:  -53.595364 ----- -----iteration: \n",
      " \n",
      "46 target diff:  0.0018254280339599954 values:  -59.639492 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.0018570470324325184 values:  -53.717354 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002259445194977073 values:  -53.65537 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0019095345846156025 values:  -59.660007 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018413609235910637 values:  -53.86227 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0020978702045823944 values:  -59.712147 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002015518112614568 values:  -53.6084 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0031120576590230984 values:  -53.92515 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0019919529927993323 values:  -59.74494 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9216022635707043 values:  -53.994663 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022808850475043657 values:  -53.8573 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020754761989109547 values:  -53.637943 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0018151436333446386 values:  -59.819798 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018148333052731367 values:  -53.856434 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.003155539823239117 values:  -53.63393 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0017349425610576398 values:  -54.05027 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0022921693025016506 values:  -59.80039 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.0013321173485738582 values:  -53.905525 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0012842498516220636 values:  -53.75864 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002276345772639609 values:  -54.057045 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.001892027938962577 values:  -59.866665 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002028447548215782 values:  -59.85796 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017981357699799806 values:  -54.06905 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0021199857273563926 values:  -59.90153 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001627020178234791 values:  -54.10456 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0016358698629728408 values:  -59.876534 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9193409842658424 values:  -61.782494 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.001978541887660822 values:  -59.898808 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00198147804631411 values:  -54.094414 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0018186847732573764 values:  -59.802532 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002834508787349564 values:  -61.60517 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.00182592352512824 values:  -59.781067 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0014514602277301619 values:  -54.07237 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias2\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias0.0024924530311258093\n",
      " values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel -61.615192\n",
      " ----------iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " 59 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      " \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "target diff: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      " 0.001548311285718254 values:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!-59.806786\n",
      " Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  60--------------------  adv learner target diff: -------------------- 0.0022866016870116863\n",
      " values:  -59.711983 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9187132697997042 values:  -54.413452 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001513060422608444 values:  -61.618587 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9204282086961589 values:  -51.61568 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  61 target diff:  0.0018281260892071562 values:  -59.767048 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0033286227454639543 values:  -54.414707 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001477642104884857 values:  -61.63258 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0023506153224737147 values:  -51.652386 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.001897133176208942 values:  -59.736267 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002057488759181104 values:  -51.696495 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002507218786872628 values:  -54.439728 ----- \n",
      "-----iteration: \n",
      " 63 target diff:  0.0016663527686009442 values:  -59.739628 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021412139657397376 values:  -51.726543 ----- \n",
      "\n",
      "-----iteration:  64 -----iteration:  target diff: 3  0.0017409814796644377 target diff: values:   0.0021954256194692346-59.698467  -----values:   -54.49115\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0019022374375985318 values:  -59.72099 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019623067479349107 values:  -51.744194 ----- \n",
      "-----iteration:  4 target diff:  0.002226375380599706 values:  -54.62156 ----- \n",
      "\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  5 target diff:  0.0018668134211905587 values:  -54.692635 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0017645619162637133 values:  -59.706535 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0014829118886341293 values:  -51.819427 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  6 target diff:  0.0018650744481741356 values:  -54.769085 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.001545105878740841 values:  -59.774563 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.002683459763258235 values:  -54.701084 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  68 target diff:  0.0021933100348669713 values:  -59.794987 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002160066707665143 values:  -54.669792 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0015442056852904922 values:  -59.783043 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0027405953400251102 values:  -54.74182 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.001959423463808823 values:  -59.805286 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  10 target diff:  0.002793456284936135 values:  -54.726227 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002014145470394696 values:  -59.84756 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002668207286790939 values:  -54.83704 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0020064298521564458 values:  -59.842365 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  12 target diff:  0.0026955799215255915 values:  -54.866203 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0015013445579319833 values:  -59.887745 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9197630940587401 values:  -60.97419 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  74 target diff:  0.001718981140097797 values:  -59.930664 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001528505424387801 values:  -54.94983 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002079998803255796 values:  -59.85984 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002006419739148417 values:  -55.02023 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9212213068845981 values:  -51.215267 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0017532696763612866 values:  -59.835064 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0017888661047392115 values:  -55.047474 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002302649053980032 values:  -60.958794 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0036524732174908984 values:  -51.16985 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002923362821531118 values:  -55.232666 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0019839800816163376 values:  -59.82256 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  2 target diff:  0.0016328026961217345 values:  -60.96988 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002553171868347803 values:  -51.151752 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.004104854982028589 values:  -55.372562 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0021189117540925226 values:  -59.80935 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0029010584056567627 values: -----iteration:   18-51.14738  target diff: ----- 0.0021787868544478214  \n",
      "\n",
      "values:  -55.368965 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0016873982807719863 values:  -59.79308 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025445002715657914 values:  -60.99355 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0025282460110745823 values:  -51.18166 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019638395812583867 values:  -55.28549 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0017981493742851161 values:  -59.841953 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.0017729523114141405 values:  -60.977577 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002194624413987499 values:  -51.18337 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0017480314171459696 values:  -59.78824 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023407372472850794 values:  -55.29859 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018410728716008646 values:  -61.00754 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9220383027395915 values:  -53.336967 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0013370394287205698 values:  -59.814526 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "6 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kerneltarget diff: \n",
      "-----iteration:   WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "21WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0020945289534604786 \n",
      " target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel values: 0.002154798293816438\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias -51.21411\n",
      " values:   ------55.270508WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel  \n",
      "\n",
      "\n",
      "----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "-----iteration:  Refresh buffer every 1000000 sampling!6 \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "0.0017177787485017973WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "values:  -61.08189 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!-----iteration: \n",
      " 1Refresh buffer every 1000000 sampling! \n",
      "target diff:  0.002455886622524924 values:  -53.375916 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  7 target diff:  0.002177143382038197 values:  -51.167683 ----- \n",
      "\n",
      "-----iteration:  2 -----iteration: target diff:   220.002467138989943736 values:  -53.409172 -----  \n",
      "target diff: \n",
      " 0.0022253412539825434 values:  -55.193134 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020076629503411026 values:  -61.182613 ----- \n",
      "\n",
      "-----iteration:  8-----iteration:   3target diff:  target diff:   0.002807505206388502 0.0023116028557259374values:   values: -51.23319  ------53.48003 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  23 target diff:  0.0016160107695808933 values:  -55.229694 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022581352361754027-----iteration:   9values:   -53.414043target diff:   0.0028113736520246585 values: ----- -51.22769  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  -----iteration: 24  8target diff:   target diff:  0.00162430950234312150.001922453591622046  values: values:   -55.143276-61.252422  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  5 target diff:  0.002016503140109941 values:  -53.459084 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002487514559061695 values:  -55.138393 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018113254728820821 values:  -61.140324 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001880725502716796 values:  -51.20447 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002247263940607216 values:  -55.168285 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017870268191652419 values:  -53.474815 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0016656467955895324 values:  -55.124676 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0014583995046998563 values:  -51.19944 ----- \n",
      "\n",
      "-------------------- -----iteration:  fqe on dqn & sale7 -------------------- \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias0.002218258258139418\n",
      " values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias -53.471897 -----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  10 target diff:  0.002904209257662533 values:  -61.15632 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0028803117747759417 values:  -55.093678 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0014886892252571966 values:  -53.496777 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0024899865239997607 values:  -61.15141 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021090986196829645 values:  -61.160923 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0016339967160768616 values:  -55.11374 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0017736637933177658 values:  -61.10694 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021788892094075163 values:  -55.209694 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0022473376234758754 values:  -55.11563 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.0021109763268957384 values:  -61.263218 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0020832253763303585 values: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " -55.015556 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0025936398533265544 values:  -55.02585 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.922521601937445 values:  -53.665257 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9202039335149708 values:  -58.437263 ----- \n",
      "\n",
      "-----iteration:  15-----iteration:  target diff:   0.002838824956063466534 values:   -61.332222target diff:   ----- 0.001999780132327671\n",
      "\n",
      " values:  -55.043888 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001998755288755342 values:  -53.588432 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00300269602813048 values:  -58.489704 ----- \n",
      "\n",
      "-----iteration:  16 -----iteration: target diff:   350.0016360179452703076  values: target diff:   0.0018635163226478535-61.311428 ----- values:   \n",
      "-55.00103\n",
      " ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9233613445449226 values:  -53.535095 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0031464942455238162 values:  -58.5254 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025447459265552407 values:  -53.634033 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0014997285089327808 values:  -54.984703 ----- \n",
      "\n",
      "-----iteration: --------------------  ckpt: 17  target diff:  150000.0016925401685577326  values: -------------------- \n",
      "-61.289852 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!-----iteration: \n",
      " 1 target diff:  0.0017761262560501022 values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel -53.58868\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias----- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl! \n",
      "3 Refresh buffer every 1000000 sampling!\n",
      "target diff:  0.0015761896143797088 values:  -53.548992 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  18 target diff:  0.002078306427718432 values:  -61.275208 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  3 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "target diff: \n",
      " 0.0025122028520254205 values:  -58.58966 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  4 target diff:  0.002006124439891606 values:  -53.67907 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020831058078828735 values:  -61.253803 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0030466469549616133 values:  -53.5209 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002143815780006423 values:  -58.669437 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0019477143640627822 values:  -61.219337 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002341896554600838 values:  -53.59597 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002025700414876214 values:  -53.745636 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023067062460411206 values:  -58.68566 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.001854147382462253 values:  -61.190937 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002329248926687888 values:  -53.584553 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002218759448880109 values:  -53.810513 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020182095496710413 values:  -58.701042 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018680811198478354 values:  -53.563316 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018434338068444565 values:  -53.71704 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021506515728694393 values:  -58.765263 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0016452814321113777 values:  -61.188854 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022102922117373754 values:  -53.549953 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023731901513768913 values:  -53.707813 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002644648976572374 values:  -58.74931 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002226805722624367 values:  -61.16266 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018312184363162964 values:  -53.489643 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001603184258722541 values:  -53.67857 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017286032911235849 values:  -58.733345 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0016964582413192052 values:  -61.16212 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017332885519873355 values:  -53.73163 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020239834819203335 values:  -53.52608 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019349218094350128 values:  -58.71024 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018343660332415085 values:  -53.562412 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  25 target diff:  0.0015520391588591973 values:  -61.14853 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0025935344996486824 values:  -53.638298 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015470637787922304 values:  -53.80971 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018091456634559727 values:  -58.62371 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.004328376953841674 values:  -58.69214 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018017217918728965 values:  -53.57746 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0015495717056804325 -----iteration: values:   12-61.011524 -----  target diff: \n",
      " \n",
      "0.00200702739121166 values:  -53.75287 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0023345885491961984 values:  -58.789837 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0029781203220228254 values:  -60.98559 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002043412532562104 values:  -53.74746 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019037196511508482 values:  -53.604767 ----- \n",
      "\n",
      "-----iteration:  28-----iteration:  14  target diff: target diff:   0.00147615926132181260.0025589316462852315 values:   values:  -61.041058-58.828728  ----- ----- \n",
      "\n",
      "\n",
      "--------------------\n",
      " ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  13 target diff: -----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "  15 target diff: 0.001763763143125633 values:  -53.711033  0.0017860354258272787----- values:   \n",
      "-58.812744 -----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  14 target diff:  0.0021711181094255724 values:  -53.77848 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  16 target diff:  -----iteration: 0.00198531855948113  15 values: target diff:   -58.86240.0016867646636544676  values: -----  \n",
      "-53.69703 \n",
      "----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002235683570250138 values:  -53.701748 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  17 target diff:  0.0018195196953749385 values:  -58.896732 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.00212849901481647 values:  -53.70418 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019811532729247993 values:  -53.74664 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9204788912008657 values:  -53.16265-----iteration:   -----16  \n",
      "\n",
      "target diff:  0.0012356638791792543 values:  -53.65041 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 -----iteration: -------------------- \n",
      "17 target diff:  0.0014682586772796255 values:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!-53.83652 ----- \n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelLoaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "Refresh buffer every 1000000 sampling!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelLoaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasRefresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel18\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "0.001709302698232834WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      " values:  WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "-58.950813Refresh buffer every 1000000 sampling!\n",
      " ----- \n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!Refresh buffer every 1000000 sampling!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "target diff:  0.002859403415723416 values:  -53.171413 ----- \n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  19 target diff:  0.0023717452834246698 values:  -59.018288 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018225778580812444 values:  -53.122078 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  3 target diff:  0.0018231609190038965 values:  -53.28164 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002058147886971712 values:  -59.070415 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002738788665415373 values:  -53.215145 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0022172154438454264 values:  -59.11425 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024577025227086433 values:  -53.25717 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020890842084652877 values: --------------------  -53.266827fqe on dqn & sale  ------------------------- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  22 target diff:  0.002904886898640717 values:  -59.212994 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017997866420057672 values:  -53.2959 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.004260884798799826 values:  -59.244335 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0013127227534843 values:  -53.349346 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002576926484102202 values:  -59.27763 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0023612453784301914 values:  -59.241295 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  26 target diff:  0.00236644607803728 values:  -59.223057 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.00254200418010914 values:  -59.2037 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.0025505507249345906 values:  -59.242878 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9197017581411528 values:  -59.79892 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9229223552492758 values:  -51.90463 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9217134390858372 values:  -53.89182 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018726424936076316 values:  -59.226276 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.0025440666889756645 values:  -51.941372 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003936221351040681 values:  -59.834526 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027649914958174093 values:  -53.787457 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002548112905932687 values:  -51.921944 ----- \n",
      "\n",
      "-----iteration: -----iteration:   300  target diff: target diff:   0.9198366435983707 0.002207317372849726 values: values:  -59.216587 -51.865154  ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  2 target diff:  0.0025546471072895576 values: -----iteration:   -59.8436932  target diff: -----  0.0024493003438286576\n",
      "\n",
      " values:  -53.74303 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004223286714827379 values:  -51.957466 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  -----iteration: 0.002630259849318147  31values:   target diff: -51.78513  0.00208455399190106-----  values: \n",
      " \n",
      "-59.203938 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0027063874990002684 values:  -53.64997 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0037789226493244316 values:  -51.999012 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023990627305053034 values:  -59.82061 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019379488883267517 values:  -53.56321 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002383486828480866 values:  -51.708008 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002182201186879357 values:  -59.157375 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026966656636627892 values:  -52.148586 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017869169451753676 values:  -59.839325 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0030969491523778333 values:  -53.390835 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002442329491410351 values:  -51.697456 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0021643710749338703 values:  -59.150566 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0032799392785396292 values:  -52.09204 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001288942433017326 values:  -59.813152 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024475457166707928 values:  -53.449123 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0018457876552625935 values:  -59.199978 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001733220770884221-----iteration:   values: 5  -51.833557target diff:   0.0025874879536279803 ----- values:  \n",
      "\n",
      "-52.147427 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002232303099456763 values:  -53.316456 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020541878103978004 values:  -51.826694-----iteration:   -----6  \n",
      "\n",
      "target diff:  0.0018296950551292066 values:  -51.955036 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019762295707970224 values:  -59.222466 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.003322392954540449 values:  -51.904396 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018331153920806706 values:  -51.87473 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002016492179782185 values:  -53.311367 ----- \n",
      "\n",
      "-----iteration: -----iteration:   36 8target diff:  target diff:  0.001930508583127606  values: 0.0021994251655047155  values:  -51.981438 -59.242676 ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  9 target diff:  0.0017172920579229807 values:  -53.27276 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022530605116651233 values:  -52.044373 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0023498159762903306 values:  -59.244076 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001993816535991957 values:  -52.092663 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0026318378903839633 values:  -52.115482 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013707713569908041 values:  -53.2496 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020493760231877598 values:  -52.128033 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017807682200364006 values:  -59.115093 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  11 target diff:  0.0015933515332407348 values:  -52.374058 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001647380322585617 values:  -52.084675 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002689768196330812 values:  -59.05038 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016454641687840168 values:  -52.15159 ----- \n",
      "-----iteration:  \n",
      "12 target diff:  0.002750101606092862 values:  -52.605587 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0019082010071605259 values:  -59.031746 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003176608759173457 values:  -52.56985 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016830097330382645 values:  -52.19694 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001983369907493363 values:  -58.977142 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.003729364419636891 values:  -52.713356 ----- \n",
      "-----iteration: \n",
      " 0 target diff:  0.9200121394216979 values:  -59.828884 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0020701426426621363 values:  -52.296185 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0017068283112982702 values:  -----iteration: -58.974155  15-----  target diff: \n",
      " \n",
      "0.0021198683422457864 values:  -52.356537 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.003101855767965835 values:  -52.76637 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030978360208569074 values:  -59.922127 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0018897830577555808 values:  -58.97332 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0023035403633753226 values:  -52.807125 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.001559315238938272 values:  -52.282192 -----WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  2 target diff:  0.0024014740815559736 values:  -59.89848 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.00275348354276166 values:  -52.793434 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0021569619621398077 values:  -58.92262 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9217962980917631 values:  -52.875645 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0015310924351680426 values:  -52.453953 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001934664519371736 values:  -59.903084 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0028010419917798577 values:  -52.809864 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0023739897216563887 values:  -52.889275 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.001721534711844157 values:  -58.88383 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002492151122957458 values:  -52.51839 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 4  2target diff:   target diff:  0.00178832500732901580.0021327413168997613  values:  -52.899483values:  -----  \n",
      "-59.93863\n",
      " ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0017607494672411091 values:  -52.54423 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0015877600409960103 values:  -52.84225 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0016277009794955996-----iteration:   3 values:  target diff:  0.0026185120009236907 values:  -52.918793 ------58.825863  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  20 target diff: -----iteration:   5 0.002217573603236573target diff:   values: 0.00202053309276491  -52.56891 values:  ----- \n",
      "-59.9538\n",
      " ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0013361384093159637 values:  -58.784695 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002505678479875534 values:  -52.744053 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019490354945740115 values:  -52.829113 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017904567819615029 values:  -52.45522 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002842517449700382 values:  -52.598248 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015212056899611744 values:  -59.94757 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019631581285163013 values:  -52.756863 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0016935253798351674 values:  -52.478413 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0022937761887110108 values:  -52.74216 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019624409403581167 values:  -60.025738 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019017601972398507 values:  -52.699898 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0020130986636576515 values:  -52.50167 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018842209042031748 values:  -52.85847 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018086306532223901 values:  -60.082306 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018533661676658209 values:  -52.633698 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.00248061566449309 values:  -52.51504 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.003371561444117746 values:  -60.06519 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002449596142091481 values:  -52.800655 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002125741768067205 values:  -52.509182 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001628796116363776 values:  -52.58932 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0022059877468946472 values:  -52.873936 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0019733152832184316 values:  -52.53615 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014549967481934472 values:  -60.10566 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl! \n",
      "9 Refresh buffer every 1000000 sampling!target diff: \n",
      " 0.0016341999995163653 values:  -52.602478 ----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "-----iteration: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "27 target diff:  0.0024096737569019484 values:  -52.545757Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl! \n",
      "----- Refresh buffer every 1000000 sampling!\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  26 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "target diff:  0.0021985640990947 values:  -52.945637-----iteration:  28 target diff:   0.0025798052407964103----- values:  -52.529625 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015319576813729264 values:  -52.580242 ----- --------------------\n",
      " \n",
      "adv learner --------------------\n",
      "-----iteration:  0 target diff:  0.9213460563414313 values:  -57.951862 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018903720621860174 values: -----iteration:   -52.58761227  ----- target diff: \n",
      " \n",
      "0.0024435103972409267 values:  -52.950935 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0021144730138642517 values:  -52.493217 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003240604625311651 values:  -57.98479 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0017430923263119134 values:  -52.601307 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 30 28 target diff:   target diff: 0.0019778569490037875  0.0016368806736948205values:  values:  -52.47161  -52.935635----- \n",
      " -----iteration:  -----\n",
      "2  \n",
      "target diff:  \n",
      "0.002654895008840253 values:  -58.00932 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0020328365418371993 values:  -52.44749 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002375197070584278 values:  -58.051006 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020858588281567427 values:  -52.688015 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  29 target diff:  0.0020839965335849903 values:  -52.79778 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0017523389439839685 values:  -52.4351 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023104469774444807 values:  -58.070843 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002364962715574743 values:  -52.748898 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.00223155812829619 values:  -52.697598 ----- \n",
      "\n",
      "-----iteration: -----iteration:  31  target diff: 33  target diff: 0.0018610759968998923  0.0017536960229482211-----iteration:  values:  values:   15 -52.707653-52.413975target diff:   ----- 0.0011876025460831462-----iteration: -----   values: \n",
      "5\n",
      "  target diff:   -52.587185\n",
      "0.0017811794079177169\n",
      "  values: -----  -58.089558\n",
      "\n",
      "-------------------- -----  \n",
      "\n",
      "ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  32 target diff:  0.0022365365420138907 values:  -52.653667 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.00211577934403091 -------------------- adv learner --------------------\n",
      "values:  -58.107735 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0023503904787003337 values:  -52.42214 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0025241336135129696 values:  -52.67231 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021432168518498644 values:  -58.14167 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0015881008563437187 values:  -52.61632 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0022906454876442353 values:  -52.41963 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018544052806850613 values:  -58.19766 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001609231744911608 values:  -52.584785 ----- \n",
      "\n",
      "-----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "36 target diff:  0.002410619725009813 values:  -52.429966 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021013008010596756 values:  -58.215183 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002191197621827818 values:  -52.453876 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0017835135966759689 values:  -52.33897 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  10 target diff:  0.0017462707281017422 values:  -58.248707 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002841220176249584 values:  -52.349907 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017749043445871233 values:  -----iteration: -52.297546  0-----  target diff: \n",
      " \n",
      "0.9196878169149775 values:  -58.9524 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0023553970217543066 values:  -52.412174 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0029013905081768337 values:  -58.28077 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0022886695036942162 values:  -52.28463 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027195908621582047 values:  -58.94184 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0019724765497301355 values:  -52.278755 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020186564825204543 values:  -52.24094 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018697220410901448 values:  -58.99705 -----iteration: -----  \n",
      "12 \n",
      "target diff:  0.0024266103013341226 values:  -58.329456 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002602500797220444 values:  -52.171867 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002049564355667673 values:  -58.362568 ----- \n",
      "-----iteration:  41\n",
      " -----iteration:  3 target diff: target diff:  0.0019520076197331523  0.001842988906274606values:   -59.008354values:  -52.208187  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  4 target diff:  0.0012471733960500457 values:  -59.107914 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  -----iteration: 0.001788031152372661  14 values: target diff:   0.0020203651527522302-52.10879 values:  ----- \n",
      " \n",
      "-58.420696 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0024132830344790546 values:  -51.991997 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002257089158531263 values:  -58.474174 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0019282144732823928 values:  -52.047203 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0021691488176467863 values:  -52.034626 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  44 target diff:  0.0019766542663751485 values:  -51.96496 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0017798437714686506 values:  -52.084606 -----iteration: -----  16\n",
      "\n",
      " target diff:  0.002290297653623935 values:  -58.493645 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9232026524981437-----iteration:   values: 44-----iteration:   -51.953472 target diff:  17 -----0.0017886093273998282  target diff:   \n",
      "values: 0.00297478057791065 \n",
      " values:  -58.497017-52.095135  ---------- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  45 target diff:  0.0020348006459160926 values:  -51.939907 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030307473122596876 values:  -51.93333 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0016450263542322908 values:  -52.19425 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0021792940693176424 values:  -51.866875 -----iteration:  18----- target diff:  \n",
      "\n",
      " 0.0029034362780197233 values:  -58.52616 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025461264968365677 values:  -51.91142 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0023966611592423433-----iteration:   19values: -----iteration:    target diff: 46  -51.798054target diff:  0.0027632432146038636 ----- 0.0023495701062349124 values:  \n",
      " values: -58.555134 \n",
      "----- \n",
      "\n",
      " -52.18478 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002768391402817137 values:  -51.94112 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0020290563189666417 values:  -58.56765 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0020246658736481453 values:  -51.873493 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.0035153678235272335 values:  -51.978996 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0015071712115169826 values:  -52.149372 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0023232308384856814 values:  -51.790672 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0020820987365696027 values:  -58.56235 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0026390351065626056 values:  -51.930584 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0019511211771927974 values:  -51.787598 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9195361255716306 values:  -59.45992 ----------iteration:  \n",
      "\n",
      " 22 target diff:  0.0028729982983576024 values:  -58.59444 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002106381767052605 values:  -52.023357 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0027622107898184482 values:  -51.841797 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0018380804040171738 values:  -51.800617 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.001688074365738566 values:  -52.009163 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002016517858641579 values:  -58.65163 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0017494547399458788 values:  -59.41895 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002588892713793595 values:  -51.897854 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0018819354344910316 values:  -51.755108 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0014155482356942332 values: -----iteration:   -52.08135224  ----- \n",
      "target diff: \n",
      " --------------------0.0018916120517245318 ckpt:   values: 20000 -58.670803 ----- \n",
      "\n",
      " --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  8 target diff:  0.0027212158523096373 values: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl! \n",
      "-51.900146Refresh buffer every 1000000 sampling!\n",
      " ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018336457137916777 values:  -59.359234 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0018602562582202865 values:  -51.704803 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "3 target diff:  0.0015721519180583957 values:  -59.44153 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.002768432491476175 values:  -51.96665 ----- \n",
      "-------------------- adv learner\n",
      " --------------------\n",
      "-----iteration:  54 target diff:  0.001967187463764136 values:  -51.7815 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002250835936144526 values:  -58.670372 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019275823014967828 values:  -59.44938 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0017533260600571105 values: -----iteration:   26 target diff:  0.0027440461574795697 -51.69659values:  -58.707287  ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  10 target diff:  0.0028706053372247364 values:  -51.951893 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0023282586725827145 values:  -51.630768 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0014314109477178308 values:  -59.451344 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel11\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biastarget diff: \n",
      " -----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "0.0021312475272542305  27values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias  -51.9015target diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel -----0.002499837490042382\n",
      "  values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      " \n",
      "\n",
      "-58.667694 ----- WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  57 target diff:  0.001888793457619832 values:  -51.639275 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.0025560148139009134 values:  -58.67042 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  12 target diff:  0.0021246841067664975 values:  -51.811745 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  58 target diff:  0.0023274987328104515 values:  -51.60241 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002757660842830557 values:  -51.77471 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002147749053151315 values:  -58.645832 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0016185966628955012 values:  -51.49872 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0024782798393492367 values:  -51.739677 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0013387549211952268 values:  -51.437508 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002630561127570743 values:  -58.61684 ----- \n",
      "\n",
      "-----iteration:  31--------------------  fqe on dqn & saletarget diff:  -------------------- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026975839401380715WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      " values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-58.59231\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  32 target diff:  0.0021234104576599955 values:  -58.564087 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001607940456802338 values:  -51.71137 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0020829141529199336 values:  -58.506268 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0023721593046559177 values:  -58.4745 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002024104981667867 values:  -51.80194 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002264887519950675 values:  -58.426727 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002391946806452574 values:  -51.74838 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0020115178732072352 values:  -58.40305 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  18 target diff:  0.001897223365306168 values:  -51.774273 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0029631515809779613 values:  -58.317463 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  19 target diff:  0.0016539913805614455 values:  -51.73808 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0028025964051660583 values:  -58.24148 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9222716517521119 values:  -54.078655 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9187630218408397 values:  -52.836285 ----- \n",
      "-----iteration: \n",
      " 20 target diff:  0.0017124977461604404 values:  -51.74821 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0023834561668283024 values:  -58.179295 ----------iteration:   \n",
      "0\n",
      " target diff:  0.9190459580311962 values:  -61.812714 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004701634079001727 values:  -54.09768 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.001986013190942798 values:  -51.665676 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0018661768440298386 values:  -52.754692 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002650023465762402 values:  -58.153107 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003553840409388216 values:  -54.109802 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019040745685791674 values:  -52.909454 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020067658644543434 values:  -61.896667 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017762028792797325 values:  -58.09805 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019295915642298137 values:  -52.943783 ----- -----iteration: \n",
      " \n",
      "3 target diff:  0.0032106091273468845 values:  -54.059795 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0017225026392606792 values:  -51.625023 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0026228097004195186 values:  -58.066372 ----- \n",
      "\n",
      "-----iteration:  4-----iteration:   4target diff:   target diff: 0.00304869507537282 0.002820739764598792 values:  values:   -54.04309-52.936436  ---------- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  2 -----iteration:  23target diff:   target diff:  0.00174734394580933680.0018494712088875994  values:  -61.972256 values: -----  -51.555603 -----\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  5 target diff:  0.0013781517638147647 values:  -53.030964 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0014795186878812719 values:  -51.536743 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016942241760199725 values:  -61.962727 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 43  5target diff:   target diff: 0.001931975646757872  0.0025956131301922416 values:  values: -58.058414  -54.108982 ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  4 target diff:  -----iteration:  0.00165715356647107426 target diff:   values: 0.003107094469516882 -61.954338  values: -----  \n",
      "-54.15325\n",
      " ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.001991174474771279 values:  -58.018513 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002552156560839336 values: -----iteration:   -57.9923977  -----target diff:   \n",
      "0.0025498803194504943\n",
      " values:  -54.1706 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018433308750910999 values:  -61.894634 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0026680539573801262 values:  -54.152004 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002137055833515905 values:  -57.955803 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019653950586805908 values:  -61.95335 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002095181166782053 values:  -54.165287 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002586651112044808 values: -----iteration:  -57.978657 7 -----  target diff:  0.0023703028821802138 \n",
      "\n",
      "values:  -61.99412 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002061735145554913 values:  -54.147087 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0025352613587723964 values:  -57.936848 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019001779531174349 values:  -62.04861 ----- WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  11 target diff:  0.001964640683717279 values:  -54.166817 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002110646636287616 values:  -57.933514 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0012605751320175732 values:  -62.038513 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019545026251321235 values:  -54.203545 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9188494209559822 values:  -51.648167 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0017157638747175527 values:  -57.929844 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020809024598959494 values:  -54.266727 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005092800954324063 values:  -51.69189 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.923455957994044 values: -----iteration:   -52.72960751  -----target diff:   \n",
      "\n",
      "0.002071378395793145 values:  -57.888367 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0025189022078916145 values:  -54.281647 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028296511518341367 values:  -51.713352 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00205550786134441 values:  -52.72992 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002170582719651929 values:  -57.918556 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025825308712649634 values:  -51.817528 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001679124726103979 values:  -52.737125 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002224188659530332 values:  -57.902126 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0022023683235303545 values:  -54.310665 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002908491395507959 values:  -51.93137 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.001725589562020041 values:  -57.93273 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002066292638826275 values:  -52.759636 ----- \n",
      "\n",
      "-----iteration:  16 -----iteration:  target diff:  50.002297869210814629 target diff:  0.0026334354288962167  values:  -54.29538 values:  -52.051056----- \n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002199986867005696 values:  -57.929512 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002761518875699726 values:  -52.077328 ----- \n",
      "\n",
      "-----iteration:  4-----iteration:   target diff: 17  target diff:  0.0017169163596907958 values:  0.0017225875509003143-54.279305  -----values:   -52.81504\n",
      "\n",
      " ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0018090242268036523 values:  -52.155464 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0015174750596410533 values:  -57.93775 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.00207499860193052 values:  -----iteration:  -54.28067 5 target diff:  ----- \n",
      "0.002331212974858678 values: \n",
      " -52.786377 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002147179626826701 values:  -57.929382 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024069116734920307 values:  -52.156532 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 6  19target diff:   target diff: 0.0021992571225493414  0.002391168886562593 values: values:   -52.701088-54.258217  ---------- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  58 target diff:  0.0016708615713893979 values:  -57.935158 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001460196038409774 values:  -52.25761 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  0 target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "0.9204321079879039WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias values: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-59.46844 ----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  -----iteration: 20  7target diff:   0.002358778779373937 target diff: values:  0.002077881713710909 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl! \n",
      "-54.245876values: Refresh buffer every 1000000 sampling!\n",
      " ----- \n",
      "\n",
      " -52.682407 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  59 target diff:  0.001782194051855958 values:  -57.95112 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  21 target diff:  0.0023299680078990924 values:  -54.22214 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- -----iteration: adv learner  --------------------8 \n",
      "target diff:  0.001976434750868563 values:  -52.64337 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0037075731458997984 values:  -59.53338 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0019479871548196005 values:  -57.959465 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020054097693087036 values:  -52.575836 ----- \n",
      "\n",
      "-----iteration:  22-----iteration:   61target diff:   0.0023263158698855458target diff:   0.001664550151796358 values:  -57.98828values:   -54.217884 ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  23 target diff:  0.002364060247875444 values:  -54.199665-----iteration:   -----62  \n",
      "target diff: \n",
      " 0.0016653330233279613 values:  -57.997753 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001863909760829435 values:  -59.52215 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017147898053852856 values:  -52.55849 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0017889617100063815 values:  -54.234287 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002186666973413156 values:  -57.99951 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021127940306681896 values:  -----iteration: -52.46508  25-----  target diff: \n",
      " 0.002948652506642265\n",
      " values:  -54.22399 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017904693993499212 values:  -59.4587 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002461580192825449 values:  -57.994873 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022572730648405103 values:  -52.446526 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002690343209667571 values:  -54.15509 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0016915945864831511 values:  -58.02139 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019241783875203154 values:  -52.448185 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021468030020345623 values:  -59.534954 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0017970803113356716 values:  -58.029854 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias5\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias0.0019321042201227451 \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-59.548504\n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-----\n",
      " \n",
      "\n",
      "-----iteration:  27 target diff:  0.004049954724034652 values:  -54.125557 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021626249667248847 values:  -52.468693 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0019475653234567864 values:  -58.001247 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.003075716251816406 values:  -59.545498 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0047035930044856894 values:  -54.056488 ----------iteration:   \n",
      "68 \n",
      "target diff:  0.0019506288777807843 values:  -58.03349 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0037652504557991054 values:  -54.067802 ----- \n",
      "-----iteration: \n",
      " 69 target diff:  0.0017116000478933676 values:  -58.017395 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002354204586090155 values:  -52.53717 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022931801293506284 values:  -59.64462 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0030810963017126407 values:  -54.039104 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0019171318281205412 values:  -58.024166 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0032105663523051713 values:  -54.034405 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0017910357330204274 values:  -58.01591 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0029241050442359758 values:  -53.9564 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002631529769759631 values:  -59.633537 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0017570789984864843 values:  -57.989468 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0024518245400819653 values:  -52.555473 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002899157863911707 values:  -53.908245 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0022190157838877537 values:  -58.013493 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001924887689885879 -----iteration:  34values:   target diff:  -59.7142330.003108289044327354  ----- values: \n",
      "\n",
      " -53.770325 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  17 target diff:  0.003158595498992413 values:  -52.5224 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0020395825998849528 values:  -57.9878 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0025247391273523143 values:  -53.687294 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002198545836289196 values:  -59.759052 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0018722404754253213 values:  -58.0117 ----- \n",
      "\n",
      "-----iteration:  36 target diff: -----iteration:  0.0023140147557098485  0values:  target diff:  -53.651436  0.9182196960306018-----  values: \n",
      "\n",
      " -53.184204 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018419823950970237 values:  -59.745296 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.00262811978324437 values:  -52.49439 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0019630135085303728 values:  -58.023647 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0024365270912091795 values:  -53.5908 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003152057160973885 values:  -53.27164 ----- \n",
      "\n",
      "-----iteration:  19 target diff: -----iteration:   0.0020674862066277534 77values:   target diff: -52.461605 0.0018085052413651364  ----- values: \n",
      " \n",
      "-58.02586 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002803036244060051 values:  -53.325043 ----- \n",
      "\n",
      "-----iteration:  12 target diff: -----iteration:   0.00238032369177707138  values: target diff:  0.002365014952611767  values: -59.829926  ----- \n",
      "-53.534077 \n",
      "----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.002049263025744156 values:  -58.010654 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023678924858384926 values:  -53.472477 -----iteration:  -----20 \n",
      " target diff: \n",
      " 0.002095352911613711 values:  -52.486233 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.001783227366237361 values:  -58.062386 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00251558260961881 values:  -53.59566 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  2139  target diff: target diff:   0.00240344544985763570.004054489874957453  values:  values: -53.322876  -52.530514 ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  80 target diff:  0.0023417894083276555 values:  -58.089226 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0022205639198745195 values:  -59.842854 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00390158247926441 values:  -53.65125 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0032639333854606344 values:  -53.149357 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.001901902595051338 values:  -58.126534 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0016890088946766768 values:  -59.82945 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002598619051376491 values:  -----iteration:  41 -53.708073 ----- target diff: -----iteration:  82 \n",
      " \n",
      "target diff: 0.002704486701687586  values: 0.002103815919331207 values:  -58.149952 ----- -53.10957 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  7 target diff:  0.0013902284358550054 values:  -53.865604 ----- -----iteration: \n",
      " 22\n",
      " target diff:  0.00267191633573003 values:  -52.548115 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.001873125252837969 values:  -58.156185 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002488870578483651 values:  -52.94798 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019841820082848517 values:  -52.470856 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0016312513860029275 values:  -58.179173 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0021494211426721912 values:  -52.79789 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002415499139590097 values:  -59.85024 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018770588392759148 values:  -52.43936 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0022433055300661 values:  -52.758087-----iteration:   85 target diff: -----  0.0019410824949804514\n",
      "\n",
      " values:  -58.144924 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002030981787449545 values:  -59.864952 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration: -----iteration:   8645  target diff: target diff:  0.0021053246372677325 values:  0.002273561333505828  -58.13773values:   ----- -52.64013 \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  25 target diff:  0.0012897311914006001 values:  -52.415596 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "-----iteration: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "87 target diff:  -----iteration:  0.001818939935091036246  target diff: values:   -58.1015970.0022969259886832334  -----values:   -52.57669\n",
      " \n",
      "-----Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      " \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  17-----iteration:   88 target diff: target diff:  0.0016773873653735964 0.0024257202506458393  values: values:   -58.107395-59.907066 ----- -----  \n",
      "\n",
      "\n",
      "-----iteration:  \n",
      "47 target diff:  0.001919222442350733 values:  -52.48712 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0022050673524333536 values:  -52.320435 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0020428872494869382 values:  -58.050354 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0022884110538963364 values:  -52.27859 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0018343234419881825 values:  -58.034298 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  18 target diff:  0.002285569770484894 values:  -59.947956 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0025260220778108643 values:  -52.19091 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0013765672740733178 values:  -58.04967 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!51\n",
      " Refresh buffer every 1000000 sampling!target diff: \n",
      " 0.002394024047355716 values:  -52.090446 ----- \n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9207758720525305 values:  -53.661797 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  19 target diff:  0.0024619893917282726--------------------  adv learnervalues:   ---------------------59.98129\n",
      " ----- \n",
      "\n",
      "-------------------- -----iteration: fqe on dqn & sale  52-------------------- \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel 0.002926854386924315 \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-51.993008\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel-----\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  1 target diff:  0.004396444703619567 values:  -53.568695 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0024030133561742384 values:  -60.014492 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002754929227987822 values:  -51.882954 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0036033389542276095 values:  -53.43934 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002770538153811527 values:  -51.78015 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0022224864320962937 values:  -60.04672 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0042003527476560144 values:  -53.343597 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0027969008006397565 values:  -51.71748 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.003176536119307907 values:  -53.25995 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0018767320670065046 values:  -60.121983 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.002556630337542489 values:  -51.619915 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0029262679189297706 values:  -53.304688 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0021989900556091293 values:  -51.553234 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  6 target diff:  0.0021065429478132965 values:  -53.139996 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0019411534374480202 values:  -51.44975 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00352891217108496 values:  -53.180843 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002369384547071558 values:  -60.12336 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0017809338305582888 -----iteration: values:   -51.3886038  -----target diff:   0.0018872725660157123\n",
      " values: \n",
      " -53.446247 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  9 target diff:  0.002679283789319109 values:  -53.36874 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0021248648757099886 values:  -51.338867 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0024023632321699367 values:  -53.317364 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002074664029379233 values:  -51.26212 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9218604707117802 -----iteration: values:  11  target diff: -52.887302  0.00252843234566918-----  values:  -53.337543\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0016303282797249868 values:  -51.19668 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0032673981549514275 values:  -60.140068 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026780412762420465 values:  -52.91981 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0015065202652041396 values:  -53.431545 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002247161676082197 values:  -51.16609 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002071644551453825 values:  -52.99693 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001472795008011414 values:  -53.34371-----iteration:   64-----  target diff: \n",
      " \n",
      "0.0026928925456347736 -------------------- values:  ckpt: -51.134956  30000 ------------------------- \n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "3 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kerneltarget diff: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "0.0019177211671532397 values:  -53.085125 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  65 target diff:  0.0019364543902008265 values:  -51.081867 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.0028144468778858924 values:  -53.08919 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  25 target diff:  0.0030242500201826407 values:  -60.094414 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0021253926362502606 values:  -51.009895 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00201275333779349 values:  -53.132263 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9209657010515219 values:  -59.62121 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0033911941543412366 values:  -60.118015 -----iteration: ----- 67  target diff: \n",
      " \n",
      "0.0022336252202374844 values:  -50.996487 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001779967606124295 values:  -53.10672 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005210723298238002 values:  -59.70863 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002040039689725739 values:  -60.132122 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0021628826404981112-----iteration:   values:  7-50.986214  -----target diff:   0.0018492135778759424\n",
      "\n",
      " -----iteration: values:   2 -53.08231target diff:   -----0.004302694893972006  \n",
      "\n",
      "values:  -59.71637 ----- \n",
      "\n",
      "-----iteration:  8-----iteration:   3target diff:   target diff: 0.002113055911316855 -----iteration:  0.002192703491926023 values: 69  -53.038006 values: target diff:  -----  0.0027783139579470205 \n",
      "\n",
      " values:  -50.954754 -59.742466-----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  9 target diff:  0.0021461960858797416-----iteration:  values:   -53.0201844 -----  \n",
      "target diff:  0.002096849384897969\n",
      " values:  -59.767128 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0019333762453514723 values:  -60.02112-----iteration:   70 -----target diff:   \n",
      "0.002185640396220584\n",
      " values:  -50.915455 ----- \n",
      "\n",
      "-----iteration:  10 -----iteration:  target diff:  0.0012924108204689155  values: target diff:  0.0018384220933869997 values:   -52.99879-59.781616 -----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  71 target diff:  0.001523687024234142 values:  -50.882477 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002219787228822179 values:  -59.80694 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0016508881754583994 values:  -50.84128 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001746123925082533 values:  -59.79621 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00299887500876248 values:  -60.011204 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  30 target diff:  0.0029078270567406118 values:  -60.011024 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0018850186015787274 values:  -50.771454 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024676400466629193 values:  -59.816692 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0020519070489684603 values:  -50.74442 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001925325825387178 values:  -59.83552 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018219058201543554 values:  -59.865604 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0018931235544763893 values:  -50.75422 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0017853763341389081 values:  -59.90024 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019354203114039883 values:  -59.816704 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0019084697385017494 values:  -50.724308 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  77 target diff:  0.0015971391272927304 values:  -50.72158 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0025490791006584374 -----iteration: values:  -59.880337  12 ----- target diff: \n",
      " 0.0025575108543411185\n",
      " values:  -59.792873 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0019403802814180486 values:  -50.713753 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9220349803666201 values:  -53.863678 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002323234091535907 values:  -59.833523 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  33 target diff:  0.0021203153325926333 values:  -59.815315 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002888280071557395 values:  -53.810528 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0013908678561171792 values:  -50.72385 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration: \n",
      " 34WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "0.002009276138102446WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "values: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "-59.83399-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel ----- \n",
      "\n",
      "\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias14 target diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "0.0018792983995712948WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "-59.86982WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias ----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.0022292608817667298 values:  -53.859993 -----Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      " \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  0 target diff:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "0.9192504192637497\n",
      " values:  -53.23383 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.0026347532233790254 values:  -53.92612 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003326556376466978 values:  -53.191708 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002301317522473621 values:  -59.931084 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022026478830689373 values:  -53.86549 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001723587828586368-----iteration:  values:   2-59.675575  target diff: -----  \n",
      "0.0030811045501485394\n",
      " values:  -53.265045 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001978643783804511 values:  -53.216824 ----- \n",
      "\n",
      "-----iteration:  36 -----iteration: target diff:   50.002291413150087539  target diff: values:   0.0022691960245214424-59.646263 -----  values: \n",
      " \n",
      "-53.804207 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.003368514322768659 values:  -60.01706 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002612828096673816 values:  -53.341957 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002067061896942082 values:  -53.787037 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016163771846414098 values:  -53.43149 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0015905727053941415-----iteration:  17 target diff:   values:  -----iteration: -59.549225  7-----0.003266604099693557  target diff: \n",
      "\n",
      " 0.0023230221560384874  values: values:  -60.041233  -53.800224-----  -----\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026047000690875956 values:  -53.568256 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 8  target diff: 18 0.0016117104190763929  values: target diff:  -53.797092 ----- \n",
      " \n",
      "0.002241381380904314 values:  -60.09618 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  7 target diff:  0.0026442946630956398 values:  -53.583473 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 19  9target diff:  0.0021271590469727473 values:  -60.137146  -----target diff:  \n",
      " \n",
      "0.0017513590880206186 values:  -53.81491 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0025531550638849716 values:  -59.49823 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015097756685173358 values:  -53.652466 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0017727126334638403 values:  -60.143116 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.00230382289598598 values:  -53.786583 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002219167599772825 values:  -53.803825 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002259246110339767 values:  -59.39726 ----- \n",
      "\n",
      "-----iteration: -----iteration:   2110  target diff: target diff:   0.001782130284253210.002169431791006694  values: values:   -53.957832-60.146572  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  11 target diff:  0.0020505096991402304 values:  -53.709797 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0022202233246571366 values:  -54.241184 ----- \n",
      "\n",
      "-----iteration:  12 -----iteration:  target diff: 40  0.0021013519845301124target diff:   0.002265920238370383values:   values: -53.61854  ------59.292873  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002053252067108248 values:  -60.197 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0024436290163412427 values:  -54.292114 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019725464667810777 values:  -60.205647 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016509283534555756 values:  -54.33172 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0015180396184207563 values:  -59.078773 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0016848465732684048 values:  -60.252575 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002764205279049195 values:  -54.44622 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0026226726697313467 values:  -53.644012 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0021776114835461127 values:  -60.317226 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  15 target diff:  0.001754795425834323 values:  -54.525364 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002074259329037858 values:  -60.340496 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002244734573218644 values:  -58.892082 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001810921764147144 values:  -53.674297 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016263283234345912 values:  -54.682068 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9234186415501152 values:  -53.547024 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0016970554255963035 values:  -53.621254 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0014438674770354694 values:  -54.99058 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0030609370891674912 values:  -58.7718 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0017802420106371212 values:  -60.3793 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0031654005615033964 values:  -53.577034 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002496960135516937 values:  -53.59682 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002756854912309924 values:  -60.42426 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0019784101061860082 values:  -58.64876 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029200258214225503 values:  -53.618862 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021090282669886285 values:  -53.60192 ----- \n",
      "\n",
      "-----iteration:  3-----iteration:   target diff: 18  0.0028095463993440192target diff:   values:  0.0017692750278932075-53.60538 values:   -53.618202-----  \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  29 target diff:  0.0017439613000067057 values:  -60.41978 ----- \n",
      "\n",
      "-----iteration:  45 -----iteration: target diff:   0.00145288898669178874  values:  -58.493008target diff:   -----0.002023029578668075 values:   \n",
      "-53.62089\n",
      " -------------------------  ckpt: \n",
      " \n",
      "40000 --------------------\n",
      "-----iteration:  30 target diff:  0.002581603687974753 values:  -60.464085 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " 31\n",
      " target diff:  0.00254459332879091 values:  -60.450157 -----iteration: -----  \n",
      "5\n",
      " target diff:  0.0020468299784846583 values:  -53.69431 ----- \n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  19 target diff:  0.0019003929413229956 values:  -53.637997 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0018312089919909269 values:  -60.456673 ----- -----iteration: \n",
      " \n",
      "6 target diff:  0.002646575780433243 values:  -53.685547 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023970133377772414 values:  -53.74985 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  33 target diff:  0.0018212272513124688 values:  -60.423794 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0018585839528363847 values:  -53.58094 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0029023421257933033-------------------------iteration:   fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "21 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelvalues: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kerneltarget diff:  \n",
      "-53.772156WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias  \n",
      "-----0.001754365780899601WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.  \n",
      "\n",
      "values:  -53.497837\n",
      " ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9191669046099283 values:  -53.909077 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002341470708165787 values:  -60.41565 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004843933813351539 values:  -53.92478 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023999314565627023 values:  -53.80055 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0028687362712783116 values:  -53.473446 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003896803891352887 values:  -53.88816 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0022384270736506198 values:  -60.352417 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019680432702959437 values:  -53.817726 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0032733958218087596 values:  -53.96401 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0020292530818290127 values:  -53.52128 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0022731020704226924 values:  -60.34969 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.004113291676482102 values:  -54.11318 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016614170847609195 values:  -53.921078 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0022145642066273845 values:  -53.5574 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025736093220977865 values:  -54.27128 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0021531231719541556 values:  -60.30749 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002433667036641962 values:  -53.490593 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0029068460143303206 values:  -53.894253 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002960821450860492 values:  -54.260456 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0018266084619137555 values: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " -60.3034-----iteration:   -----7  \n",
      "target diff:  \n",
      "0.0026171369825007612 values:  -54.330654 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002147059705199065 values:  -53.94727-----iteration:  26  ----- target diff: \n",
      "\n",
      " 0.0020638735493993757 values:  -53.4443 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0029938455464815247 values:  -54.240414 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002088836800399064 values:  -60.318123 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002381509087666205 values:  -53.965828-----iteration:   -----27  \n",
      "target diff: \n",
      " 0.001989603035903328 values:  -53.387623 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.003571610586094378 values:  -54.24753 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9208222014516206 values:  -60.718906 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002657521603403096 values:  -54.004787 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020657784187171806-----iteration:   values:  28-60.283813  target diff: -----  \n",
      "0.0017929553761178536\n",
      " values:  -53.436825 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002014133204152571 values:  -54.07662 ----- \n",
      "\n",
      "-----iteration: -----iteration:   1 target diff:  0.002570607723326959 16values:   target diff: -60.75504  0.0016552493554873949-----  values: \n",
      " \n",
      "-53.988308 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0018489103036196193 values:  -60.243633 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0026301744787268068 values:  -54.15111 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002522369918822854 values:  -53.319977 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002732274208823369 values:  -60.783054 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022833454139701117 values:  -54.22788 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0016466322114378417 values:  -60.237206 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002053350398959796 values:  -54.00312 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021869111132072462 values:  -53.272335 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002233183578357414 values:  -60.715057 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0022792419167188566 values:  -----iteration:  -54.2343518  -----target diff:  \n",
      " \n",
      "0.0021645395002030474 values:  -54.064472 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0019131709324699572 values:  -53.22901 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0021147787221552487 values:  -60.246227 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024764051356950807 values:  -60.739872 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002855384262599349 values:  -54.0953 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019158127290942984 values:  -54.341587 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0019436133133729553 values:  -53.15765 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0018941378298002534 values:  -60.208866 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016872650301474165 values:  -60.78011 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  20 15 target diff: target diff:  0.002741090934205982  0.0017961392273786484values:   values: -54.141636  -54.402588-----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  33 target diff:  0.00214288132571361 values:  -53.096992 ----- \n",
      "\n",
      "-----iteration:  21 -----iteration: target diff:   160.0026617838232576544  target diff: values:   0.0016894343978074919-54.12365  values:  ------54.404297 -----iteration: \n",
      "  \n",
      "45----- target diff:   \n",
      "\n",
      "0.0025103687321093035 values:  -60.21764 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0018962396995956916 values:  -53.122246 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002301233965725784 values:  -54.146187 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021129687964803103 values:  -54.519 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0017620970333953004 values:  -60.236145 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015164162281855911 values:  -60.793304 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0018430688792930585 values:  -53.06283 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002412840692830461 values:  -54.148785 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002679936363664202-----iteration:  7 target diff:   0.002490448116976807values:   values: -54.59898 ----- -60.75568 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019672368933110035 values:  -53.02973 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0021805013286377785 values:  -60.232124 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0017339009827870792 values:  -52.98362 ----- \n",
      "-----iteration: \n",
      " 8 target diff:  0.0018566514632933654 values:  -60.78576 ----------iteration:   24 target diff:  0.001961799403351779\n",
      "\n",
      " values:  -54.146564 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0029589708079761565 values:  -54.59676 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0017044351284942374 values:  -60.242626 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0018605214396737548 values:  -52.89163 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0029485091185021766 values:  -54.125854 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002009082213637421 values:  -54.62679 ----- \n",
      "\n",
      "-----iteration:  49-----iteration:   39target diff:   0.0020990416850558747target diff:   0.001974803307388274values:   values: -60.196404  ------52.861324  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  26-----iteration:   9target diff:   target diff: 0.002854060427718174 0.0015358465877642331 values:   -60.72515values:   ------54.111668  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  21 target diff:  0.002026927836330246 -----iteration:  values:  50-54.6773  target diff:  0.0017231835031017663----- values:   \n",
      "-60.170143\n",
      " ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002220006500863188 values:  -60.768314 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.00241073937971576 values:  -54.1081 ----- -----iteration: \n",
      "\n",
      " 40 target diff:  0.0016996813688636423 values:  -52.743183 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0020367522903618636 values:  -54.697884 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0018486227128642345 values:  -60.141487 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0025902639550146344 values:  -54.12115 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0022202164122175276 values:  -52.699627 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0027597317371234214 values:  -60.701687 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002188827169909907-----iteration:   values: 42 -54.12583  target diff:  0.0017772624097163589-----  values: \n",
      " \n",
      "-52.675446 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002134625373465675 values:  -54.763943 ----- -----iteration: \n",
      " \n",
      "52 target diff:  0.001583177727139488 values:  -60.148846 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0027034595710613172 values:  -54.14173 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.001681868172011148 values:  -52.632214 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018456950995350758 values:  -54.98999 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002519865556149636 values:  -60.69852 ----- \n",
      "\n",
      "-----iteration:  31 -----iteration:  target diff: 44  0.002718787815052773target diff:   0.0015265483779025864values:   values:  -52.570198-54.140656 ----- ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  53 target diff:  0.0014889452111308623 values:  -60.13664 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0030133650659430757 values:  -55.01154 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002083067160143048 values:  -60.697216 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0024285870400582717 values:  -54.153664 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0016146026287155054 values:  -52.515503 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0015942485873509057 values:  -54.925816 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002334306845053815 values:  -60.709343 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002878242191382121 values:  -54.07596 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002491501406026284 values:  -60.757915 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0021120584626207464 values:  -52.42458 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0022668948017176703 values:  -54.025043 -----iteration:  -----27 \n",
      " \n",
      "target diff:  0.0019949734077434637 values:  -54.846287 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0024243941829486383 values:  -60.771385 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002422028570878306-----iteration:   values: 47  -54.89568target diff:   0.0018724848612551271-----  \n",
      "\n",
      "values:  -52.401577 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0026416803796150776 values:  -53.912506 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0019529798264232908 values:  -52.374363 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002672153134276043 values:  -54.864235 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.003314745535899025 values:  -53.786175 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0022774382873012497 values:  -54.79678 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0015315173819986255 values:  -52.3245 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0025058135417680427 values:  -53.72862 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  17 target diff:  0.0024056632876973145 values:  -60.816624 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002110942220668655 values:  -54.71654 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0028515928599608486 values:  -53.640728 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0019594446002077597 values:  -52.183353 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9213622140817258 values:  -57.16436 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0019994845447659864 values:  -54.64266 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0018422857644097323 values:  -53.54237 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002428198343524346 values:  -60.861626 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030860168124389616 values:  -57.221333 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.00284216325595562 values:  -53.482693 ----- \n",
      "\n",
      "-----iteration: -----iteration:   5133 target diff:   target diff: 0.00211628209701966  0.0018918181671942161 values:  -54.587833values:   -52.07456----- ----- \n",
      " \n",
      "-----iteration:  2\n",
      "\n",
      " target diff:  0.002888817870990587 values:  -57.20804 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.002007092216555518 values:  -53.405514 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0018341181554680527 values:  -52.060894 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026473147899322477 values:  -57.20048 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002090509436990452 values:  -54.57842 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0026708867760875028 values:  -60.91403 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0024040329681814074 values:  -53.392414 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002316999114739428 values:  -57.248425 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.001547034753026142 values:  -51.976315 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019821889999639946 values:  -54.505615 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0018957835218993996 values:  -53.4083 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002103532400216334 values:  -57.295036 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003430512988864459 values:  -60.92007 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0025478209650652015 values:  -53.36781 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0018690146505527024 values:  -54.513714 ----- -----iteration: -----iteration:   654 \n",
      "\n",
      " target diff:  target diff: 0.0027728484918160393 values:  0.0017313125179654059  -57.333035values:   ------51.95277  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0023124959147207457 values:  -53.384155 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0017829096587693544 values:  -51.996265 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018658733932307814 values:  -57.36329 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.001999330674766556 values:  -54.500637 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002635849883457118 values:  -53.333942 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015859978620915679 values:  -57.39034 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0018205886621002387 values:  -51.874046 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002394095201634233 values:  -53.306744 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001751642116504849 values:  -57.372078 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017907192636571168 values:  -54.537422 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002933357863516794 values:  -61.09274 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0027881533857433654 values:  -53.31028 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002229168123616465 values:  -57.407665 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0018831380764639369 values:  -----iteration:  -54.50978557 ----- \n",
      " target diff: \n",
      " 0.0019020995534096644 values:  -51.81958 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.004947808038688607 values:  -61.09143 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0025700590289825724 values:  -53.28888 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018686779074981884 values:  -57.46526 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0019101864368193272 values:  -54.403645 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002000585854502729 values:  -53.318546 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0027586034106937994 values:  -61.06735 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0018467429317139269 values:  -51.780586 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016470963130565935 values:  -57.491116 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0022236474558138372 values:  -54.39643 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0024909446580387426 values:  -53.24252 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002361851630606862 values:  -61.167873 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018335625605782069 values:  -57.54122 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  42 target diff: 59 0.0020024284817766053 values:   target diff: -54.3477  0.0017385696145016997-----  values: \n",
      "\n",
      " -51.758877 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0021906525005614217 values:  -53.245598 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002524269938858663 values:  -57.596966 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0030207793399888673 values:  -61.09402 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0018941396428450946 values:  -51.707573 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002550045442201178 values:  -53.265144 ----- \n",
      "\n",
      "-----iteration:  15 target diff: -----iteration:   0.0017429156564559133 43values:   target diff:  -57.651680.0015115749313004496 values:  -54.319424  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  26 target diff:  0.0023538321874862866 values:  -61.049103 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0016741332908421901 values:  -51.707092 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0019073828435070476 values:  -53.286797 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.001574718851775884 values:  -54.275173 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0014348940947882527 values:  -51.677765 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "-----iteration:  27 target diff:  0.0022264432583111726 values:  -61.03 ----- \n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias55\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "0.0019970141457707224WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "values:  -53.310078 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  45 target diff:  0.0017946039100985877 values:  -54.169075 ----- \n",
      "\n",
      "-----iteration:  16 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "target diff: Refresh buffer every 1000000 sampling! \n",
      "0.0031569880156931164 values:  -57.693966 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!-----iteration: \n",
      " 28 target diff:  0.0028382982879409956 values:  -61.012882 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  56 target diff:  0.0019175466403168891 values:  -53.3283 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  46WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "target diff:  0.0019393321970156028 values:  -54.091137 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  17 target diff:  0.002800987258465986 values:  -57.750042 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0018240477649481951 values:  -53.300663 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002346975364582963 values:  -60.96538 ----- \n",
      "\n",
      "-----iteration:  47 -----iteration: target diff:   0.001722156796843668218  values: target diff:   -54.0887530.0026625725779674076 -----  \n",
      "\n",
      "values:  -57.796963 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002364197756179389 values:  -53.32373 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0032246535093510328 values:  -57.834137 ----- -----iteration: \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 target diff:  0.0015294479226389828 values:  -54.029778 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002339934709221533 values:  -53.363415 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001987061326513156 values:  -60.984486 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002060331306097531 values:  -57.87492 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002504922647074338 values:  -53.423553 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0019596935037315515 values:  -54.050903 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0024739657194769323 values:  -61.028282 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0033232151452463926 values:  -57.89704-----iteration:   -----61  target diff: \n",
      " \n",
      "0.0024460353329951194 values:  -53.441414 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel50\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biastarget diff: \n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.001840135739157164\n",
      " values:  -53.97611 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00241932334255551-----iteration:   values:  62 target diff: -57.96894  0.0017318034616872742 values:  -53.487385-----  \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  32 target diff:  0.0018501106222071461 values:  -60.997322 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0026251989468706613 -----iteration:  63 target diff:  0.001641707332026309 values:  -53.488945 ----- \n",
      "\n",
      "values:  -58.033245 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0017514521358345083 values:  -53.93275 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0030291851713706228 values:  -58.087463 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.001987187349872594 values:  -53.46082 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002544734710020782 values:  -60.990284 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0021615168283771976 values:  -58.139423 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0019061887890114042 values:  -53.96209 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0017792864801837852 values:  -53.450928 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022661600786635034 values:  -58.172356 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.001790205149642962 values:  -53.92508 ----- \n",
      "\n",
      "-----iteration: -----iteration:  66  34target diff:   0.001569259763867226target diff:   values:  0.0026660092780307005-53.510376 values:   ----- \n",
      "-60.94672\n",
      " ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002433672876753513 values:  -58.227722 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.00203935819758739 values:  -53.891468 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0014811240193911078 values:  -53.5426 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0019705588663173363 values:  -58.274326 ----- \n",
      "\n",
      "-----iteration:  55-----iteration:   target diff: 35  0.0021126596472124375target diff:   values: 0.002845488674342689 values:   -53.85932-60.921387  ----- \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0022835508427468676 values:  -58.339417 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0015604869185052081 values:  -53.84742 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0028116159310528784 values:  -60.865086 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  30 target diff:  0.0027058774922284917 values:  -58.395237 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0019522782973922055 values:  -53.776512 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019004550941955941 values:  -60.87277 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0016507895797807023 values:  -53.72129 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002055683207685663 values:  -60.887016 -----iteration: -----  0\n",
      " \n",
      "target diff:  0.9222970484232274 values:  -53.787884 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0017231377203227134 values:  -53.646626 ----- \n",
      "\n",
      "-----iteration:  31-----iteration:   target diff: 39  0.002817035194135589target diff:   values: 0.0022400159216210227 -58.46099 ----- \n",
      " \n",
      "values:  -60.8614 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003684136509648851 values:  -53.823128 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0016528658953400294 values:  -53.592144 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002502660519163805 values:  -58.551678 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0019324674418215815 values:  -60.88256 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0018931414666016738 values:  -53.56656 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0035913288377963123 values:  -53.817196 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0027063429895759186 values:  -58.600185 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.00237425649380825 values:  -60.818275 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0017901575419848733 values:  -53.466705 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025065406173953625 values:  -53.759617 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  34 target diff:  0.002483436000600627 values:  -58.618134 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0017820084168260343 values:  -53.400063 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002244019410699649 values:  -60.80947 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028280412863122 values:  -53.694767 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019100480182881337 values:  -58.63084 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0019199931881614674 values:  -53.348606 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9224258366904932 values:  -52.94085 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0022875283587084102 values:  -60.716892 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021063000013382353 values:  -53.753025 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0020019691336420242 values:  -53.267544 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0035613125684200914 values:  -----iteration: -52.952168 36 target diff:   0.00215491788560319-----  values:  \n",
      "\n",
      "-58.683716 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002464458903360981 values:  -60.61668 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023006757383786797 values:  -53.73736 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0018757213679593745 values:  -53.228096 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.001869686822628541 values:  -58.68944 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0032144123240793274 values:  -52.978123 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0024208730459447806 values:  -60.52014 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001809312799867411 values:  -53.795715 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0018911844796513605 values:  -53.181152 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017261065188582255 values:  -58.739086 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002064561565211178 values:  -60.400295 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002968392927285763 values:  -52.958004 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023744976073455087 values:  -53.74366 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0024558304969650438 values:  -58.74128 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0018009023112521621 values:  -53.157642 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.001993001370148303 values:  -60.30536 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0029133857836358347 values:  -53.01108 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.001742984266804561 values:  -58.729424 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020541422988255543 values:  -53.73923 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0017978333839345861 -----iteration: values:   69-60.20172 target diff:   -----0.0018549419489479857  values: \n",
      " -53.130554\n",
      " ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002859473982495663 values:  -53.026768 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0021100258345493387 values:  -53.11685-----iteration:  -----  49\n",
      " target diff: \n",
      " 0.0020217946869033956-----iteration:   values: 41  -60.086983target diff:   0.002313248660116598 values:  -58.732964 ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  10 target diff:  0.0016179710623466519 values:  -53.683475 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.001797909315086541 values:  -----iteration:  71-59.97054  target diff:  ----- 0.0021624892525265588\n",
      " values: \n",
      " -53.125088 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0026418052608742173 values:  -58.82624 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0021360315996857356 values:  -53.0864 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018029834738530917 values:  -53.71344 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0018443277198070408 values:  -53.072624 -----iteration:  ----- \n",
      "\n",
      "51 target diff:  0.001966646006769286 values:  -59.89167 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0028237179389500925 values:  -53.13611 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.00233471539522816 values:  -58.81313 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.001975225458103329 values:  -59.78237 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002131452373936926 values:  -53.164116 ----- \n",
      "-----iteration: \n",
      " 12 target diff:  0.0018912037857760462 values:  -53.725216 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0015843807006398255 values:  -58.878357 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0020798919381555393 values:  -53.127827 ----- \n",
      "\n",
      "-----iteration: -----iteration:   5313  target diff: target diff:  0.002221662374160857 0.002047074042780817 values:   -----iteration: -53.669502values:   -----  -59.6753 \n",
      "9 -----\n",
      " target diff: \n",
      " \n",
      "0.0026034432035947097 values:  -53.18333 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.002216984718406951 values:  -53.12283 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0022497382954526903 values:  -58.88085 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0018829601537737745 values:  -59.669773 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0023009784979262705 values:  -53.608585 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0017251876238475652 values:  -53.056396 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020263990458452225 values:  -53.108616 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002154868939154191 values:  -59.502583 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003438125311147584 values:  -58.89517 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0020542393781156107 values:  -52.995014 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0022369635456610205 values:  -59.396824 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0023873322592032785 values:  -53.5497 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0020795993838420962 values:  -58.91755 ----- \n",
      "-----iteration:  \n",
      "11 target diff:  0.002097322905061062 values:  -53.122185 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0018998379474449453 values:  -52.959476 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0022218492520118954 values:  -59.337654 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002374462945941746 values:  -53.488987 ----- \n",
      "\n",
      "-----iteration:  48 target diff: -----iteration:   0.001713592574183592712  values: target diff:   -58.9034960.0018710284057554065  values: ----- -53.135715 \n",
      " ----- \n",
      "\n",
      "\n",
      "-----iteration:  78 target diff:  0.0017863197820666185 values:  -52.940605 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0019275092504046636 values:  -59.22802 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001970249768685157 values:  -53.50226 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0015534589980532188 values:  -53.25413 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.001475509317779751 values:  -58.921352 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----iteration: \n",
      " 79WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      " target diff:  0.0017653778528299276WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "-52.918293WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  18 target diff:  0.0026679826932424753 values:  -53.448215 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  59 target diff:  0.0020987608154393374Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling! \n",
      "values:  -59.101383 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.0034507224663817334 values:  -53.308056 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  80 target diff:  0.0017238493672836089 values:  -52.856426 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  60 target diff:  0.001899072472808381 values:  -58.996613 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  -----iteration: 0.001749773151937122  15values:   target diff:  0.0024807599724791405 values:  -52.79532-53.31573 ----- \n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002192201733096508 values:  -53.30776 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0017023984108965533 values:  -58.867977 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0018600109078086462 values:  -52.75531 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0015590101271327167 values:  -53.21549 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.001759637089005624 values:  -----iteration:  -58.7427383  ----- target diff:  \n",
      "0.0018166113037313997\n",
      " values:  -52.698296 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002758308965396578 values:  -53.299934 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0030789319518668592 values:  -53.175747 ----- \n",
      "\n",
      "-----iteration: -----iteration:   8463  target diff:  target diff: 0.001714537733186796  0.0016866839331106823values:   values:  -52.6664-58.612904  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  21 target diff:  0.002071057587219199 values:  -53.268562 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0022953395712292826 values:  -52.579002 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.003032531966885333 values:  -53.138794 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0016089730775938305 values:  -58.460888 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.001843737289609775 values:  -52.52201 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-----iteration:  \n",
      "65WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:   target diff: 19  target diff:  0.0023477149502493480.002896954554821622  values: values:  -58.37193 -53.08264  ---------- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  22 target diff:  0.0018111822171741185 values:  -53.294697 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0018361252877898279 values:  -52.421345 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0017696499393500616 values:  -58.275948 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003226853639175961 values:  -53.079872 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.002280228794045464 values:  -52.410725 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0025741286957528726 values:  -53.10389 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0017964637572314554 values:  -58.272984 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002019267808954799 values:  -53.312237 ----- -----iteration: \n",
      "\n",
      " 89 target diff:  0.0018536835928664906 values:  -52.409992 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002353330610613684 values:  -53.181248 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002482179305950464 values:  -58.23626 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0015902202545247728 values:  -52.368305 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0020686847896652237 values:  -58.186733 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0019135857146390844 values:  -52.334354 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0032099827159383907 values:  -53.151833 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.001949957979469887 values:  -53.16836 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.001934585639811136 values:  -58.196507 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0024481296527582136 values:  -53.17879 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0020636042021121167 values:  -52.319668 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0025488136812831593 values:  -53.20104 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.001954012384154176 values:  -52.285313 -----iteration:  ----- 71 target diff: \n",
      "\n",
      " 0.0021597189951146484 values:  -58.21223 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  25 target diff:  0.0021076383252762935 values:  -53.269146 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0024248789246907217 values:  -53.194405 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.001984948975408638 values:  -52.314724 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0022084097777106486 values:  -58.12835 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0020420580356023703 values:  -53.192043 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.921473950820607 values:  -58.640392 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0020840711599129863 values:  -53.245308 ----- -----iteration: \n",
      "\n",
      " 95 target diff:  0.0020728928958681065 values:  -52.274998 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0018477204215494839 values:  -58.090584 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004535778190786674 values:  -58.66898 ----- -----iteration: \n",
      "\n",
      " 27 target diff:  0.0016181718797306328 values:  -53.100742 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.001911627621408588 values:  -52.232876 ----- \n",
      "\n",
      "-----iteration:  74-----iteration:   28target diff:   0.0016463005889032617target diff:  values:  -58.04775  ----- \n",
      "\n",
      "0.0029999186062697014 values:  -53.249256 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0033707187793032218 -----iteration: values:   -58.673328  -----target diff:  0.0018627121478160934  \n",
      "\n",
      "values:  -53.110874 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0018505632020815576 values:  -52.183044 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0015989289169662788 values:  -58.01654 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002511837994856155 values:  -58.65279 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0023731988632362784 values:  -53.14373 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002596795055034639 values:  -53.232563 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.00176250319245649 values:  -52.146492 ----- \n",
      "\n",
      "-----iteration:  4 target diff: -----iteration:  76 target diff:   0.001594343694990876 values:  0.0032391707557426932 values: -58.00525 -58.684875 -----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  99 target diff:  0.0017144779342412395 values:  -52.152058-----iteration:   -----30 \n",
      " target diff:  0.0024693576218461364\n",
      " -------------------- values:  -----iteration: -53.216663  ckpt: -----30   35000 target diff: \n",
      "-------------------- 0.0018600287829049235\n",
      " values:  -53.042213 ----- \n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  77 target diff:  0.001541794788326081 values:  -57.910896 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  5 target diff:  0.0018443053043832923 values: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling! \n",
      "-58.766926 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  31 target diff:  0.001813048463334745 values:  -53.02824 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  6 target diff:  0.003918239193198889 values:  -58.78934 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0020560291448363396 values:  -53.186188 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0016076786235321554 values:  -57.89405 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017639585171920344 values:  -58.804356 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002857092021630803 values:  -53.176235 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0014299236702653522 values:  -57.89249 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019659983169241727 values:  -58.88802 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.001721768619795588 values:  -52.99157 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002476673361120761 values:  -58.914837 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001684560157013988 values:  -----iteration: -52.935368  33-----  target diff: \n",
      " \n",
      "0.0018737543266481318 values:  -53.14748 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022308097272252907 values:  -58.95892 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0030473039602252963 values:  -58.930676 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.001290009211106016 values:  -52.933952 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0037365018301905805 values:  -53.16698 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration:  12\n",
      " target diff:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias0.001983440128227043\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-58.958576\n",
      " ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0023808223899346973 values:  -58.98098 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002872270706349499 values:  -53.158474 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0022256750674761665 values:  -59.04748 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  15 target diff:  0.0030093986051308876 values:  -59.101467 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9192244020653575 values:  -61.194614 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.003619013400637329 values:  -53.154316 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0023919448668677534 values:  -59.11554 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0032532106225396755 values:  -61.166405 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002032165672998555 values:  -59.15128 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.003198314763119462 values:  -53.17465 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029046722655338138 values:  -61.122566 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  38 target diff:  -----iteration:  3 target diff:  0.002017370973662599 values:  -61.124146 ----- \n",
      "\n",
      "0.002362730092847956 values:  -53.226776 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0027338317662938378 values:  -59.115623 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.003084469719593804 values:  -59.153442 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9186259280918044 values:  -54.37718 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9217475314418863 values:  -53.448505 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023004519904891245 values:  -61.134712 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002530821995553461 values:  -53.23013 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0032618414678079128 values:  -54.383507 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003737931409808215 values:  -59.157696 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024492897356573236 values:  -61.10267 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0024096047636466464 values:  -53.542393 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002436501301381507 values:  -54.443363 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017684074433732832 values:  -61.147198 ----- \n",
      "\n",
      "-----iteration:  40-----iteration:   21target diff:   target diff:  0.00257627413765649640.0026661647858559068  values: values:   -59.139183-53.217976  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  2 target diff:  0.0018687041647984597 values: -----iteration:   -53.5412523  -----target diff:   \n",
      "0.0025117134829095596\n",
      " values:  -54.53637 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018664955008132712 values:  -61.08621 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021267170903248437 values:  -53.50906 ----- \n",
      "-----iteration: \n",
      " 41 -----iteration: target diff:  4 0.0023686548886997392 values:  -53.234043 ----- \n",
      "\n",
      " target diff:  0.0022114823463937495 values:  -54.524036 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023994142590529873 values:  -61.074097 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0031134267654216985 -----iteration:  values:  4-59.157658  target diff: -----  0.002364264566725447\n",
      " \n",
      "values:  -53.428524 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002160634577257236 values:  -54.61288 -----iteration:  42----- \n",
      "\n",
      " target diff:  0.0028268704476718275 values:  -53.264507 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017511407863671875 values:  -53.39307 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0022232681944907356 values:  -53.28144 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0014482212276795278 values:  -61.10462 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "-----iteration: -----iteration:  23  6target diff:  0.0029604201529490125  values: target diff:   -59.20215 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "0.001937263019603801Refresh buffer every 1000000 sampling! \n",
      "values: \n",
      "\n",
      " -54.629116 ----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "6WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel target diff:  0.0017729722541191617\n",
      " values:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-53.37139\n",
      " ----- \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration: \n",
      " 44 target diff:  0.0018326348382388014 values:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-53.313557 \n",
      "----- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  7 target diff:  0.001806598656489367 values:  -54.663208 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!\n",
      "\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  45 target diff:  0.002060548533562171 values:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-53.328266\n",
      " ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017477107828386268\n",
      " values:  -53.346844 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0017835578361121156 values:  -59.23896WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  46 target diff:  0.002062191258593825 values:  -53.331688 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021277270028927935 values:  -54.718697 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002334922846708918 values:  -53.323883 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002197961795968897 values:  -59.246914 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0016121429908012674 values:  -53.337288 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022237426970343707 values:  -54.703114 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019883542803122126 values:  -53.30718 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017852031246540483 values:  -54.748104 ----- \n",
      "\n",
      "-----iteration:  48-----iteration:  target diff:   0.00181704261897260510  values: target diff:  0.0019907966686383794  -53.319183 values: -----  \n",
      "\n",
      "-53.24918 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale -------------------------iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel26\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel 0.0022092341529401645\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      " -59.164055 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0022582292858756873 values:  -54.752342 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020091986871243455 values:  -53.33681 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.001791944837485021 values:  -53.34931 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003559345718539904 values:  -59.202305 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002565741009297152 values:  -53.266705 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0017131674371066526 values:  -53.384365 ----- \n",
      "\n",
      "-----iteration: -----iteration:   2813  target diff:  target diff: 0.0029200377478981144  0.001339922797679131 values: values:   -53.217888 ------59.177467 ----- \n",
      "\n",
      " \n",
      "--------------------\n",
      " ckpt:  40000 --------------------\n",
      "-----iteration:  12 target diff: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling! 0.00203361475763026\n",
      " values:  -54.90285 ----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel51\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biastarget diff: \n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0018642743612938533 \n",
      "values:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-53.421455 ----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  13 target diff:  0.003091840426968104 values:  -54.902496 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  29 target diff:  0.00216692793351242 values:  -59.141144 ----- WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  52 target diff:  0.0015215242768888164 values:  -53.4493 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  30 target diff:  0.001958533326062768 values:  -59.156666 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.001427013256235968 values:  -53.472992 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-----iteration: \n",
      " 14 target diff:  0.0018824789108291683 values:  -54.971348 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  31 target diff:  0.0021832574955809167 values: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "-59.13561 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  15 target diff:  0.0020334412436745527 values:  -55.01513 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  16 target diff:  0.0018021506452123599 values:  -55.00828 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002589110795180976 values:  -59.124966 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001812389793812091 values:  -55.014996 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0015495488325058336 values:  -59.167053 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9201794072323332 values:  -61.139748 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018947481034063815 values:  -54.960815 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0031948798479416026 values:  -59.213257 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021332991445279378 values:  -61.111782 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002643182219651548 values:  -55.036617 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.0016900351780137002 values:  -61.168858 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002263594953936394 values:  -59.16889 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0020268735089161625 values:  -55.025658 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0015775180650362635 values:  -61.17721 ----- \n",
      "\n",
      "-------------------- -----iteration: fqe on dqn & sale  21-------------------- \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "0.0014445122984127507 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-55.038883 \n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-----iteration: \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. 36\n",
      " target diff:  0.0020972505220380588 values:  -59.181973 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0016677493809799339 values:  -61.1623 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0024504561456548456 values:  -59.172115 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0016786482298196278 values:  -59.177284 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001607515176869249 values:  -61.23286 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022433704067204028 values:  -61.1817 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.001695238382008962 values:  -59.14688 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016715135640574137 values:  -61.20322 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  40 target diff:  0.0024729083355604945 values:  -59.120808 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002410148106175958 values:  -61.186245 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0022774666080365357 values:  -59.154438 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023957981978796204 values:  -61.153984 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9219969190096404 values:  -52.751133 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  10 target diff:  0.0017559873834887487 values:  -61.141113 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002101525313678456 values:  -59.16642 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025575020998298862 values:  -52.83502 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016576134456087327 values:  -61.1037 ----- \n",
      "\n",
      "-----iteration: -----iteration:   430  target diff: target diff:   0.92352649861784470.002023375235172026  values: values:   -59.147346-52.88391  ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  0 target diff:  0.9191055710424619 values:  -51.917583 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001775504146244404 values:  -61.06562 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 1  44target diff:   0.002815261879732808target diff:   values: 0.002153000581782769  values: -52.955444  -59.127228-----  -----\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  1 target diff:  0.0046734525455108525 values:  -52.064575 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0022066919708790015 values:  -52.915585 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025064064906466436 values:  -53.052235 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002391455710840779 values:  -61.029053 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0034595654977771203 values:  -52.250725 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.001707445296301987 values:  -59.136684 ----------iteration:   3\n",
      " \n",
      "target diff:  0.0023264521654421336 values:  -52.88781 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021961257980908947 values:  -53.01093 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002927149977396502 values:  -52.386677 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018887950573099332 values:  -61.038757 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002228157826776786 values:  -59.06311 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0026961831102714435 values:  -52.65743 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002545879722025919 values:  -52.81297 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0025075707858689495 values:  -53.03692 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  -----iteration:  0.003273485685001241515  target diff: values:   -52.731686 0.0018017991908897241----- values:   \n",
      "-60.994053\n",
      " ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002284039953814491 values:  -59.03023 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  5 target diff:  0.0024230544190009507 values:  -52.751045 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002355858797070875 values:  -53.020336 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018707574776515635 values:  -52.75614 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  1648  target diff: target diff:  0.00208875477607151 0.0019028704195085712  values: values:   -59.040535-60.981976  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  6 target diff:  0.0020376528420101405 values:  -53.069675 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0026534959911786297 values:  -52.841587 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0021748585845711675 values:  -59.012268 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00253945245416272 values:  -53.153233 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019000969509436992 values:  -52.76996 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002605667718853732 values:  -53.10599 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002057107108841408 values:  -60.980377 ----- \n",
      "\n",
      "-----iteration: -----iteration:  8  50target diff:   0.0018547822431474522target diff:   0.001674405673474537 values:  -53.159756 values: -----  \n",
      "-59.028477\n",
      " ----- -----iteration: \n",
      " \n",
      "7 target diff:  0.0019917230312702728 values:  -53.031963 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0031467562225741675 values:  -53.264473 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002356615996032676 values:  -59.088932 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0012901961696562627 values: -----iteration:  -53.205494 ----- \n",
      " 10\n",
      " target diff:  0.0023622582605270018 values:  -53.35144 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0022205737849238143 values:  -60.937233 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.003894410371259359 values:  -52.941216 ----- \n",
      "\n",
      "-----iteration:  52 -----iteration: target diff:  11  target diff: 0.0018053086211499538  0.002464720692189182values:   -59.041492values:   -53.292866-----  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001597520376194763 values:  -52.806786 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0024016473865243423 values:  -53.38722 ----- \n",
      "\n",
      "-----iteration:  53 target diff: -----iteration:   190.0026554796834721297 target diff:   values: 0.0023215925205073624  values:  -60.861572 ----- \n",
      "\n",
      "-59.011528 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019909960244793214 values:  -----iteration:  -53.50030510 target diff:   0.002065122562879569-----  values: \n",
      " -52.8451\n",
      " ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0021454290881551615 -----iteration: values:   -60.7622154 -----  target diff: \n",
      " \n",
      "0.0023924930788305383 values:  -59.01824 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019874005292277773 values:  -53.616302 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002397810179987505 values:  -52.930576 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0017100545860382955 values:  -59.034206 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002510385599982683 values:  -53.720436 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002148115908687259 values:  -52.957466 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0026952244838595626 values:  -60.74267 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020545736358942583 values:  -53.76641 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0018975241829037822 values:  -59.036736 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001923793563464195 values:  -52.942303 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001852177883538019 values:  -53.771175 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  22 target diff:  0.0020510621052784207 values:  -60.727753 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0020325460063553642 values:  -59.05309 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001407813018829603 values:  -52.97268 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002474795481018597 values:  -60.6301 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.001672377333605882 values:  -59.05129 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.001906501312456677 values:  -53.808105 ----- \n",
      "\n",
      "-----iteration:  0 target diff: -----iteration:  59  target diff: 0.9226966589712228 0.0013716428576163284 values:   values:  -59.034817 ------52.390625  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002113107660849798 values:  -53.84472 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0026786758047880714 values:  -60.689827 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0039240311711163855 values:  -52.45876 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003582955491956084 values:  -52.408375 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002713314901763865 values:  -52.427826 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0028508426687346247 values:  -60.657818 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003036906382090934 values:  -53.832336 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00247910314056924 values:  -52.49054 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025592014960002323 values:  -52.50729 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002538381011651535 values:  -53.949482 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.0022772137371829056 values:  -52.549847 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002669160768983871 values:  -60.689823 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001995605445734939 values:  -52.57257 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002995981820694968 values:  -53.93579 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015308846358004602 values:  -52.686375 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  -----iteration:  0.92034546194737723  values:  target diff:  -52.638123 0.002451886116917819----- values:   \n",
      "-53.92547\n",
      " ----- \n",
      "\n",
      "-----iteration:  9 target diff: -----iteration:   0.0033433285115835655 values:  -52.69058 27 target diff:  0.0025335430479180854 values:  -60.61306 ----- \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038118698567202285 values:  -52.613926 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0024398982016562596 values:  -----iteration: -53.906067  10-----  target diff: \n",
      " \n",
      "0.0020880250943064926 values:  -52.71103 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.921925208589855 values:  -58.038002 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0024964028357330466 values:  -----iteration:  11-53.946323  target diff: -----  0.0016076946333570053\n",
      " \n",
      "values:  -52.77465 ----- \n",
      "\n",
      "-----iteration:  28-----iteration:   target diff:  0.0023579131804678474 values:  2 target diff: -60.492565  ----- 0.0031881520844959485\n",
      " values: \n",
      " -52.631664 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005733060450856637 values:  -58.089832 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002325352686541499 values:  -54.049473 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0031121977594212075 -----iteration:  12values:  target diff:  0.002380237132965485  values: -52.538574  ----- -52.74168 \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003423268855168378 values:  -58.13551 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021532682566777336 values:  -52.418083 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0030278331693325243 values:  -58.184002 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002317985214576685 values:  -52.753483 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0020993802905523704 values:  -54.043873 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022497484648437566 values:  -52.228558 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002553122152959773 values:  -60.31913 -----iteration:  -----4 target diff:  0.0026853886046187166  values:  -58.207886 \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration: -----iteration:  14 -----iteration: 6   28target diff:  0.0016738911246741348 values:  target diff:   -52.7893750.002734094635926107  -----target diff: values:   \n",
      "0.002311590476002302 \n",
      " values: -52.049805  -53.97351-----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  5 target diff:  0.0024298307277047216 values:  -58.236946 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002195547833413939 values:  -51.911823 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0029446006027458445 values:  -60.167133 ----- \n",
      "\n",
      "-----iteration:  15 -----iteration:  target diff: 6  0.0019995681449149214target diff:   values:  -52.8221440.0015296121157932906  values:  ------58.239483  \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  8 target diff:  0.0020888531818347537 values:  -51.86861 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002753890616909807 values:  -53.978306 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002429842699094207 values:  -58.253967 ----- \n",
      "-----iteration: \n",
      " 16 target diff:  0.0017170425235978482 values:  -52.80399 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002370709255589117 values:  -54.064045 -----iteration: -----  8\n",
      " target diff:  0.0020188582349599605 \n",
      "values:  -58.29566 ----- \n",
      "\n",
      "-----iteration:  9 target diff: -----iteration:  0.0015722736325259037  values: 31  target diff: -51.77268 0.0024994554034844917 -----  \n",
      "\n",
      "values:  -59.996548 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0025497620717633202 values:  -52.751095 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 10  31target diff:   target diff: 0.0014503375311050355  0.0021576689173306144values:  values:  -51.714336  -54.142982-----  -----\n",
      " \n",
      "\n",
      "-------------------- \n",
      "ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  9 target diff:  0.0019171814122775062 values:  -58.326794 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel-----iteration:  32 target diff:  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.002378637127857504\n",
      " values:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-60.04237\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias -----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  18 target diff: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 0.0016408515530953298 values:  -52.787083 ----- \n",
      "-----iteration:  \n",
      "10 target diff:  0.002144924689203675 values:  -58.37045 -----WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  32 target diff:  0.0019441509864410215 values:  -54.136333 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  33 target diff:  0.0018533289834121293 values:  -54.105038 ----- -----iteration:  33 target diff: \n",
      " 0.0032392776450663042 values:  -59.912197 \n",
      "----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019928290298740995 values:  -52.758728 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019796244223670703 values:  -58.40292 ----- \n",
      "\n",
      "-----iteration:  34 target diff: -----iteration:  34  target diff:  0.0021079931708956960.002134538757862125  values: values:   -54.075386-59.847404  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  20 target diff:  0.0024188625730112746 -----iteration: values:   12-52.800293  -----target diff:   \n",
      "0.002072025717017803 \n",
      "values:  -58.46699 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001746191761698712 values:  -54.115234 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018969189922078632 values:  -52.849052 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020486643647733616 values:  -58.526356 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019086239086328956 values:  -59.755795 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0016394288470290422 values:  -54.127197 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002504533781870518 values:  -58.54943 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  37 target diff:  0.00216922317341572 values:  -54.1163 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0021940819657966333 values:  -58.623257 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0020030079912686113 values:  -52.893776 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002226985588916353 values:  -59.728527 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0018912498741124161 values:  -54.111748 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0031528959437176294 values:  -58.686012 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  -----iteration: 0.002486202789649551  values:  23 -54.086254 target diff: ----- 0.002278776994025176  \n",
      "values:  \n",
      "-52.859356 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021024508623855 values:  -58.725945 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.003327323444524693 values:  -54.022915 ----------iteration:   24 \n",
      "target diff: \n",
      " 0.0020002872930391276 values:  -52.844273 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002282349194276657 values:  -59.59527 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0023822866164729824 values:  -58.77893 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.003103099978955898 values:  -54.01853-----iteration:   -----25 \n",
      "\n",
      " target diff:  0.0017854784865499191 values:  -52.823444 ----- \n",
      "\n",
      "-----iteration: -----iteration:  26 target diff:   190.00243408496836847 values:  -52.81646 target diff:   -----0.0023558301126545412 \n",
      "\n",
      " values:  -58.834663 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0031709343727415362 values:  -59.46128 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0029736197780422134 values:  -53.954327 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018712673629834504 values:  -52.802532 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0025696517601672447 values:  -58.859287 ----- \n",
      "\n",
      "-----iteration:  43 target diff: -----iteration:  0.003218724395425442  values: 39 target diff:   -53.945915 ----- 0.0020741169205734144\n",
      "\n",
      " values:  -59.275654 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.0023974475028312333 values:  -52.800407 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002558436942719344 values:  -58.887054 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0018334562724204983 values:  -59.100258 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0030262143557589025 values:  -52.767265 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0028239658574408166 values:  -53.971245 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0024183705236029023 values:  -58.89527 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017248276656781825 values:  -58.965725 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0032101400546619497 values:  -52.710632 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0022605504751091357 values:  -58.94469 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0028427438656151026 values:  -53.963875 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.001908541675640247 values:  -58.82415 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9243746888557013 values:  -52.277058 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0031025892262225075 values:  -52.68777 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0024175679752807405 values:  -58.959892 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0021373545622304486 values:  -53.95158 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0023866381708051356 values:  -52.662945 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002208918532721589 values:  -52.324974 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0027937472887195167 values:  -58.972576 ----- -----iteration: \n",
      "\n",
      " 43 target diff:  0.001955247268180276 values:  -----iteration: -58.732094  -----33  target diff:  \n",
      "0.002851936198791622\n",
      " values:  -52.650032 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002165155885879138 values:  -53.97796 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022122806763412053 values:  -58.98761 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002830551403044429 values:  -52.274635-----iteration:   ----------iteration: 44   \n",
      "34target diff: \n",
      "  0.002012942551189652target diff:  values:  -58.577938 -----  0.002701784763730432 \n",
      "\n",
      "values:  -52.609097 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0018599893827763417 values:  -54.060436 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002047730844639254 values: -----iteration:   27-52.3155  target diff: -----  0.002436546371574685\n",
      " \n",
      "values:  -59.025215 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0024941046372968746 values:  -52.576416 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0015833908151509945 values:  -58.514343 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0024200891108860185 values:  -54.092 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0024981919640883047 values:  -52.509544 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0025330841968286073 values:  -59.04217 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0017642035222940435 values:  -58.383953 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.003823278230280872 values:  -52.263428 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0016830402307831185 values:  -54.041668 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0037848170043814897 values:  -52.47727 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018298741285973019 values:  -59.041893 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016614383288140054 values:  -52.282257 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002289624327143665 values:  -54.06115 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.001412817614942093 values:  -58.29288 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.003259219171986297 values:  -52.449493 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002168860502376325 values:  -54.09613 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0019857542993783083 values:  -59.070225 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002614949107443018 values:  -52.44766 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001763332361421104 values:  -52.295773 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002053388984698118 values:  -54.053387 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0025333371032109464 values:  -52.467037 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0018296637710723648 values:  -59.08239 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023405751745796378 values:  -52.225716 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0022026572681353935 values:  -54.0289 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0023845669521163895 values:  -52.496082 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024174564358685614 values:  -52.258606 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.001997936249174836 values:  -59.11083 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0027143902418366823 values:  -52.494514 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0018404112434809927 values:  -53.998615 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002072034445987827 values:  -52.282314 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0024298323542554044 values:  -52.48838 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.00181882158269568 values:  -54.027344 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002047282722041029 values:  -59.115932 ----- \n",
      "\n",
      "-----iteration: -----iteration:   1044  target diff: target diff:  0.0017458889232278983  0.002376247956414904values:  -52.21951 values:  -52.538013  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  57 target diff:  0.002274279694453175 values:  -54.116158 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0026714268889650133 values:  -52.52415-----iteration:   -----34  \n",
      "\n",
      "target diff:  0.0019853937430238935 values:  -59.121014 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  11 target diff:  0.0016316303899504205 values:  -52.2536 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0025626213682479037 values:  -54.087322 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002032658340161308 values:  -52.496807 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021802724089084267 values:  -52.273174 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0014918634045075617 values:  -54.105984 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias47\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias0.0019689738836493305\n",
      " values: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "-52.505745WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "13WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0020349720141094084\n",
      " values:  -52.285122 -----iteration: -----  35\n",
      "\n",
      " target diff:  0.0018813433276880008 values:  -59.09135 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  48 --------------------target diff:   adv learner0.0020261433594355545  --------------------values: \n",
      " -52.52005 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0021908822320096805 values:  -59.102234 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019087523846479887 values:  -52.27554 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0024024082826871445 values:  -52.51969 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0020043803940128497 values:  -59.042786 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9196365893155415 values:  -59.45583 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002402412311996834 values:  -52.526207 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018492896394553722 values:  -52.29493 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002424086769171926 values:  -52.525787 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019305693523986363 values:  -52.339233 -----iteration: -----  1 target diff:  \n",
      "0.004272604159261487\n",
      " values:  -59.488564 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.003825841026630744 values:  -59.00196 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002543116751133083 values:  -52.53117 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.001939458879356111 values:  -52.49302 ----- \n",
      "\n",
      "-----iteration:  39-----iteration:   target diff:  170.002022292769306434 target diff:   values: 0.002600424010623461  -58.994778values:   ----------iteration: -52.369976  2 \n",
      " -----\n",
      "target diff:   \n",
      "0.002892463606077432\n",
      " values:  -59.463375 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0021253501306026912 values:  -52.49795 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0019738458287584934 values:  -58.99679 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018377149677966244 values:  -59.420197 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  18 target diff:  0.002213707115992995 values:  -52.384052 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0022511106214521868 values:  -52.480675 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0015239303079322966 values:  -58.98536 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020813738371933026 values:  -59.429768 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0020606532938370627 values:  -52.403233 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0014561584012237894 values:  -58.98605 -----iteration: -----  19\n",
      " \n",
      "-------------------- target diff: ckpt:  30000 -------------------- \n",
      "0.002720601362741526 values:  -52.324726 -----Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl! \n",
      "\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  57 target diff:  0.0026900258420168165 values:  -52.446472 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002423133295330416 values:  -52.320744 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019979607964653663 values:  -59.452274 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  58WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " target diff:  \n",
      "0.0020826820852951947 values:  -52.446175 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  59 target diff:  0.002187110896935039 values:  -52.464478 ----------iteration:   \n",
      "21 \n",
      "target diff:  0.0019348601328949085 values:  -52.36324 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002412881511733943 values:  -59.411053 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002399893376140533 values:  -52.461845 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0020648262360429474 values:  -52.46539 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00220831154904028 values:  -52.32845 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017016310188524145 values:  -59.30686 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0021419230068865933 values:  -52.519657 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018832565908837116 values:  -52.313244 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8 target diff:  0.002243024381540036 values:  -59.300194 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0022052357733027207 values:  -52.511005 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0021279233921183017 values:  -52.380882 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  64 target diff:  0.002028867510821621 values:  -52.54248 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9183444255635276 values:  -51.980915 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0013999902049943423 values:  -59.374153 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  65 target diff:  0.002094430035874536 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent0/trajs0.pkl!\n",
      "values:  Refresh buffer every 1000000 sampling!-52.51334\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  1 target diff:  0.003015884177550955 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold0/train/agent4/trajs4.pkl!values: \n",
      " Refresh buffer every 1000000 sampling!-51.92071\n",
      " ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  25 target diff:  0.0022173481108506846 values:  -52.383415 ----- \n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  66 target diff:  0.001941172697554986 values:  -52.513176 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0031716998551970786 values:  -51.882046 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.002136355573456674 values:  -52.525364 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 3  26target diff:  target diff:  0.0023556982082707403  0.0016957431591105134values:   -52.118538values:  ----- \n",
      "\n",
      " -52.326397 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0015121559665704323 values:  -52.54703 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024295766439715884 values:  -52.216045 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0022181174315921495 values:  -52.5599 -----iteration:  5-----  target diff:  \n",
      "\n",
      "0.002163413451995855 values:  -52.23919 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  27 target diff:  0.001503941695179887 values:  -52.30235 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001997138892285815 values:  -52.422417 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0019066301128439233 values:  -52.58795 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0017538426847057537 values:  -52.367123 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002129358023674693 values:  -52.457966 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.00207089329803226 values:  -52.611877 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  29 target diff:  0.0017539191638734149 values:  -----iteration: -52.317173 8  ----- target diff: \n",
      " 0.0019231349579561885\n",
      " values:  -52.573895 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0014872113112511362 values:  -52.50672 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "0WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel target diff: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "0.9206903949234359 WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.values: \n",
      " -59.409077 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  9Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent3/trajs3.pkl!\n",
      " target diff: Refresh buffer every 1000000 sampling! \n",
      "0.002377517740296532 values:  -52.48803 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  30 target diff:  0.0026390165577264064 values:  -52.286114-------------------- -----  \n",
      "adv learner \n",
      "--------------------\n",
      "-----iteration:  1 target diff:  0.003927718121918112 values:  -59.434917 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019573726382600466 values:  -52.515472 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0018116156393716183 values:  -52.298775 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002939360900351755 values:  -59.46213 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019140742576792538 values:  -52.676838 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002262841662471259 values:  -59.49052 -----WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  32 target diff:  0.0017503163616395547 values:  -52.29248 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020630527983334823 values:  -59.510845 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022058660840111525 values:  -52.708294-----iteration:   -----33  \n",
      "\n",
      "target diff:  0.0017853165946629197 values:  -52.324272 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017585677196794945 values:  -59.558987 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002605316260633549 values:  -52.810036 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0017684737245068573 values:  -52.2997 ----- \n",
      "-----iteration:  \n",
      "6 target diff:  0.0022664241578817614 values:  -59.590916 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9196507165086626 values:  -59.88483 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  14 target diff:  0.001987294285569936 values:  -52.8443 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018892425035748077 values:  -59.588383 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "35WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "0.001478541825190466WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      " values:  -52.309597 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015856842588512097 values:  -59.569275 ----- \n",
      "\n",
      "-----iteration:  15 target diff: -----iteration:  0.001796025383826211 1 target diff:  0.004416616311293209  values:  -59.882793 values: ----- \n",
      "\n",
      " -52.83859 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001743346887249732 values:  -59.543736 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0021711348816172518 values:  -52.83678 ----- \n",
      "-----iteration:  \n",
      "2 target diff:  0.0024110367027496593 values:  -59.901085 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0016464782766925032 values:  -52.8581 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015520436176187425-----iteration:   values: 3 -59.56653  target diff: -----  0.002305906356394919\n",
      " \n",
      "values:  -59.854836 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0019457750697880864 values:  -52.76914 ----- \n",
      "\n",
      "-----iteration: -----iteration:   419 -----iteration:   target diff: target diff: 11   0.0020160262899115960.001655457558908008target diff:    values: 0.00176915854171407values:  -59.881985  ----- \n",
      "values:  -52.78835  ----- \n",
      "-59.61004\n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022108258933828248 values:  -59.618896-----iteration:   -----5  target diff:  \n",
      "0.002047345285340655\n",
      " values:  -59.884975 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0018117044974231505 values:  -52.783913 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024183343480947946 values:  -59.629585 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.0019855769980161144 values:  -59.86114 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.0019425462531451117 values:  -59.651836 ----- -----iteration: \n",
      " \n",
      "21 target diff:  0.0022065533630372166 values:  -52.84092 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016370010393424498 values:  -59.826164 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019982130157609676 values:  -52.897823 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0014565774261054698 values:  -59.61065 ----- \n",
      "\n",
      "-----iteration: -----iteration:  0 8  target diff: target diff:   0.9234243988155730.0022069543700500445  values:  values:  -59.832207 ----- \n",
      "\n",
      "-54.549248 ----- \n",
      "-----iteration:  \n",
      "0 target diff:  0.9224023133751487 values:  -52.584404 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.00200714332812317 values:  -52.927586 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0033700287684584667 values:  -54.88631 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002000603680557282 values:  -59.82954 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0035168165659103467 values:  -54.965473 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0035857405535423092 values:  -52.593098 ----- \n",
      "\n",
      "-----iteration:  24 -----iteration: target diff:   0.002517291284706434310  values:  -52.94775target diff:  ----- 0.0019781415847817435  values: \n",
      "\n",
      " -59.786674 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0032280106027245893 values:  -55.007908 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017274792361307656 values:  -52.576294 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0019856938617953276 values:  -52.86035 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024840476725642804 values:  -55.019047 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0015618754379554771 values:  -52.48632 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023857435581720594 values:  -52.790745 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0026130159900110976 values:  -55.032104 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001813109456274312 values:  -52.5557 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001800907562797366 values:  -59.835537 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  -----iteration: 0.0024758718359437887  6 target diff:  values:  0.002330882555973255 values: -52.54132  ------55.071026  ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  27 target diff:  0.001937784946522342 values:  -52.815426 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002103985533071989 values:  -59.832333 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022386471807301156-----iteration:   values: 7  target diff: -52.45786  0.00262522438209881----- values:   -55.133453\n",
      " -----\n",
      " \n",
      "\n",
      "-----iteration:  28 target diff:  0.003081830875434753 values:  -52.84443 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0031902875956006343 values:  -55.124424 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  29 target diff:  0.0021892440945659 values:  -52.97553 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.00245843123423732 values:  -59.845623 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022634170473473636 values:  -55.118652 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019243428107234572 values:  -52.552876 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001896601637191884 values:  -53.023075 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.00217570273157062 values:  -55.179592 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018163333275965949 values:  -59.858097 ----- \n",
      "-----iteration: \n",
      " 0 target diff:  0.9212026653881905 values:  -59.25755 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0019996401256909143 values:  -53.19694 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0026113463809180858 values:  -52.54752 ----------iteration:  \n",
      " 1\n",
      " target diff:  0.004813341256964151 values:  -59.272038 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.003291473131603171 values:  -55.183388 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0017438865818317241 values:  -59.93642 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.00267590259178247 values:  -53.215664 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002181389720352615 values:  -59.289104 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019983111543776166 values:  -52.56543 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002426125097925543 values:  -55.161953 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001842761384115813 values:  -53.217377 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016606993803116165 values:  -59.92869 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020420165690139187 values:  -59.302887 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0016889580426030957 values:  -53.186775 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001813860480608628 values:  -59.27666 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018534025898978685 values:  -52.60551 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002651652911293559 values:  -55.145817 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019077307977901187 values:  -53.191822 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018436033126437302 values:  -59.851673 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002141467430226027 values:  -59.20141 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0015165485424062444 values:  -53.08471 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0027004222666983206 values:  -52.57892 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001966322519171655 values:  -55.17715 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0030290330180021024 values:  -59.196327 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0022746046061702854 values:  -53.11735 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002700570374626171 values:  -59.809574 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0020625260200107178 values:  -55.151764 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001622870679686841 values:  -59.258507 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0020956382992030217 values:  -52.647114 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001598701266046509 values:  -53.160664 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020311901966730953 values:  -59.899807 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020664387287746633 values:  -55.172688 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0022806214011322603 values:  -52.471474 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0017506425808140728 values:  -53.200687 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018432763721325917 values:  -59.130276 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0024315392056314146 values:  -59.78635 ----- \n",
      "\n",
      "-----iteration:  40 -----iteration: target diff:   170.0019656063899025807  target diff:  values:  0.0015219906354542597 -53.332012values:  -----  -55.16503 \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.004372132312866524 values:  -59.19985 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002923305504889606 values:  -52.462864 ----- \n",
      "\n",
      "-----iteration: -----iteration:   2110  target diff:  target diff: 0.001935208161897702  values: 0.0026380892787784757  values: -59.236973 ----- -59.688046  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  41 target diff:  0.0026005391132893213 values:  -53.34504 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002433260619540165 values:  -52.452415 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002341940398234162 values:  -55.18613 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002913359977893521 values:  -59.22054 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0019174828144471502 values:  -53.31657 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018645925016972423 values:  -52.536488 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0014579955353826541 values:  -59.249043 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  19 target diff:  0.0018628948949058013WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "values:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration: -55.22453 \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "22----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biastarget diff:  \n",
      "\n",
      "\n",
      "0.0024313195281338526 WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "-59.65319 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----\n",
      " \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  43 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "target diff: Refresh buffer every 1000000 sampling! 0.0013324939392940762\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      " values:  -53.263367 ----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----iteration:  17 target diff:  \n",
      "0.0016409820549497503 values:  -52.4849 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  20 target diff:  0.0021063624455128984 values:  -----iteration: -55.227917  -----18  \n",
      "target diff: \n",
      " 0.0016339137646973702 values:  -52.422382 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002112454383534541 values:  -59.594204 ----- \n",
      "\n",
      "-----iteration: -----iteration:   2119  target diff:  target diff: 0.0020833836683923804  values: 0.0011955097078495524 -55.255352  values:  ------52.41685  \n",
      "-----\n",
      " \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  24 target diff:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent3/trajs3.pkl!\n",
      "0.002007403427253842Refresh buffer every 1000000 sampling! \n",
      "values:  -59.649494 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  22 target diff:  0.001803540791483469 values:  -55.300556 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0018218064138530315 values:  -59.696407 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018345948811586967 values:  -55.349094 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002322904382324139 values:  -55.39167 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002584399846213293 values:  -55.460968 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  26 target diff:  0.0029363947854961995 values:  -59.67591 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002555503631210093 values:  -55.475086 -------------------- -----fqe on dqn & sale  --------------------\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  0 target diff:  0.9198138401399771 values:  -50.942055 -----iteration: -----  \n",
      "27\n",
      " target diff:  0.002468614891497116 values:  -59.728428 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004216958456721766 values:  -50.891598 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002288515560143545 values:  -55.496513 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0035276087647567265 values:  -51.018383 ----- \n",
      "\n",
      "-----iteration:  28-----iteration:  28  target diff:  target diff: 0.002361636315463413 0.0019685706309439423 values:  values:   -55.47561 -59.69382-----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  3 target diff:  0.003104288549230457 values:  -51.105373 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028313773096423655 values:  -51.208813 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002548613786991286 values:  -55.501858 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0022090004989335056 values:  -59.642303 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002449888030576832 values:  -51.198467 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.003012282247445068-----iteration:   values:  30-55.48224  target diff: -----  0.00258649852820302 \n",
      "values: \n",
      " -59.642693 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.002642572653404203 values:  -51.169075 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002200754772148796 values:  -55.510384 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0023214693058619717 values:  -55.56695 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022278947109928486 values:  -51.232178 ----- \n",
      "\n",
      "-----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "0 target diff:  0.9219942496477088 values:  -57.157017 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.00243486286674439 values:  -55.639008 ----- \n",
      "\n",
      "-----iteration:  8-----iteration:  target diff:  31  0.002533133115336638target diff:  values:  0.0022059121491551075  values: -51.217304  -59.560528-----  -----\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  1 target diff:  0.004114086400789327 values:  -57.211086 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0028428464361350356 values:  -55.66708 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027268887307153214 values:  -57.21078 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9220457848540285 values:  -51.82478 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0029592816172055204 values:  -51.311543 ----- \n",
      "-----iteration:  \n",
      "35 target diff:  0.0026894651434597495 values:  -55.725864 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021077873901863787 values:  -57.22248 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0024005599086294586 values:  -59.576084 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021346801521324138 values:  -51.86237 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0026737523335533635 values:  -55.78605 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020626246500385008 values:  -57.249203 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.003428317947841317 values:  -51.32096 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0028324637129319083 values:  -55.80134 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002957126038989755-----iteration:  values:   -59.5575262  target diff: -----  \n",
      "\n",
      "0.0014740700201362554 values:  -51.896023 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0017918145999840257 values:  -51.30206 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020094969465826113 values:  -57.236797 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002145009469127253 values:  -55.82776 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026444924190095064 values:  -57.274937 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0020706188336192164 values:  -51.3648 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0022924050999093607 values:  -55.8818 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002574449743671512 values:  -59.46131 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003442760737039694 values:  -51.274475 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002457789177574111 values:  -55.91583 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018347644366831434 values:  -57.325993 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.002192183902448348 values:  -55.93152 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002909339608435486 values:  -51.22263 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0023784522882182332 values:  -59.44024 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015881314141973802 values:  -57.365902 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018956147161612018 values:  -55.953465 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0023169401606431784 values:  -51.134644 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0020435102265797156 values:  -59.407585 ----- \n",
      "-----iteration: \n",
      " 9 target diff:  0.001972448319554497 values:  -57.39854 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.001857124000887699 values:  -56.025463 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014219963247382604 values:  -57.47308 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0031241168557607406 values:  -51.181973 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002419261912627154 values:  -56.060555 ----- \n",
      "-----iteration: \n",
      " 37 target diff:  0.0023473367032441654 values:  -59.373634 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002055356039388731 values:  -51.20646 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002030042724382273 values:  -56.08317 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002476640865673019 values:  -51.330486 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  46 target diff:  0.0020028878534846632 values:  -56.10398 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002001713811401184 values:  -59.369167 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018567484088136956 values:  -56.1208 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.003936359066728054 values:  -51.37594 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9217858958299174 values:  -52.986084 ----- \n",
      "\n",
      "-----iteration: -----iteration:   4820  target diff: target diff:   0.00185441862994638130.0018080976854070072  values: values:  -56.10107  -51.456097-----  ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  -----iteration: 49  1 target diff:  target diff: 0.0016210102083422462 0.0022058391104640526  values:  -56.112793values:   -53.044426----- ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  21 -----iteration: target diff:   0.002755996380833010239  values: target diff:   -51.540920.002555337970665176  ----- \n",
      "values:  \n",
      "-59.331787 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0018720490878198633 values:  -56.07517 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0028538665333444897 values:  -51.616943 ----------iteration:  2 target diff:  \n",
      " \n",
      "0.0015137911795214693 values:  -53.052788 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002150738751954018-----iteration:   values: 3  -56.086555 -----target diff:   \n",
      "\n",
      "0.0016471750654464066 values:  -53.08722 ----- \n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "-----iteration:  23 target diff:  0.0021165775326850785 values:  -51.80597 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0025776423045754736 values:  -59.16067 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0020841479026577673 values:  -56.13125 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023341982218701507 values:  -53.064606 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9229463598990707-----iteration:   24values:   -57.082367target diff:   -----0.003288180863218667  \n",
      "values: \n",
      " -51.887173 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0026260537032580683 values:  -56.171104 ----- \n",
      "\n",
      "-----iteration:  5 target diff: -----iteration:   410.0016817159930181361  target diff: values:  0.0031977020182076717 -53.02956  -----values:   \n",
      "-59.09914\n",
      " ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002394493847352438 values:  -51.963013 -----iteration: -----  \n",
      "1 \n",
      "target diff:  0.005147592938274523 values:  -57.069817 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002278794292927934 values:  -56.250813 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0014926042493360685 values:  -52.998528 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0019497660665047495 values:  -59.107883 ----- \n",
      "\n",
      "-------------------------iteration:   training agent26  --------------------target diff: \n",
      " 0.001980215017467204 values:  -51.98188Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold1/train/agent/trajs.pkl! \n",
      "----- Refresh buffer every 1000000 sampling!\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 target diff:  0.00308581422981416 values:  -57.09254 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002255570554844838-----iteration:   55values:   target diff:  -59.025066 0.0026753040910447454-----  values: \n",
      " \n",
      "-56.255913 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021320937038179946 values:  -57.11504 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0020985345288511057 values:  -56.242596 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.001941254241357821 values:  -58.994164 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0028356049305932915 values:  -52.043495 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0017275689060872726 values:  -56.321033 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0021247180469919393 values:  -58.98591 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019792844069763957 values:  -57.159912 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002222660149359548 values:  -56.384975 ----- -----iteration: \n",
      "\n",
      " 28 target diff:  0.002316664989586638 values:  -52.137695 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002082860267918502 values:  -58.92454 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0026002822292494213-----iteration:  values:   47-52.160725  target diff:  ----- 0.001566543624939339\n",
      " \n",
      "values:  -58.901943 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.003758769637311181 values:  -57.14276 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002018237427911603 values:  -56.447468 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0029742839540684105 values:  -52.178654 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002017685594625956 values:  -58.91535 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022063235438261357 values:  -57.150303 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0021869110446005274 values:  -56.51064 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.003505342468466115 values:  -52.41999 ----- -----iteration: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 49 target diff:  0.0019060281543118503 values:  -58.833828 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002325840962414267 values:  -56.493256 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0037061932442731373 values:  -52.486797 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0016333711681730053 values:  -58.84737 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0014179671316425168 values:  -57.13581 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  51 target diff:  0.0015262617602558063 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent1/trajs1.pkl!\n",
      "values: Refresh buffer every 1000000 sampling! -58.762268-----iteration:  \n",
      "33 -----  target diff: \n",
      " \n",
      "0.002814101447176201 values:  -52.52117 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold0/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  52 target diff:  0.0016909900213491185 values:  -58.718086 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0023052788378249787 values:  -56.50748 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.00401924918207029 values:  -52.66753 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0011194889903715802 values:  -58.65769 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0028669773127470524 values:  -56.54754 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0032325180312028144 values:  -52.80133 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0031713206704462784 values:  -52.844387 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0023271023735129273 values:  -56.560844 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0018725200989215447 values:  -56.54632 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0033140160245889966 values:  -52.92182 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  66 target diff:  0.002369913253368085 values:  -56.535297 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0032632529547009085 values:  -52.97107 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0017359321999528626 values:  -56.594463 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0019073025661265558 values:  -56.617474 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0030153343607095644 values:  -52.98639 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  69 target diff:  0.0017741164932573827 values:  -56.637478 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.003087710296504098 values:  -53.14268 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0019268944922430607 values:  -56.654144 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.004033026950969308 values:  -53.390713 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0017661323140341725 values:  -56.648987 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9204937456747252 values:  -60.684772 -----iteration: -----  42\n",
      " \n",
      "target diff:  0.005384555373507853 values:  -53.456352 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0016805872169960915 values:  -56.733242 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  43 target diff:  0.0027294804140233224 values:  -53.46888 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004319194978716775 values:  -60.748146 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0019294881156885157 values:  -56.71963 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028822190436365576 values:  -60.879856 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0031793404367462326 values:  -53.49519 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9205632800274783 values:  -59.521965 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0018538100357517247 values:  -56.743164 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0028449307533798605 values:  -60.986095 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0035028031018882444 values:  -53.542217 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0014637728155409992 values:  -56.776054 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004524329676941234 values:  -59.52349 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0025380309920106413 values:  -61.011547 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0037155747043976614 values:  -59.57633 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0035929111915737654 values:  -53.548565 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002541926964745428 values:  -61.04882 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024561426751665816 values:  -59.59795 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.003218809275989338 values:  -53.609287 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0021232334167453517 values:  -61.0639 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023921840770546473 values:  -61.03805 ----------iteration:   \n",
      "48\n",
      " target diff:  0.0030850894219691632 values:  -53.604004 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018676061736535624 values:  -59.600414 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018902286773138117 values:  -60.955006 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018702754117006473 values:  -59.647987 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002403701993799178 values:  -53.605217 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020121146496149245 values:  -60.993237 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0024406959542134818 values:  -53.565327 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001691651249121401 values:  -59.638874 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  10 target diff:  0.002595223244430088 values:  -60.89904 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020840054038653256 values:  -60.93388 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0024447395036999733 values:  -53.57088 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018876600946121816 values:  -59.640648 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9203124798765816 values:  -51.35065 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002388754467133441 values:  -61.004097 ----- \n",
      "\n",
      "-----iteration:  52-----iteration:  target diff:   80.002326320754105098  target diff: values:   0.0020329029032155523-53.610874  values: ----- -59.67641 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  1 target diff:  0.003546949022364151 values:  -51.431904 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  -----iteration: 0.0028997946588712282 values:   -53.6665579 ----- target diff:   0.0027650327707677085\n",
      " \n",
      "values:  -59.717674 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025453054382675827 values:  -51.52103 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003028373159526907 values:  -60.9788 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002687349176248115 values:  -59.797405 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.003206513673730707 values:  -53.607685 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002391787678293592 values:  -60.92646 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024631178274871473 values:  -51.567497 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0027190909028935095 values:  -59.86421 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018921603958675873 values:  -60.953144 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002369806669580823 values:  -53.55526 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001983231933508381 values:  -51.626995 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002237834637156458 values:  -59.91253 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020212558269611194 values:  -60.986816 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0024597765807545663 values:  -53.57721 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002623931043195049 values:  -51.68337 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002512153547565526 values:  -----iteration: -60.96151  13-----  target diff: \n",
      " \n",
      "0.001631285061859726 values:  -59.94585 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002593426465204202 values:  -53.517464 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002406292615514434 values:  -51.776302 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018168159490741624 values:  -60.937187 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018542105122214794 values:  -60.01723 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002296683428753341 values:  -53.477547 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021664315321581347 values:  -51.82816 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0023998445744189585 values:  -60.053627 ----- \n",
      "\n",
      "-----iteration:  19 target diff: -----iteration:   0.002068002963987678559  target diff: values:   -60.869970.00242416982471538  -----values:   \n",
      "-53.428013 \n",
      "----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002434419043750936 values:  -51.855976 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0028208475994134625 values:  -53.412106 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.00241552989836635 values:  -60.16149 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 9-----iteration:   17  61target diff:  target diff:  target diff:  0.002424998768847667 0.002662836112612518 0.0028055639820075686  values: values: values:    -51.98518-60.22263  ---------- -53.409187\n",
      "\n",
      "  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  20 -----iteration:  target diff:  180.002356176341346198  target diff: values:   0.0031982399669302163-60.891506  values:  ------60.29233  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  62 target diff:  0.0025131961100443383 values:  -53.378235 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0037761085867199624 values:  -52.135315 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0027578432297814945-----iteration:   values: 63  -60.921955target diff:  0.0025177599466812742 ----- values:   -53.384518\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002232009636434579 values:  -60.36225 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0035699510214976644 values:  -52.222786 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0024310621389426897 values:  -53.302296 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023956988990578706 values:  -60.4112 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0026414344354932897 values:  -53.326008 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 22  -----iteration: target diff:   21120.0022029782869941307 target diff:   values:  target diff: 0.003156169598790102   0.0027523694931288387values: -60.86143   -----values:  \n",
      "\n",
      "-60.455242  ------52.26507 \n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0028580226061085236 values:  -53.33473 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0025562795962538296 values:  -60.50645 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002354838858495792 values:  -52.22933 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0023830986813936092 values:  -53.30411 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002656248488642081 values:  -60.76263 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0031072257402592943 values:  -60.528812 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0027226818919843273 values:  -53.245304 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0027751041487966595 values:  -60.56873 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0024467528441584493 values:  -53.283848 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.003595081618222694 values:  -60.65128 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021365378100586937 values:  -52.180416 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002168663270255662 -----iteration:  values: 70 -60.58161  target diff: ----- 0.002240802180800691  \n",
      "values: \n",
      " -53.237217 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002550065939417495 values:  -52.19519 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023898066167922097 values:  -60.599358 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0041668533828855825 values:  -60.50122 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002000342030427322 -----iteration: values:   71-52.254787  target diff: -----  0.002529201148612885\n",
      "\n",
      " values:  -53.238956 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002171364722256232 values:  -60.69148 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0022366938062412735 values:  -52.292397 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.003171425532501904 values:  -53.2438 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0035504393718207533 values:  -60.387154 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0016633056340719387 values:  -52.31913 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002223333639348549 values:  -53.257664 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.004010314550029245 values:  -60.36021 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.003074625210209892 values:  -60.74284 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0022638480317078756 values:  -53.22349 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0018243571571209623 values:  -52.470947 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0031222937552945534 values:  -60.377033 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0030554014796597357 values:  -60.773716 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002672119051720124 values:  -53.206978 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002716496637770457 values:  -60.386192 ----- \n",
      "\n",
      "-----iteration:  76 -----iteration: target diff:   0.0028653408090693415 20values:   target diff:  -53.1845970.0030316566911786132 -----  values:  \n",
      "-52.469517\n",
      " ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001923627237005495 values:  -60.769016 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0030742118104429158 values:  -60.358337-----iteration:   77-----  \n",
      "target diff: \n",
      " 0.0029611124707802873 values:  -53.098816 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0024761824615362905 values:  -52.474285 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0016603440419291746 values:  -60.780098-----iteration:  78 -----  \n",
      "\n",
      "target diff:  0.00285761170160803 values:  -53.060356 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0032403727876194775 values:  -60.23556 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002089416777771606 values:  -52.49938 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0026815436108990486 values:  -53.06649 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0025928056390321632 values:  -60.796413 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0030140491339982894 values:  -60.190895 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.001931644772571424 values:  -52.501972 ----- \n",
      "\n",
      "-----iteration: -----iteration:   3380  target diff: target diff:  0.002651310102086424 values:   0.002512695984664934-60.220615  -----values:   \n",
      "-53.000652\n",
      " ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002413369143939598 values:  -60.848927 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0025832326121327594 values:  -52.9044 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.003336200997604036 values:  -60.129375 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0022622949603158223 values:  -52.50164 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0029841908666512137 values:  -60.109734 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.001978283412119272 values:  -60.84812 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002287942701693371 values:  -52.464962 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0023489778609994193 values:  -52.783882 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002740018246316016 values:  -60.151875 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0018823260099840795 values:  -60.87323 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0026004768749065526 values:  -52.75675 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0019519696411392595 values:  -52.414272 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.003191940806371644 values:  -60.113483 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0022898482836088735 values:  -60.85825 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0024242058691725846 values:  -52.643787 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0024263188773341058 values:  -60.109417 ----- \n",
      "\n",
      "-----iteration: -----iteration:   3727  target diff: target diff:   0.00190905689347278420.002447954466011743  values:  values: -60.901054  -52.341213-----  -----\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  85 target diff:  0.002216392974620484 values:  -52.643852 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0032401302689478518 values:  -60.043407 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0028106538951125754 values:  -52.60075 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001909744547436284 values:  -60.876953 ----- -----iteration:  \n",
      "28\n",
      " target diff:  0.0028024110791718708 values:  -52.28793 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0026394703196586586 values:  -60.05219 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0018792978509858053 values:  -52.514416 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0027476229388839314 values:  -60.056946 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0027618219523908977 values:  -52.23452 ----------iteration:   \n",
      "39\n",
      " target diff:  0.0017675290146191586 values:  -60.856865 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0021561175990700804 values:  -----iteration: -52.399986  -----42 \n",
      " \n",
      "target diff:  0.002633216651895223 values:  -60.03405 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.003060194393614004 values:  -52.21656 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0017098985224183578 values:  -60.788933 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0024334513592280537 values:  -52.325752 ----- \n",
      "-----iteration: \n",
      " 43 target diff:  0.00281823785801107 values:  -59.97094 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001828317513406268 values:  -60.799168 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002493565539556026 values:  -59.905968 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0022454071556651657 values:  -52.35355 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0022584136149354224 values:  -52.17069 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.001795830956134776 values:  -60.75878 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0026633987133553314 values:  -59.875175 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0026684888199474746 values:  -52.30265 ----- \n",
      "\n",
      "-----iteration:  43 target diff: -----iteration:   0.00163915437852134846 target diff:   0.00341456130276406 values: values:   -59.801277 ------60.69477  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  92 target diff:  0.002027460406634438 values:  -52.244576 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0033404204841133173 values:  -52.13464 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0017414119790160382 values:  -60.700344 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0026822414464634484 values:  -59.80372 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0018886517585726327 values:  -52.22574 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0029684589215980078 values:  -52.123608 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0019010509957884227 values:  -60.684177 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0021492816133780192 values:  -52.132 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002834685914148293 values:  -59.767147 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  -----iteration:  95 -----iteration: target diff:   0.0017854182040235487340.002264258281109095   target diff: values: values:    -60.6809770.0024988519848078987-52.029247   values: ----------  -52.092052 \n",
      "\n",
      " \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002538427501526082 values:  -59.65531 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.001994147394117846 values:  -51.99484 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002742261837184787 values:  -52.0527 ----- \n",
      "\n",
      "-----iteration:  47-----iteration:   50 target diff: target diff:  0.0017262478416667935 0.002662202382670968 values:   values: -59.536533  ------60.645058  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.002358068053572522 values:  -51.911804 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0026148807622256385 saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_10000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9132767908785497 values:  -51.486797 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00178365817156083 values:  -51.55683 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019744988673017763 values:  -51.592884 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014936126534496302 values:  -51.583992 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9125032310524206 values:  -51.352043 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026773829093663594 values:  -51.41228 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020981876506066493 values:  -51.42579 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019840026647209383 values:  -51.447292 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001962951061281207 values:  -51.47619 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002025996082800572 values:  -51.483208 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018686622684112677 values:  -51.512066 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017157651247752628 values:  -51.536263 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0014092987050386952 values:  -51.576546 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  0 target diff:  0.9123878497989881 values:  -52.327293 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038688759319967588 values:  -52.37926 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  2 target diff:  0.002429859640940856 values:  -52.436226 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024549353797722194 values:  -52.516247 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017676347032978695 values:  -52.48557 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.0019195359652491122 values:  -52.389412 -----WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  6 target diff:  0.0019312243064675042 values:  -52.312824 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020589616422019372 values:  -52.353184 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  8 target diff:  0.0016464635791765176 values:  -52.248474 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001596867549348708 values:  -52.15017 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  10 target diff:  0.001615498457396612 values:  -52.101357 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001550114523009822 values:  -52.050484 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0014743298664740613 values:  -52.085026 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9166118066418133 values:  -62.187233 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002427141149351491 values:  -62.237907 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 target diff:  0.0014778133025686868 values:  -62.20221 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9126265414231597 values:  -52.28893 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  1 target diff:  0.003372467056473304 values:  -52.343113 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002185873391540105 values:  -52.412388 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001962707139457938 values:  -52.34925 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002751849994774833 values:  -52.40202 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- ckpt: -----iteration:   50005  --------------------target diff: \n",
      " 0.0016039310935079866 values:  -52.397583 -----Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl! \n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " target diff:  0.001945802999194826 values:  -52.44883 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  0 target diff:  0.9178655624933136 values:  -63.446877 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015948462780864588 values:  -52.40274 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0023393848243228347 values:  -63.421406 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017152387551558348 values:  -63.421852 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0014677731493272209 values:  -52.48462 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "3WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "target diff:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel0.0013114524194253125\n",
      " values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      " -63.45248WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "--------------------WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasckpt:  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "10000 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "--------------------WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasRefresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.--------------------\n",
      " adv learner --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9122383176265584 values:  -52.811882 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038228298118903725 values:  -52.85431 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028003362318863257 values:  -52.741844 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  3 target diff:  0.0025076583325408844 values:  -52.748615 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9196588574248028 values:  -63.388557 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9128237107181727 values:  -51.637096 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001688259871719402 values:  -52.71338 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002982689547223098 values:  -63.39108 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002998783973652405 values:  -51.62502 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024732443154009028 values:  -52.630424 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001577158921353024 values:  -63.37234 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027405176562088343 values:  -51.640545 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023253623602755937 values:  -52.64109 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001599673458845941 values:  -63.307125 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002294051839639711 values:  -51.650364 ----- \n",
      "\n",
      "-----iteration:  4-----iteration:   target diff: 7  0.0017934011913462895target diff:   values:  0.0014526853503581084-63.35636 values:   -52.589314-----  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  4 target diff:  0.002530165353950813 values:  -51.689278 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0015660682955995727 values:  -63.29446 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021050602661480556 values:  -51.6907 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0014956742883757688 values:  -63.2609 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019879436912716543 values:  -51.71705 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016001051128779883 values:  -51.779663 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001661325343807465 values:  -51.843193 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020510700903580404 values:  -51.81654 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9132286047955028 values:  -52.33126 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017928983833090798 values:  -51.79998 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034018700407297928 values:  -52.306072 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023575147148213503 values:  -51.774326 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020398514782143558 values:  -52.353477 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023487676309548477 values:  -51.903206 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "0.0026693873150606534\n",
      " values:  -52.337864 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0015433025764215007 values:  -52.31244 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0028918105682772177 values:  -51.82207 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9185153248991241 values:  -64.53144 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001758722907794905 values:  -52.322422 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0023669077479485387 values:  -51.977497 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003956189411708146 values:  -64.53553 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0013311174035993232 values:  -52.313717 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-----iteration: \n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.2\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "0.0026412404419395206 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelvalues:  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-64.48101 ----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "-----iteration:  15Refresh buffer every 1000000 sampling! \n",
      "target diff:  0.003087170643929494 values:  -51.972218 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.0026401810509605957 values:  -64.58108 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0021795578177763388 values:  -51.962925 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019783887568195543 values:  -64.68188 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019649764298274096 values:  -51.9891 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001661880881815163 values:  -64.70312 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0020312250236886186 values:  -51.97254 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0013189618341880832 values:  -64.75626 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel--------------------\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "fqe on dqn & saleWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel --------------------\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  19 target diff:  0.001552619648623475 values:  -51.913204 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0015012658725845848 values:  -51.85305 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  21 target diff:  0.0020540507129536032 values:  -51.791348 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  22 target diff:  0.001828351128728461 values:  -51.79621 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  23 target diff:  0.002476404699829355 values:  -51.662106 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9130003219965953 values:  -52.932564 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0019079780587271963 values:  -51.54939 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002687851253982384 values:  -52.833736 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002062848496390241 values:  -52.902065 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001719606494280194 values:  -51.417427 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003050168047966355 values:  -52.850918 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002425760097337627 values:  -52.851368 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0016042224526294383 values:  -51.28335 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00159170625443165 values:  -52.859585 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001740760986456077 values:  -51.203403 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017803826098522378 values:  -52.828857 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.0015198921009025063 values:  -50.933647 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0013966149285005057 values:  -52.890892 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018967469801553299 values:  -50.84613 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9188102385137116 values:  -63.716927 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001480396616647888 values:  -50.623432 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0041545755443394335 values:  -63.657173 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0026504048561451026 values:  -63.78284 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002749645258408582 values:  -63.730564 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022499655585407974 values:  -63.727608 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.0017602762209152356 values:  -63.87084 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9112852001279761 values:  -53.660683 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.003274497999849319 values:  -53.632866 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018920448452491355 values:  -63.989292 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029010153182756925 values:  -53.616264 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9121984820727278 values:  -53.064644 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018760146034177872 values:  -53.72372 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018109034138096027 values:  -64.00726 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003847738072488999 values:  -53.08842 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019998856052826685 values:  -53.69711 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002753720407187594 values:  -53.122883 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.00118021096012132 values:  -63.942852 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0014245245427450502 values:  -53.776253 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  3 target diff:  0.002840804489878342WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-53.134285\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " ----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "0.0021181004879053254 values:  -53.06602 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  5 target diff:  0.0020826575623333764 values:  -52.977192 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002033262373353197 values:  -52.931194 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017086867683053413 values:  -52.91095 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  8 target diff:  0.001664863956163272 values:  -52.843437 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.0015808587027758738 values:  -52.797516 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9178794361614 values:  -63.23875 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002108968288511242 values:  -52.74367 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.006231438085779164 values:  -63.23747 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029878505172590635 values:  -63.194702 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  3 target diff:  0.002681746270674803 values:  -63.239956 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9130914786559214 values:  -54.528217 ----- \n",
      "\n",
      "-----iteration:  11 -----iteration: target diff:  4 0.0024461316076738503 target diff:   0.002010743734941871values:   values: -52.774555  -63.222813----- \n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003520276595551231 values:  -54.514275 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020324973191736756 values:  -63.237415 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028160176536359016 values:  -54.505184 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018703728146425662 values:  -63.229908 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016228478728437057 values:  -54.467888 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0028346302661540527 values:  -52.84067 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0028473970441664 values:  -63.264385 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002127101296399264 values:  -63.278843 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001611463442756637 values:  -54.42454 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003623152209254706 values:  -52.724236 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018460894270764807 values:  -63.348675 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001951040994078563 values:  -54.4575 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021714508521089504 values:  -52.749554 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  10 target diff:  0.0020573131550027657 values:  -63.38351 ----- \n",
      "\n",
      "-----iteration: -----iteration:   615  target diff: target diff:   0.00193270823435124090.001682161715645369  values: values:  -54.504967 -52.77989  ----- \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  11 target diff:  0.002131822770829178 values:  -63.418404 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001994511424800429 values:  -63.394085 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020308038928664187 values:  -54.484062 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.001571489762493011 values:  -52.76713 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001987050082085697 values:  -63.386555 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0017374521012251442 values:  -63.384914 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017680325186818886 values:  -54.485332 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0017198749474025424 values:  -52.824196 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001852023618915206 values:  -63.380764 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00150347119619392 values:  -54.507507 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017812826407219023 values:  -63.40438 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015252120959059147 values:  -54.49118 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019077809549481238 values:  -63.445496 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021291436810014957 values:  -52.792694 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001116708639491905 values:  -54.448902 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0015431912682968237 values:  -63.391167 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019045755129044385 values:  -52.726807 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0018444735557460218 values:  -63.461823 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0021839408162599373 values:  -52.63171 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.001636533231181457 values:  -63.467926 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002200157075857481 values:  -52.578144 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018253107720663118 values:  -63.42262 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002023782523071766 values:  -52.49143 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019576012570907127 values:  -63.446484 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002040960965052915 values:  -52.341663 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.001541489893221658 values:  -63.46739 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.001784619741688385 values:  -52.230766 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.001515879565370176 values:  -63.49114 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  25 target diff:  0.0017956280147470053 values:  -52.145718 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001509809382942205 values:  -63.455433 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0017229267583896404 values:  -52.04847 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9132349012173459 values:  -55.06628 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018956488446133907 -----iteration:  values:  -51.99629626  target diff: -----  0.0017845981602294676\n",
      " \n",
      "values:  -63.53106 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003527817106035007 values:  -55.105164 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018238172730319952 values:  -51.831264 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0015207095345362285 values:  -63.5614 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0032933342052962294 values:  -55.11868 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002251775443276588 values:  -51.660854 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0016503667357307859 values:  -63.566364 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0027820519560948806 values:  -55.10981 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0017570186374237407 values:  -51.522053 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00158274692444825 values:  -63.601017 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021662851515836575 values:  -55.169655 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0017653143807053024 values:  -51.31437 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0013381268010731755 values:  -63.566563 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  5 target diff:  0.0024588547258140667 values:  -55.18628 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  32 target diff:  0.0014766213927386018 values:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-51.06734 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias--------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "adv learnerWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.--------------------\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  6 target diff:  0.0016893641643577412 values:  -55.16126 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0027039613441090546 values:  -55.137306 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  8 target diff:  0.0026082323430355447 values:  -55.052864 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002947894161963875 values:  -54.998848 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017889724526886134 values:  -55.070526 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  11 target diff:  0.0027290991330425484 values:  -55.10047 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002414274399006376 values:  -55.10024 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001981720832617117 values:  -55.11547 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018437819999794487 values:  -55.035503 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  15 target diff:  0.0021876405720459144 values:  -55.10247 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9172140288359976 values:  -64.80233 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.004568094409511199 values:  -64.71568 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002057280526495203 values:  -55.044746 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003671474316008735 values:  -64.68284 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.00238269967211499 values:  -55.084236 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9127502360527475 values:  -51.953754 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0025033422083938876 values:  -55.141136 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021970293567143266 values:  -64.701675 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003609518953779904 values:  -51.98405 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0016023509790663833 values:  -55.28137 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001954954727761334 values:  -64.62854 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028725179075427473 values:  -51.995975 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025275821710195228 values:  -64.62359 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002144396179820673 values:  -55.226093 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022857627393622747 values:  -51.913006 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016113004743482907 values:  -64.57497 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016042298173956826 values:  -64.614 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0023109157258392595 values:  -55.169426 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028962121844140314 values:  -51.962437 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001728861444818735 values:  -64.608215 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002223261958881115 values:  -51.966705 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0022087810414914296 values:  -55.08415 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001400282517111066 values:  -64.59542 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002646626506183843 values:  -54.98571 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020829668806421012 values:  -51.945347 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018516416543254226 values:  -54.900425 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018986436703862446 values:  -51.97479 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002197596516307709 values:  -54.891926 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015241668580590001 values:  -51.947166 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0017977921618670821 values:  -54.848972 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00148543065280244 values:  -51.958767 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0021656244951522878 values:  -54.792095 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.002040310259550034 values:  -54.694927 ----- \n",
      "\n",
      "-----iteration:  29 -----iteration:  target diff: 0  0.0021922628174321506target diff:   0.9179137113129849values:   -54.667164values:  -----  -62.36337 ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  1 target diff:  0.0046191150040582685 values:  -62.4119 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0020549952396632146 values:  -54.644035 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027795141946554687 values:  -62.393284 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0022517518105615577 values:  -54.63153 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002469487865424239 values:  -62.414417 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  32 target diff:  0.0021094466727300414 values:  -54.554058 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002163986296280081 -----iteration: values:   33-62.445526  -----target diff:   \n",
      "0.001996725693792679\n",
      " values:  -54.497036 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.001453643672484255 values:  -54.379246 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "-----iteration:  5 target diff:  0.0019613204594064984 values:  -62.463604 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  0Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl! \n",
      "target diff: Refresh buffer every 1000000 sampling! \n",
      "0.9129188366849481 -----iteration: values:  -51.283855 6 ----- target diff:   \n",
      "0.001609714424124319\n",
      " Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!values: \n",
      " -62.576538 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  7 target diff:  0.0017264051856818005 values:  -62.6312 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026985889334184615 values:  -51.306133 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017304370389065456 values:  -62.594486 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019668870103844035 values:  -51.298607 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015846586029290262 values:  -62.684605 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019165165892576276 values:  -62.701572 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018102973563678462 values:  -51.357372 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  11 target diff:  0.0013757774141170734 values:  -62.76176 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!4\n",
      " Refresh buffer every 1000000 sampling!\n",
      "target diff:  0.0023140258829941096 values:  -51.32479 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  5 target diff:  0.0018174856570167665 values:  -51.316525 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019244062765536199 values:  -51.25469 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021661205290495647 values:  -51.211597 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001891251810432488 values:  -51.22586 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.0022421584729738044 values:  -51.204197 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0024866194409017954 values:  -51.16389 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9129863905652762 values:  -54.76981 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0042558182859178265 values:  -54.736126 ----- -----iteration: \n",
      " \n",
      "11 target diff:  0.0028593585767938178 values:  -51.13842 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002910080602553856 values:  -54.688694 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025320904105531005 values:  -54.673138 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016909348133233829 values:  -51.172962 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019321193165622581 values:  -54.65331 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.002049856174351587 values:  -54.639717 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024066481252850267 values:  -51.149117 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.918301205532135 values:  -62.904438 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017970598399518396 values:  -54.707855 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0020681973775269844 values:  -51.16973 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0040021773924752485 values:  -62.81618 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002075280383783811 values:  -54.6278 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002426842839079772 values:  -51.16524 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0037064182919198893 values:  -62.724945 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016815275935886129 values:  -54.65656 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026548802012281063 values:  -62.768406 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018851876223492398 values:  -51.149075 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001918297547153408 values:  -62.83308 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019357281805139127 values:  -54.593594 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021755778871622744 values:  -51.023785 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016343960027564682 values:  -62.909756 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0013600845818409664 values:  -62.884644 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0016904232466885933 values:  -54.64668 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021802220408349035 values:  -50.985638 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0022917672075899315 values:  -54.65338 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002405091117230803 values:  -54.672436 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002189726878789537 values:  -51.064915 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0025994908401762284 values:  -54.5881 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0031413628396187256 values:  -50.98141 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0015800942558321894 values:  -54.527275 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0020322735193912334 values:  -50.923016 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0022677957721236107 values:  -----iteration: -54.435818 22 ----- target diff:   \n",
      "0.002548757831440393\n",
      " values:  -50.837917 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  23 target diff:  0.002018567323956564 values:  -50.78607 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020680040790633175 values:  -54.429302 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0019025274915367037 values:  -50.59498 ----- \n",
      "\n",
      "-----iteration: -----iteration:  17 0  target diff: target diff:  0.0014683735433110526  0.9178940245522326values:   -54.43091values:   -62.459812-----  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  1 target diff:  0.00432878581664824 values:  -62.53213 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002097607538595682 values:  -50.401165 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0035171339873485137 values:  -62.489887 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0028770712140939094 values:  -50.307148 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002479216168984296 values:  -62.503723 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019099631395942908 values:  -62.608974 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002001254761256862 values:  -50.130756 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018443345998267093 values:  -62.720295 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0023350028941590112 values:  -50.015728 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018678961848316918 values:  -62.765408 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002160254273860631 values:  -49.886265 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016004095217682574 values:  -62.8349 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002347701141778595 values:  -49.738293 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019345526768043415 values:  -62.80839 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  31 target diff:  0.0021851892160210137 values:  -49.596252 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019649312333634697 values:  -62.84597 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002105144399747693 values:  -49.43942 -----iteration: -----  10\n",
      " \n",
      "target diff:  0.0017816185577487114 values:  -62.821186 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9115960254165563 values:  -50.217094 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016188186243845859 values:  -62.865814 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0017402514221876678 values:  -49.202328 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003829067956915501 values:  -50.24975 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0013300126663420536 values:  -62.855762 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  34 target diff:  0.002061071277539854 values:  -49.02415 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!-----iteration: \n",
      " 2 Refresh buffer every 1000000 sampling!\n",
      "target diff:  0.002524229275535362 values:  -50.2229 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  35 target diff:  0.0020732485047976596 values:  -48.748146 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019257946825346451 values:  -50.291355 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002590060777641726 values:  -48.592834 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0017656254276163907 values:  -48.471165 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002249259036804763 values:  -50.343536 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017199216526838452 values:  -48.316715 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017793906071317583 values:  -50.30276 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0014968393434090465 values:  -48.20459 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "--------------------Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl! \n",
      "fqe on dqn & saleRefresh buffer every 1000000 sampling! \n",
      "--------------------WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  6 target diff:  0.001538698421201699 values:  -50.288765 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022985927843859684 values:  -50.25548 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  8 target diff:  0.0019595608390096404 values:  -50.311237 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016150407546358296 values:  -50.318295 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013444741379420506 values:  -50.294575 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "--------------------WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel fqe on dqn & sale\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias --------------------\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  0 target diff:  0.917960056616567 values:  -62.94499 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.006169973918471277 values:  -62.94608 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002751109028470698 values:  -62.939037 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020652009245440087 values:  -62.950153 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  4 target diff:  0.002038071537220564 values:  -62.963535 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.0016029747997272047 values:  -62.9679 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.912722061797839 values:  -51.42029 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017078905311647598 values:  -63.02276 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003416730354845467 values:  -51.399807 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016123023057572597 values:  -63.0369 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025314629973512545 values:  -51.384624 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0012675452909258807 values:  -62.953457 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019912276959076457 values:  -51.386604 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.001844446101501863 values:  -51.48292 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018998499178112904 values:  -51.51579 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001697296611513604 values:  -51.495754 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9126897618477225 values:  -52.48911 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0036778715956035956 values:  -52.476048 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015088939529348765 values:  -51.457207 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017233833624757066 values:  -52.516605 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016586087469644178 values:  -51.426777 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.00253862985079619 values:  -52.59438 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.0016537908261973072 values:  -51.508087 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017719062073125384 values:  -52.627556 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016678103342529027 values:  -52.705944 ----- -----iteration: \n",
      " \n",
      "10 -----iteration: target diff:  0 0.0018141672928730453 values:  target diff:   0.9168653878551594-51.51804 values:   ------61.03825  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  11 target diff:  0.0013516330970484347 values:  -51.510616 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0013907296881898812 values:  -52.80505 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004840482515546037 values:  -61.051 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0026446588765803645 values:  -61.037495 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021877609277854092 values:  -61.053093 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002231791216955441 values:  -61.08094 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020590711716083304 values:  -61.068707 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016946510763574151 values:  -61.080086 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.001801385005173779 values:  -61.14712 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8 target diff:  0.0015627166544658368 values:  -61.220642 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.914058844636357 values:  -52.196575 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9135591265706988 -----iteration: values:   9-54.884163  target diff: -----  \n",
      "0.00157907527462186\n",
      " values:  -61.235447 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002658577802370913 values:  -52.288635 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001163207035215084 values:  -61.331123 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  1WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biastarget diff: \n",
      " 0.0037337176302284962 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelvalues:  -54.833897 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-----\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  2 target diff:  0.002113250309945302 values:  -52.26047 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  2WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " target diff: \n",
      " 0.0025978904183118494 values:  -54.85854 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.002581245767331403 values:  -54.84846 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022498817685733885 values:  -52.28024 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.003352460626706995 values:  -54.920044 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002381290716723188 values:  -54.90057 -----iteration: ----- 4 \n",
      " \n",
      "target diff:  0.0018454256252900154 values:  -52.23348 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023835367757050327 values:  -54.99401 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00128723483722576 values:  -52.26526 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!-----iteration: \n",
      " Refresh buffer every 1000000 sampling!7\n",
      " target diff:  0.002203561788718028 values:  -55.0371 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  8 target diff:  0.0019829102764162276 values:  -55.066772 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001678623952558809 values:  -55.08988 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0016019647333045228 values:  -55.056305 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  11 target diff:  0.002205035459451589 values:  -55.01144 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016108799706790221 values:  -54.970463 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0015141229395913575 values:  -55.048798 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.0019961151793054504 values:  -55.020283 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.00254871881707432 values:  -55.043056 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.918785818535305 values:  -62.71964 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003988343313676739 values:  -62.724 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  16 target diff:  0.0023641272608854688 values:  -54.979797 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002595496181088842 values:  -62.791504 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9122318295178737 values:  -50.889282 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019582807379013084 values:  -62.832706 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0030290648721982933 values:  -55.02348 ----- \n",
      "\n",
      "-----iteration:  1 target diff: -----iteration:   0.0023928799401453074  values: target diff:   -50.8508380.002174827687472737 -----  values: \n",
      " \n",
      "-62.804165 ----- \n",
      "\n",
      "-----iteration:  18-----iteration:   2target diff:   0.002163186283682753target diff:  0.002149923856291373  values: values:   -55.014183-50.887714 ----- ----- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  5 target diff:  0.0014075403472877939 values:  -62.856537 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018588289530083715 values:  -50.936893 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002845012768404207 values:  -55.016914 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018346610142099531 values:  -50.92056 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016763139450878969 values:  -50.952385 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003052994839299341 values:  -55.115044 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001560115734259783 values:  -50.889496 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0036528412133290224 values:  -55.23166 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001819720997954763 values:  -50.928253 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002254886902466862 values:  -55.325775 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001301364226492952 values:  -50.96698 WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  23 target diff:  0.0025653622197368635 values:  -55.262592 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.00241573259992782 values:  -55.209984 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9159951205933304 values:  -60.43149 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.003245427126127098 values:  -55.160225 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00527317406984024 values:  -60.47332 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002686460057746116 values:  -55.07831 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.004781919274421497 values:  -60.523464 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0022979323295594526 values:  -55.07784 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.00250629570881731-----iteration:  values:  3 -55.02698  target diff: -----  \n",
      "\n",
      "0.003278310872204684 values:  -60.572002 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0025929860959134853 -----iteration: values:   4-55.037224  target diff: -----  0.002399702617196827 \n",
      "values: \n",
      " -60.59713 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.0026867473145843 values:  -60.652153 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0025408762752711874 values:  -55.04889 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9121670863324823 -----iteration: values:   6-51.144127  target diff: -----  0.0018965052843928677\n",
      " \n",
      "values:  -60.700706 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.003373950354925645 values:  -55.061214 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002862098643090048 values:  -51.14484 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00206783218696934 values:  -60.70405 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003044710973559717 values:  -55.038486 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023359258723476576 values:  -60.71826 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020117352270218737 values:  -51.154644 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022050816621205947 values:  -----iteration:  -60.715833  ----- target diff: \n",
      " \n",
      "0.0021321707807376465 values:  -54.9782 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020458982250603453 values:  -51.15615 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0030801728461673696 values:  -54.89972 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020671520867312125 values:  -60.721294 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021949315847546924 values:  -51.14322 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002377948734639382 values:  -54.83484 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018971439231381532 values:  -60.785587 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002658418907860209 values:  -54.74311 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018293831302678117 values:  -60.81568 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001657003377333992 values:  -51.08903 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0027648531654911484 values:  -54.772774 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019896865861581477 values:  -60.838894 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019400288875377493 values:  -51.08269 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0017089415074405445 values:  -60.840034 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0029268539381033403 values:  -54.68539 ----- \n",
      "\n",
      "-----iteration: -----iteration:   157  target diff: target diff:   0.00220682312689953530.0016294513642258234  values: values:   -60.84089-51.068047  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration: -----iteration:   398  target diff: target diff:   0.0027498776508213150.0017330824269861178  values: values:   -54.586235-51.043324  ----- ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  16 target diff:  0.0019745171639573645 values:  -60.884068 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0033424396883074106 values:  -54.550823 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00171553616194411 values:  -51.0163 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0022173558859647055 values:  -60.951195 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0022980054433445383 values:  -54.440742 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0022291278506452322 values:  -60.98791 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0025174167377983283 values:  -54.428776 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001723024657510075 values:  -50.962452 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0026538937552361133 values:  -54.309776 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.001787470016426355 values:  -61.023888 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0014495478361867464 values:  -50.952923 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  44 target diff: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl! \n",
      "0.0024382826583022404 Refresh buffer every 1000000 sampling!\n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-54.20026\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!20\n",
      " Refresh buffer every 1000000 sampling!target diff:  \n",
      "0.0018649070932650075 values:  -61.083412 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  45 target diff:  0.002279377215780371 values:  -54.15589 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0014471990391458855 values:  -61.20446 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  46 target diff:  0.0023942605428488345 values:  -54.109562Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl! -----\n",
      " Refresh buffer every 1000000 sampling!\n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "-----iteration: Refresh buffer every 1000000 sampling! \n",
      "47 target diff:  0.0018840243242752768 values: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "-54.019 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  48 target diff:  0.0020772705661540364 values:  -53.947746 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002253165532003292 values:  -53.875034 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.00274663998273402 values:  -53.7841 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  51 target diff:  0.0021263635625905957 values:  -53.73514 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "52WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biastarget diff:  \n",
      "0.0040271030382501615 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelvalues:  -53.69911 \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias-----\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      " \n",
      "\n",
      "-----iteration:  53 target diff:  0.001961676765184776 values:  -53.621468 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0020147798558053103 values:  -53.54883 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002128876561680391 values:  -53.524426 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0018892589175687044 values:  -53.471184 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  57 target diff:  0.002317260361360011 values:  -53.41831 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9124439838525903 values:  -50.96766 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0020556652232038603 values:  -53.43929 ----- \n",
      "\n",
      "-----iteration:  59-----iteration:   target diff: 1  target diff: 0.0027577863551242854  0.0016922149541232611values:   values:  -53.365276-50.97294  ----------  \n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  60 target diff:  0.002306255646509761 values: -----iteration:   -53.3232422 ----- target diff:   0.0016559241247025304\n",
      " values: \n",
      " -50.97024 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020257878646655013 values:  -51.001457 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0019628524233049143 values:  -53.28506 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9178047183713363 values:  -63.173523 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001929027525074837 values:  -50.998684 -----iteration:  -----62  \n",
      "target diff:  \n",
      "0.0024708912623451007 values:  -53.220146 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003132968670690374 values:  -63.195408 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0020695935555364686 values:  -53.162273 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001405598979686868 values:  -50.991386 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017905449368433297 values:  -63.15582 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0020041478520261844 values:  -53.120056 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002580810589207831 values:  -63.13534 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.001779081559714089 values:  -53.035595 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001415650356035762 values:  -63.106266 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0026511510299586463 values:  -52.914227 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0019965620200901616 values:  -52.747997 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0018241234694309544 values:  -52.586052 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  69 target diff:  0.0018476485992026922 values:  -52.351818 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002150981633447579 values:  -52.08637 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  71 target diff:  0.002194829084245086 values:  -51.911713 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9111400739129936 values:  -51.892155 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0019896528322187468 values:  -51.713947 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.0047450216390062154 values:  -51.87022 ----- \n",
      "\n",
      "-------------------- -----iteration: ckpt:   735000  target diff: -------------------- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002631912548945426 values:  -51.46924 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent/trajs.pkl!\n",
      "\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 target diff:  0.0024921225287840736 -----iteration:  74values:  target diff:   -51.8019 0.0018838724523780486-----  values: \n",
      "\n",
      " -51.284756 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  0 target diff:  0.9174705576063014 values:  -62.548985 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002070744158145979 values:  -51.017735 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002418122435193112 values:  -51.812744 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005990273078024911 values:  -62.539894 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0027951372605066025 values:  -50.883423 ----- \n",
      "-----iteration: \n",
      " 4 target diff:  0.002316190248855784 values:  -51.81298 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029808223982743364 values:  -62.524605 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002070146051240912 values:  -51.80017 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0027850842057534782 values:  -50.785034 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025372829654081897 values:  -62.57504 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016619893730228537 values:  -51.79538 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002426388863789677 values:  -62.607246 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0028000339315872353 values:  -50.615574 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015979725674407968 values:  -51.78538 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  5 target diff:  0.0018063790763093843 values:  -62.609722 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0030825530920496323 values:  -50.60797 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018504682594645044 values:  -62.581245 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018302959662601635 values:  -51.75516 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0032317281457582272 values:  -50.555805 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018056271143939468 values:  -62.56658 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002026493590727777 values:  -51.713135 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017611039714459447 values:  -62.46207 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.003262864483486681 values:  -50.49871 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018385427452540493 values:  -51.687344 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002279289330967377 values:  -62.503716 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.003447778782556431 values:  -50.35309 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015743223336258114 values:  -62.47452 ----- \n",
      "-----iteration: \n",
      " 11 target diff:  0.002391921304651522 values:  -51.707256 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015472977591239597 values:  -62.45542 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.004020059221895188 values:  -50.275818 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021144986051450355 values:  -51.65551 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0012658985973915881 values:  -62.47801 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----iteration: \n",
      " 84 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias0.0035356515543924585\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelvalues: \n",
      " -50.21335 -----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  13 target diff:  0.001605925886535603 values:  -51.67397 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.003321382507953643 values:  -50.118076 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9153007813221421 values:  -58.985867 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0027737628028421425 values:  -51.722317 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0030949906523227567 values:  -50.092255 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0015021093957926913 values:  -58.956318 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002236768683077395 values:  -51.72733 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017954303624313005 values:  -58.94968 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.003009428645009879 values:  -49.98283 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017240076869022767 values:  -58.876915 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002409557477813225 values:  -51.72397 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.003191479905447421 values:  -49.87547 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale -----iteration: -------------------- \n",
      "4WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biastarget diff:  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel0.001828935373312705\n",
      " values:  -58.90688WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "\n",
      "-----iteration:  89 target diff:  0.0025248808112789544 values:  -49.741238 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0022792789337572417 values:  -51.80976 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001496960844470899 values:  -58.80147 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.003083357222007059 values:  -49.68518 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0024819746099647017 values:  -49.65528 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0030071969584367147 values:  -51.70316 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.002453918664038631 values:  -49.643227 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0026006436788908044 values:  -51.609577 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0023805733789012337 values:  -49.605473 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0022931948049418256 values:  -49.605145 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023236855601106933 values:  -51.430016 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0021822679030721573 values:  -49.62412 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  21 target diff:  0.0027040273075333234 values:  -51.29936 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  96 target diff:  0.0022888628492235513 values:  -49.645332 ----- \n",
      "\n",
      "-----iteration:  97 target diff: -----iteration:   0.001878527968820363422  values: target diff:   -49.739780.0024601720313711804  -----values:  \n",
      " \n",
      "-51.11247 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9177573887212248 values:  -62.584126 ----- \n",
      "-----iteration: \n",
      " 0 target diff:  0.9152392917180505 values:  -57.740498 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0018251398072252263 values:  -49.81733 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.003004648946563411 values:  -50.940063 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0037261937840261635 values:  -62.51177 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0036055445982455204 values:  -57.784016 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  -----iteration: 0.0019457345966711439  24values:  -49.87429 target diff:   0.0023559887895127484----- \n",
      " values:  \n",
      "-50.865337-------------------- -----  ckpt: \n",
      " \n",
      "30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel 2\n",
      " target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0025160934159655494\n",
      " values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "-62.517082 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!-----iteration: \n",
      " 2 target diff:  0.0025140371622089613 values:  -57.7583 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  25 target diff:  0.0021606379295776254 values:  -50.782017 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner -----iteration: -------------------- 3\n",
      " target diff:  0.0018729718623845392 values:  -62.4748 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.001970168627943935 values:  -50.658566 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001769509134975808 values:  -57.53321 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001769614919384927 values:  -62.44112 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0026256100236318842 values:  -57.493294 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0023220927075750003 values:  -50.428154 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023270590847666406 values:  -62.520695 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0015688310261296322 values:  -57.532845 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0026130693682789355 values:  -50.317635 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018697107283913161 values:  -62.57931 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015927556565305547 values:  -57.586983 ----- \n",
      "\n",
      "-----iteration:  29-----iteration:   target diff: 7  0.0023767750246013824--------------------target diff:    0.0013985635569660029values:   fqe on dqn & salevalues:  -50.138573 ---------------------62.55972 \n",
      "-----  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  7 target diff:  0.0015891172204960072 values:  -57.62759 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002218236515821188 values:  -50.005642 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019333170927154405 values:  -57.604404 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0025375891422777584 values:  -49.81137 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017268197081612526 values:  -57.643776 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0022560611033982923-----iteration:   values: 10  -49.565483target diff:   ----- 0.002083984640352554 \n",
      "\n",
      "values:  -57.7139 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0023043110039606407 values:  -49.452656 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019351252584963968 values:  -57.687775 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  34 target diff:  0.002202834999389756 values:  -49.212368 ----- \n",
      "\n",
      "-----iteration:  12 target diff: WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----iteration:  \n",
      "0.0022057731084784435\n",
      "  35values:   target diff: -57.73315  0.002301195153582737-----  values: \n",
      " \n",
      "-49.057102 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.00213525645609233 values:  -48.85197 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9129754047578494 values:  -----iteration: -53.073128  0-----  \n",
      "target diff: \n",
      " 0.9176222721060179 values:  -----iteration: -62.619873  13 -----target diff:  \n",
      "\n",
      " 0.002061389384765032 values:  -57.791164 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0029210111392219476 -----iteration: values:   -53.04863737  target diff: -----  0.0021774335805592746\n",
      " values: \n",
      " -48.61316 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0047894321672417965 values:  -62.688442 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002618416099246668 values:  -57.748177 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024433944828824296 values:  -53.013863 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0020783945889485114 values:  -48.40229 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003008450742997734 values:  -62.648857 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020550743994569823 values:  -52.971027 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0020106656194700165 values:  -----iteration: -57.7658  -----39  target diff: \n",
      "\n",
      " -----iteration: 0.0018867198103453805 3 target diff:   values:  -48.159264 -----0.002824025162059609 values:   -62.672398\n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001986183034616275 values:  -52.98409 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022132845469578924 values:  -62.655407 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002510768105547756 values:  -47.916653 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019796767570981586 values:  -52.92049 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0015967986725486142 values:  -57.735493 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0018525114868169934 values:  -47.673313 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  -----iteration:  6 target diff: 0.0022585465289792625  0.0016945183149892854values:   -62.622887values:   -53.017544-----  -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  42 target diff:  0.0024329443320508454 values:  -47.53168 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002130287511127193 values:  -57.709633 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023093502019124507 values:  -62.524178 -----iteration:  7----- \n",
      " target diff: \n",
      " 0.0016477773100823424 values:  -53.071342 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0019058203035424055 values:  -47.363342 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0016803399272507596 values:  -57.60755 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019241352067434186 values:  -53.05794 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00237680048282889 values:  -62.54608 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0018434973043322974 values:  -47.215435 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00163049883758621 values:  -53.06012 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002396634068109368 values:  -57.559483 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002125899561677636 values:  -62.51621 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002194716164528004 values:  -47.038 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014270105313781206 values:  -53.02265 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022917708511314134 values:  -57.484 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0021726191898807667 values:  -46.848442 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001913437161429443 values:  -62.496433 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002254722008760347 values:  -46.688477 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019372406830450624 values:  -62.575134 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0023647973778808643 values:  -57.404472 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0019404821466801549 values:  -46.53841 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0017214150766749448 values:  -62.553303 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.001713399000481593 values:  -57.356567 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0019479937779173753 values:  -46.34997 ----- \n",
      "\n",
      "-----iteration:  23-----iteration:  12  target diff: target diff:   0.00151707143067411080.002304590184357482  values:  -62.603874 ----- values: \n",
      "\n",
      " -57.405544 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0019745243336229696 values:  -46.161736 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.001977184737730704 values:  -57.414883 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002237013992134292 values:  -45.885124 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016624498231109237 values:  -62.603718 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0021217949660983426 values:  -57.39512 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0022788992666914376 values:  -45.769794 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001859374647949096 values:  -62.62881 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0016187805828260995 values:  -57.331543 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  53 target diff:  0.0017349515428344404 values:  -45.58471 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001604791672055649 values:  -62.660103 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0021996023211548034 values:  -45.46065 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0022847612987576824 values:  -57.222847 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9120294032489149 values:  -53.497894 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0016375375105906656 values:  -45.347256 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0017062665559519174 values:  -57.19054 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0013868115833969594 values:  -62.70618 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  1 target diff:  0.005514346459824838 -----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "-53.480766WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel  56\n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel target diff:   \n",
      "\n",
      "0.002235461035360066\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasvalues:  \n",
      "-45.269207WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. -----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel29\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biastarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel0.0018598000102014595 \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasvalues:  \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-57.1576 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target diff:  \n",
      "0.0037674158348555324-----iteration:   values: 57 -53.534973  -----target diff:   \n",
      "0.0014680739877715012 values: \n",
      " -45.142254 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-------------------- adv learnerWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      " --------------------WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  30 target diff:  0.001918384850939531 values:  -57.18198 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  31 target diff:  0.0019036540914520006 values:  -57.124607 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002431943406766608 values:  -53.587727 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002061820292864998 values:  -53.62307 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0017172381698530048 values:  -56.963215 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017776680218506249 values:  -53.574455 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  33 target diff:  0.0032732389169283513 values:  -57.014156 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0013127075980476596 values:  -53.594933 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  34 target diff:  0.0022712728432420872 values:  -56.871372 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  35 target diff:  0.0021582619450019806 values:  -56.74868 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0022866378301479484 values:  -56.586395 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  37 target diff:  0.0021447439543771448 values:  -56.44656 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002202348415643485 values:  -56.37497 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9190460820711343 values:  -63.701626 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0017111282234096564 values:  -56.305122 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  40 target diff:  0.001582599018482104 values:  -56.172993 -----iteration: -----  \n",
      "1\n",
      " target diff:  0.003450545143131874 values:  -63.728394 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0011797938395803217 values:  -56.090096 ----- -----iteration: \n",
      " \n",
      "2--------------------  target diff: ckpt:   0.00253400844128689510000  --------------------values: \n",
      " -63.745266 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  0 target diff:  0.9128370750373201 values:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/trajs1.pkl!-50.452656\n",
      " Refresh buffer every 1000000 sampling!\n",
      "----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  3 target diff:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "0.0018692827590196333\n",
      " values:  -63.749874 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  1 target diff:  0.001908624421578232 values:  -50.498188 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001788089833076104 values:  -63.701702 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.0015422003480423942 values:  -63.62101 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0015470543374397725 values:  -50.550957 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014969132201792447 values:  -50.627144 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015314637086372334 values:  -63.699406 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9104757022253869 values:  -52.96574 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015955807432992413 values:  -63.62753 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003659717724994874 values:  -52.958683 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  8 target diff:  0.0012342339685535498 values:  -63.599266 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024980339485999466 values:  -52.947147 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018394845823314226 values:  -52.96903 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001410670301140717 values:  -52.886787 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.912066953868512 values:  -51.33553 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005403794049862456 values:  -51.368675 -----iteration: -----  0 \n",
      "target diff: \n",
      " 0.9150260150106614 values:  -59.36784 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9172849625723304 values:  -61.31774 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 target diff:  0.00312649004857748 values:  -51.382793 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00364463372325251 values:  -61.273438 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001465906391960283 values:  -59.310966 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025444453399264206 values:  -51.3773 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025709191448168764 values:  -61.366283 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002163464056024039 values:  -51.392693 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9124947163397467 values:  -51.53254 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022671804733746274 values:  -61.325985 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017953459936350315 values:  -51.35263 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0037005768505518804 values:  -51.47817 -----iteration: -----  4 \n",
      "target diff:  \n",
      "0.002190989332844059 values:  -61.42307 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002088376200420273 values:  -51.380466 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002671623379378672 values:  -51.439697-----iteration:   -----5  \n",
      "target diff: \n",
      " 0.002136583274928481 values:  -61.453846 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018077760130357989 values:  -51.36942 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015183243647136893 values:  -61.379597 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020875693955930675 values:  -51.48238 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0014859394881169261 values:  -51.36056 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "-----iteration:  7 target diff:  0.00137635050324212 values:  -61.41966 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001670322858828807 values:  -51.502163 ----- \n",
      "\n",
      "-------------------- training agentLoaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!\n",
      " Refresh buffer every 1000000 sampling!--------------------\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelLoaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "Refresh buffer every 1000000 sampling!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!5\n",
      "Refresh buffer every 1000000 sampling! target diff: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0013751859414289302 values:  -51.51435 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!Refresh buffer every 1000000 sampling!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelWARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-------------------- adv learner --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  0 target diff:  0.915555915220352 values:  -59.237614 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0015621691257619056 values:  -59.193455 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017370763036513837 values:  -59.090557 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001949089114763582 values:  -59.098785 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  4 target diff:  0.0016954514965816642 values:  -59.067417 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  5 target diff:  0.0018636214627539536 values:  -59.00462 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020688946290609122 values:  -58.899048 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022403257309114954 values:  -58.864094 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016769673779981262 values:  -58.810688 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002116097493325183 values:  -58.763767 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015406449839238062 values:  -58.744755 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  11 target diff:  0.0017337919727875835 values:  -58.619263 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  12 target diff:  0.0022796108586072153 values:  -58.537556 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  13 target diff:  0.0021746560132783962 values:  -58.474514 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018125760518625251 values:  -58.44281 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9127662487806484 values:  -50.85882 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9131283395064794 values:  -52.14632 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0017581852714359393 values:  -58.434933 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0012434181328674773 values:  -50.908638 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004016318734105943 values:  -52.146023 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0024032836360575196 values:  -58.500576 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002152234376821669 values:  -52.10734 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0024828912928151975 values:  -58.26169 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001871072614008262 values:  -52.183937 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021211938004923746 values:  -52.09564 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.003911544236078459 values:  -58.264492 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021920198669529794 values:  -52.06622 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020834065773057287 values:  -58.246426 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018400214233543813 values:  -51.991646 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0017928741096510101 values:  -58.21596 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0015390558392735555 values:  -58.12201 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002631190857671088 values:  -51.93741 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8 target diff:  0.0015725417458902233 values:  -51.957054 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0033183659918650534 values:  -58.006348 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015247392577869485 values:  -51.949284 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018812346565273003 values:  -57.9155 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9117090721074199 values:  -52.123882 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.006245916137019787 values:  -52.19399 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0017787752973083318 values:  -57.855076 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014713070495713132 values:  -51.85148 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0035150285670764413 values:  -52.156803 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002057819104275756 values:  -57.86392 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002622780456894305 values:  -52.179226 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018601634866422575 values:  -57.832397 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028196704137168826 values:  -52.19534 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023679522615210834 values:  -52.17002 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002117293897915507 values:  -57.67422 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001987483048414612 values:  -52.212578 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0020419962425720236 values:  -57.603344 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015890492625913913 values:  -52.175972 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002152966889982188 values:  -57.368572 ----- \n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "-----iteration:  8 target diff:  0.0016674287909017827 values:  -52.12852 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002554478628404326 values:  -57.26935 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001751828289392388 values:  -52.09295 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9101053128311946 values:  -52.92742 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0021203906554136155 values:  -57.073536 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0017580329041284152 values:  -53.016445 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018968156717269352 values:  -52.099976 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002248655655290906 values:  -56.995552 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0016157375390019957 values:  -53.120266 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001989915846903995 values:  -56.837864 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001463877719210055 values:  -53.129246 ----- \n",
      "\n",
      "-------------------- ckpt: -----iteration:   11 45000 target diff:  0.0013191337296155235--------------------\n",
      " values:  -52.091694 ----- \n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "-------------------- ckpt:  50000 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias--------------------\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent/trajs.pkl!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernelWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasWARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold2/train/agent4/trajs4.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "-------------------------iteration:   adv learner34  --------------------target diff: \n",
      " 0.001989934182689706WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "values:  -56.700188 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  35 target diff:  0.0017054420565985981 values:  -56.59681 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0016916917502628225 values:  -56.48392 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  37 target diff:  0.0016392469916766974 values:  -56.34515 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  38 target diff:  0.0026469701837264323 values:  -56.191895 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.00234401763577715 values:  -55.924152 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0024718720070396804 values:  -55.687447 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0023514986505971973 values:  -55.463543 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0021107080522644772 values:  -55.28744 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0016717587702728587 values:  -55.122944 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  44 target diff:  0.0017817552154788488 values:  -54.98465 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0032315710533570305 values:  -54.885433 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9119396026357659 values:  -51.464985 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9139801552826775 values:  -54.664665 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0021446256152650393 values:  -54.712383 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0010764698862604446 values:  -51.486004 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003117023768075383 values:  -54.71563 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002596581518368507 values:  -54.747856 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018653206675641046 values:  -54.39655 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.001772239202085934 values:  -54.26202 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014902662178964059 values:  -54.73413 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0019896382689152748 values:  -53.747524 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002490208702757923 values:  -53.54061 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  51 target diff:  0.002367736299595577 values:  -53.338207 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0017069974967912288 values:  -53.148277 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9117123542634411 values:  -51.578247 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0019596940160179193 values:  -52.991726 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  54 target diff:  0.0016029793240376095-----iteration:  values:   -52.783431  -----target diff:   \n",
      "0.005368901280606736 values:  \n",
      "-51.60866 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003856063904440734 values:  -51.659126 ----------iteration:   55\n",
      "\n",
      " target diff:  0.0017912750455668443 values:  -52.61859 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9114014086013366 values:  -52.411064 ----- \n",
      "\n",
      "-----iteration: -----iteration:   356  target diff: target diff:   0.00167924007882843340.0025839094513612814  values: values:   -51.74403-52.409267 -----  \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  1 target diff:  0.001454416291907518 values:  -52.340446 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  4Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent2/trajs2.pkl! \n",
      "target diff: Refresh buffer every 1000000 sampling! 0.00247528696316587\n",
      " values:  -51.723736 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  57 target diff:  0.0016592357629765585 values:  -52.21991 ----- \n",
      "--------------------\n",
      " adv learner --------------------\n",
      "-----iteration: -----iteration:   558  target diff:  0.0015821364206818436 values: target diff:   0.002392479458969997-52.043064  values:  -51.688652 ---------- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  59 target diff:  -----iteration: 0.0016591148278794396  6values:   target diff: -51.85953  0.0017101733604314156-----  \n",
      "values:  \n",
      "-51.688286 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0018140988155684722 values:  -51.61955 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001826640823780506 values:  -51.66571 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  61 target diff:  0.0016804186164588797 values:  -51.44759 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017967153695792708 values:  -51.62791 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0014452038242749109 values:  -51.268547 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "9WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias target diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel0.0014310258428500537\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel-51.679558\n",
      " ----- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9129798980713464 values:  -53.021484 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027552890276506497 values:  -52.992302 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0015898648349605949 values:  -53.00083 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0013610639061387906 values:  -53.09425 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9154003481307611 values:  -58.577553 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0019095674049245744 values:  -58.483727 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0013461259974239133 values:  -58.387474 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9135072930481901 values:  -52.60216 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0011467562933131707 values:  -52.54111 ----- \n",
      "\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9153547053706679 values:  -59.248684 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025420398652988775 values:  -59.260864 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019693172987362974 values:  -59.209743 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018056533517115685 values:  -59.208836 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002005041939118847 values:  -59.140003 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016194666133101234 values:  -59.126854 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018062856912124906 values:  -59.119873 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0014949789289441149 values:  -59.045628 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  0 target diff:  0.9149357199158903 values:  -58.764004 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0024038910273834263 values:  -58.767307 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019618345008603844 values:  -58.7601 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018685450203856286 values:  -58.733856 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  4 target diff:  0.0018708080903746002 values:  -58.799038 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002166636431036377 values:  -58.73584 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018781114361641608 values:  -58.8317 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  7 target diff:  0.002513149188776977 values:  -58.89993 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001988794777734501 values:  -58.83677 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018390439965387973 values:  -58.91679 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0027122537938344023 values:  -58.84551 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021404637870163145 values:  -58.88134 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002184175616275461 values:  -58.86233 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  13 target diff:  0.0016720256877806156 values:  -58.82388 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9119982654977058 values:  -64.68193 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.003267350618022507 values:  -58.834476 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003791195850755277 values:  -64.64186 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018567388662792963 values:  -58.72556 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002092728980413169 values:  -64.660706 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0022319127069803527 values:  -58.66715 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021758666291632075 values:  -64.68779 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00209086839314416 values:  -64.708664 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0016290426413765545 values:  -58.557026 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002212081142344339 values:  -64.75744 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019022579110733325 values:  -64.72661 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020862144359606633 values:  -64.68831 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021148149753090007 values:  -58.653027 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002349228170850359 values:  -64.72318 ----- \n",
      "-----iteration: \n",
      " 19 target diff:  0.0024698321657464477 values:  -58.535 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002272414442696579 values:  -64.748085 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020049434678695017 values:  -64.71801 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002439649372347116 values:  -58.48391 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021962128113189147 values:  -64.73427 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0020274223227789764 values:  -64.71862 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018323569060692524 values:  -58.293736 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0015950998461025981 values:  -64.765434 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0022068779440980865 values:  -64.72825 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018463811939218324 values:  -64.67455 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002317767452171207 values:  -58.30697 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0022736263416354473 values:  -64.6848 ----- \n",
      "-----iteration:  \n",
      "23 target diff:  0.00236703935268568 values:  -58.207256 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002446540999927522 values:  -64.72212 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0017559039165319491 values:  -64.7438 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002325594590151862 values:  -58.088245 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002561260524317842 values:  -64.68558 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0016759162362930831 values:  -57.893158 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023865191322652688 values:  -64.76479 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.00255974448943832 values:  -57.749573 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.00260839018216516 values:  -64.70717 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0022975785715911735 values:  -57.551277 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0027163541648455394 values:  -57.44991 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002474813873253471 values:  -64.71034 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0028888066379035094 -----iteration: values:  -64.63158 29 -----  target diff: \n",
      "\n",
      " 0.002036016245610274 values:  -57.427925 ----- \n",
      "\n",
      "-----iteration:  24 target diff: -----iteration:   0.0031840370400081830  values:  target diff: -64.61632  -----0.002402624711598777  values: \n",
      " \n",
      "-57.23989 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.00291807487428006 values:  -64.55937 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002080342144694423 values:  -57.065918 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002199808764140666 values:  -64.54353 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0021299128920072834 values:  -56.88804 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0030224468832760185 values:  -64.56172 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0023979863060902993 values:  -56.76081 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0019579129305230354 values:  -56.66522 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002357226611333972 values:  -64.564804 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00209278938844723 values:  -64.55987 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019825570903400816 values:  -56.43655 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  30 target diff:  0.001894528708566504 values:  -64.4936 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002227885112247039 values:  -56.299736 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0022402371524035364 values:  -64.52285 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0018389084122215193 values:  -64.56436 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019270776697649097 values:  -55.91306 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0025443426302335084 values:  -64.55325 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002195498876220993 values:  -55.804165 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002166333928258946 values:  -64.52111 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0020937124422639648 values:  -55.655186 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0023907764487003133 values:  -64.492355 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0018794689865878713 values:  -55.40086 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0016714034925328935 values:  -64.462166 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017105642339553776 values:  -55.288994 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0018635594617290514 values:  -64.43123 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0020864674741650625 values:  -55.06222 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0024911713008740365-----iteration:  43  values: target diff:  -64.44199  -----0.0017432447647185826  \n",
      "values:  -54.885212\n",
      " ----- \n",
      "\n",
      "-----iteration:  39 -----iteration: target diff:  44 0.0019314852708382062  target diff: values:   -64.429330.0017411556735273301  ----- values:  -54.79252 \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  45 target diff:  0.0023468788769261217 values:  -54.601227 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0021600718055531844 values:  -64.38874 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.001930370495727642 values:  -54.417088 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001509938085280448 values:  -64.35054 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018870540391498695 values:  -54.181267 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0021413547293312493 values:  -64.3173 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0023036218575109113 values:  -54.02943 ----- \n",
      "\n",
      "-----iteration:  49 target diff: -----iteration:   0.00189279418527919843  values: target diff:  -53.831562  0.0025859158336465514-----  values: \n",
      " \n",
      "-64.31562 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0023017005369047553 values:  -53.685547 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003251210586788548 values:  -64.24433 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.001943957331048422 values:  -53.48066 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0017990783917309254 values:  -53.288235 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.001821254510117543 values:  -64.18947 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.00201954288915738 values:  -53.175564 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  46 target diff:  0.001544813534403775 values:  -64.119316 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0016968155849826688 values:  -52.980705 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0018333495703062468 values:  -52.849148 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0021047757784595817 values:  -64.136024 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002206206855147353 values:  -64.10236 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0015254029990948517 values:  -52.665913 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0023331106509495783 values:  -64.04218 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0017940804358611 values:  -52.451637 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0013325216425717607 values:  -63.997536 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0019251618271413438 values:  -52.15904 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0020750293703101696 values:  -52.01696 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.001583641601213812 values:  -51.81492 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.001824651202921095 values:  -51.6536 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0015832777039197614 values:  -51.480927 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0016163154145355954 values:  -51.325275 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.00156872811439069 values:  -51.171772 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0015265799578194905 values:  -51.036774 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  66 target diff:  0.0015191200289598325 values:  -50.895966 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0015446790234784151 values:  -50.761837 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.913688166053193 values:  -62.356907 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0015582759817180094 values:  -50.64453 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003246160955031116 values:  -62.3879 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.001454411489607932 values:  -50.528725 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028144904705684295 values:  -62.37781 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022955517113197755 values:  -62.39555 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0025137405460331596 values:  -62.37575 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0026029313747458955 values:  -62.447422 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  6 target diff:  0.002263111467884148 values:  -62.567657 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0028878614748330308 values:  -62.610004 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002269781424239606 values:  -62.661263 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9142797650759921 values:  -59.95465 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0024168342645689727 values:  -62.69906 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0029567353349123538 values:  -59.922356 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001917856255192149 values:  -59.91408 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017840680528930267 values:  -62.72801 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021514092775224663 values:  -62.724255 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023087663307848542 values:  -62.69821 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025083801439122508 values:  -59.85911 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019514488314255755 values:  -62.69743 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019313509091999695 values:  -62.797188 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002205165090411047 values:  -59.71534 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.003559577026005285 values:  -59.67571 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0029698897457429096 values:  -62.839058 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022097470193330913 values:  -59.700413 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0024508177232875 values:  -62.830467 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023255755248237737 values:  -59.610027 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002796882481122999 values:  -62.872967 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0023460792752898734 values:  -62.94112 ----- -----iteration: \n",
      " 8\n",
      " target diff:  0.001810272918081651 values:  -59.573284 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022409844431997158 values: -----iteration:   -59.50989519  target diff: ----- \n",
      " 0.0020254134316252553 \n",
      "values:  -62.974926 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022384354519784364 values:  -59.552593 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002717172590565636 values:  -62.881096 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  -----iteration: 0.0025146049428736504 21  values: target diff:   -59.40618 0.0030809361669611127----- values:   -62.947575\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0031522859778140575 values:  -62.974678 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.004091250244215521 values:  -58.9792 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0023315319720124956 values:  -63.0384 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  13 target diff:  0.004504523630975705 values:  -58.846577 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0016659327422364127 values:  -63.019756 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0021884889758778943 values:  -63.04935 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002153366199563251 values:  -58.86529 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0017882188333443808 values:  -63.033504 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.00213288762399782 values:  -58.82078 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001972961430923993 values:  -63.010967 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0019831256044520497 values:  -63.01441 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0025493438279790264 values:  -58.81064 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0024883229745551946 values:  -62.908474 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002269460758328638 values:  -58.649727 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0023539826523452574 values:  -62.84592 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.00234565669650275 values:  -58.647026 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0017554801698816684 values:  -58.59671 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0023673868884524084 values:  -62.697395 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0026567313178585423 values:  -62.594086 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0017624079283617392 values:  -58.56439 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0022857201748922563 values:  -62.59342 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0024038162366998364 values:  -58.38659 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0019295034379089642 values:  -62.53952 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0037401935388273718 values:  -58.31036 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0017685117236088271 values:  -62.520725 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0033323074873279645 values:  -58.178677 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0021158518469934708 values:  -62.453697 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.001990075567188933 values:  -62.421944 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002385657316458271 values:  -58.02704 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001661756143004181 values:  -62.336 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.001825911544436984 values:  -62.32482 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0028240838895222742 values:  -57.91801 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002198940456646961 values:  -62.233196 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023927771076378236 values:  -57.86063 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018775451144937042 values:  -57.81307 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0021186302313648017 values:  -62.122078 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0027314226265767066 values:  -57.561993 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0019402227657313335 values:  -61.990574 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.003548306871868826 values:  -57.442436 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0017744944695348899 values:  -61.896137 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0023686423680072074 values:  -57.40781 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0016431023485008413 values:  -61.784126 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0023007207536751657 values:  -57.335705 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0016208307469160763 values:  -61.670574 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0017174819881429024 values:  -57.300632 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0016750662255677169 values:  -61.63549 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0019389025509679407 values:  -57.2264 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0016559123635379591 values:  -57.171604 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0017909231268535258 values:  -61.58133 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0016924853817442522 values:  -57.04494 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001837500242471284 values:  -64.86419 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017589577389028356 values:  -64.8796 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021984076025535686 values:  -64.821815 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0024399482925603565 values:  -64.74464 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002006718456926917 values:  -64.74376 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  20 target diff:  0.002170880353622611 values:  -64.715225 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0021893095275788386 values:  -64.737625 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0022610467736267044 values:  -64.73659 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002461731056263599 values:  -64.68945 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002600228639475054 values:  -64.68465 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002499790155410777 values:  -64.73449 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002582836599102235 values:  -64.78678 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0028620716320951977 values:  -64.833496 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0024232061214763943 values:  -64.8378 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0024625265113060943 values:  -64.76482 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0026238651932461213 values:  -64.81386 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  31 target diff:  0.002419262369550822 values:  -64.789925 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0022155784700026875 values:  -64.71936 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0029114229633600496 values:  -64.679565 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002670165553751877 values:  -64.601555 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002714265677886538 values:  -64.41769 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0024175815008370977 values:  -64.31669 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0020600315470259574 values:  -64.218666 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.00209256027223859 values:  -64.06075 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0023752416655286467 values:  -63.989014 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0024024890630017833 values:  -63.874702 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001925651177096324 values:  -63.79185 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0024034262802261437 values:  -63.698742 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0018147875194736351 values:  -63.612026 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002179611735099568 values:  -63.55311 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0018976762570483798 values:  -63.411724 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.001868710379694372 values:  -63.280518 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018163841587475536 values:  -63.096157 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0020570098901201736 values:  -62.92365 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0023720763051852853 values:  -62.721676 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0020820258616229327 values:  -62.54081 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0021446618715713476 values:  -62.40858 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0018042488396937824 values:  -62.20579 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  53 target diff:  0.0023904889618504965 values:  -62.00777 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0022539986927883403 values:  -61.865192 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0015059968708297502 values:  -61.682728 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.002343325081448084 values:  -61.54806 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0026237844257757503 values:  -61.31645 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.00220413711032969 values:  -61.180866 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0019231947101806415 values:  -61.044434 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0020530012653153596 values:  -60.964752 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0019006066606155408 values:  -60.84231 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002180686124756224 values:  -60.72189 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0017854078407757588 values:  -60.76471 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0020171911490782057 values:  -60.60924 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0019456620302612416 values:  -60.481804 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0019515189463945792 values:  -60.394997 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0017236114119093453 values:  -60.378147 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0017152483933395059 values:  -60.20581 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0021745135405015297 values:  -60.119877 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0016381849578897397 values:  -59.967793 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.001951075945711244 values:  -59.868366 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  72 target diff:  0.0016855273024408122 values:  -59.837093 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0018426901055887154 values:  -59.776157 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0016790117730865833 values:  -59.765476 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002028559796252296 values:  -59.66306 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0015960528786011818 values:  -59.619205 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0018192717161762777 values:  -59.56582 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0020605852660602144 values:  -59.43586 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0014209148411329382 values:  -59.224266 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  0 target diff:  0.9125675673076128 values:  -64.43554 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004975761151298816 values:  -64.48195 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.004507785961904894 values:  -64.54451 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003474477552670988 values:  -64.55272 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0035476679253214098 values:  -64.63618 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002829171724160975 values:  -64.64324 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0034489720531201175 values:  -64.68329 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002578320389326751 values:  -64.69247 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  8 target diff:  0.0031035285104849893 values:  -64.72893 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002616504624910914 values:  -64.798485 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022817671123605207 values:  -64.87397 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00298863753660057 values:  -64.910194 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022211003486060166 values:  -64.92948 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002144597439356057 values:  -64.98934 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002266853610633426 values:  -64.994804 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0026671300672308374 values:  -65.03626 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002511583199489686 values:  -65.081 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019819016877959655 values:  -65.13557 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002695512614705521 values:  -65.17137 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.003195573502703561 values:  -65.14274 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0028496704525099456 values:  -65.1638 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0030747543650682797 values:  -65.16573 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.003174749197612522 values:  -65.21836 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002985066632475277 values:  -65.24144 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0027480858288579844 values:  -65.26696 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0028354127229979873 values:  -65.260216 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0027342417865084674 values:  -65.2613 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003235466856969891 values:  -65.26256 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0029841892750514403 values:  -65.200874 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002919139979459403 values:  -65.20257 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0031753327744169155 values:  -65.12885 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0030488209102709045 values:  -65.02202 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0029981769398832975 values:  -64.98893 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0021716353667453345 values:  -65.012314 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0023915394200439356 values:  -64.92547 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002944601556558019 values:  -64.89767 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  36 target diff:  0.0030371350994187907 values:  -64.802666 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0026471616607342784 values:  -64.71833 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0027001964379543835 values:  -64.57903 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.003356257071998902 values:  -64.426414 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002812184248516093 values:  -64.285324 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0024369586595595336 values:  -64.15197 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0024239229509281533 values:  -64.035706 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0025787926732751152 values:  -63.92722 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002586329292187956 values:  -63.85644 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003897423165274498 values:  -63.621235 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003355115263454727 values:  -63.502995 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.00210517783124476 values:  -63.26126 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0032767144842342894 values:  -63.085762 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0030196698737301924 values:  -62.954075 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0038113912006955647 values:  -62.80411 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0026074188001658435 values:  -62.58305 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002853058727589746 values:  -62.33115 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0037614988865648327 values:  -62.147514 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0027896227392431735 values:  -61.889683 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0026921243236596656 values:  -61.676403 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0037584809671358656 values:  -61.45889 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.003238473290518065 values:  -61.306835 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.00278852024425578 values:  -61.17464 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0022243329335547603 values:  -61.092598 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  60 target diff:  0.002632744486980229 values:  -61.02294 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0023359698234996116 values:  -60.92789 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0020697883746724132 values:  -60.84074 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.001985821161398656 values:  -60.69611 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0024082266818947038 values:  -60.57137 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0020836252800237294 values:  -60.45594 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0019717459380397375 values:  -60.421753 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0021508224446962925 values:  -60.369045 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002216837275254756 values:  -60.229195 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0017278633415824841 values:  -60.109173 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002268608438889238 values:  -59.976704 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0020394079672026422 values:  -59.885063 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0023424594425529278 values:  -59.802876 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0023777600043403753 values:  -59.709282 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0022280325704813176 values:  -59.567226 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002100578181342847 values:  -59.4221 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002453116590791448 values:  -59.277107 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002122464183824816 values:  -59.17791 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0020114349971816652 values:  -59.022453 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.002172413156831402 values:  -58.93908 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0020155623795194786 values:  -58.812958 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.002369144301114555 values:  -58.669136 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0018403657685314673 values:  -58.57221 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.001824310363716041 values:  -58.43653 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.002382181672530606 values:  -58.26971 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0022243647000494055 values:  -58.09585 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0030846034651857194 values:  -57.99415 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0020932001017586427 values:  -57.89281 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  88 target diff:  0.001659343856538221 values:  -57.77411 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0021995441674743754 values:  -57.703056 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.002035024857666497 values:  -57.638294 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0022464155331271924 values:  -57.486423 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0024249214839097374 values:  -57.3216 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.003014205947858947 values:  -57.169106 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  94 target diff:  0.0025094068781724853 values:  -57.046307 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0021435928289503478 values:  -56.982735 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.002117265602157329 values:  -56.951164 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0020533923715839873 values:  -56.893383 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0029244512360158646 values:  -56.77764 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.002317450203896553 values:  -56.63197 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9141456530896798 values:  -63.694885 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003507671116055376 values:  -63.7512 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003122336367440266 values:  -63.818073 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003816421357637476 values:  -63.801083 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00287624120222365 values:  -63.820698 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00254573429950009 values:  -63.798157 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002698780226736976 values:  -63.895447 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0025291028175907135 values:  -63.969154 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0026909063343471397 values:  -63.9862 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018419881271331518 values:  -64.038536 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002135788249432563 values:  -64.10826 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.003089345316940178 values:  -64.13298 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022840477979664065 values:  -64.17386 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019595280778652263 values:  -64.23388 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0020329245054020737 values:  -64.29345 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0021846396687360383 values:  -64.39392 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002345985704232452 values:  -64.44915 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018319326538682643 values:  -64.496704 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002189687272329864 values:  -64.49329 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  19 target diff:  0.0019409937824747896 values:  -64.49774 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0014986461243308967 values:  -64.495445 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9141059630985681 values:  -64.70681 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004153628939088128 values:  -64.74035 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003743617971094251 values:  -64.8134 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003767650916189637 values:  -64.823616 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.003319914268315971 values:  -64.839424 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002843312727218527 values:  -64.90046 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.003125934379832618 values:  -64.903625 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0029056640562872484 values:  -64.94628 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0026059923494175315 values:  -64.993484 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  9 target diff:  0.003046881951088606 values:  -65.042595 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0024832403288038247 values:  -65.006485 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002250895039678967 values:  -65.05504 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.003095684198019625 values:  -65.06001 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024965032196358756 values:  -65.06842 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.00258863349223115 values:  -65.08183 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.00310390937170421 values:  -65.10813 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.004001659354269546 values:  -65.08144 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.003968862790426251 values:  -65.10555 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.004841348673133158 values:  -65.144264 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0036867962883296163 values:  -65.14246 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003676836285487707 values:  -65.15473 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0030730422699810603 values:  -65.12898 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002868852487207345 values:  -65.08699 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.004322134907597727 values:  -65.03563 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.003243588490128168 values:  -64.98955 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0027501005362138573 values:  -64.90658 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0028944950451774117 values:  -64.76606 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003550469668948858 values:  -64.6776 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.003342863171115321 values:  -64.522224 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.003545970332901494 values:  -64.400986 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0035535190091493577 values:  -64.26567 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0039054426954749635 values:  -64.15371 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0035363501420492714 values:  -64.02916 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0035220941184649955 values:  -63.92863 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0031137960308303125 values:  -63.782154 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0034803266691540414 values:  -63.593296 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  36 target diff:  0.004706802748279472 values:  -63.413307 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.00356940649310361 values:  -63.30441 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0028185512065491266 values:  -63.25817 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002532159236321682 values:  -63.085445 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0036936066182221556 values:  -62.990295 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.002694175896260749 values:  -62.81305 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0034293097224262063 values:  -62.7251 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002618687605452151 values:  -62.64971 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002807971722027199 values:  -62.52757 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0027758736620964934 values:  -62.44254 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002827800428409542 values:  -62.375034 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0023559006316272928 values:  -62.312706 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0025294656853554476 values:  -62.21036 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0026030375837002963 values:  -62.160786 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002847619040168269 values:  -62.01254 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002644634121866421 values:  -61.83195 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0028025598316458672 values:  -61.634686 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002711803378539514 values:  -61.531944 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0020223438605344846 values:  -61.39599 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0023384188158627104 values:  -61.284695 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0031895543638625385 values:  -61.090084 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0021794844533864323 values:  -60.97433 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002854721327396003 values:  -60.786846 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0025018989788196987 values:  -60.64847 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0027947175597731106 values:  -60.44089 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0024682852491111286 values:  -60.42343 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002364235634231441 values:  -60.22465 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0024385893258339754 values:  -60.137634 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0026989026477159347 values:  -59.97077 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002622043386196662 values:  -59.82458 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002941932065709083 values:  -59.639652 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.003066865097828597 values:  -59.45175 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0026786992699139537 values:  -59.352474 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  69 target diff:  0.0027483328129483723 values:  -59.223164 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0021912191906494336 values:  -59.125893 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0024231569965218083 values:  -59.057682 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0036990961227940265 values:  -58.837856 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0023181945499552562 values:  -58.695442 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0024151266697696448 values:  -58.595833 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002387136257520689 values:  -58.58688 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0020891687490328646 values:  -58.577015 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0028603866889277043 values:  -58.44543 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0022031965742423383 values:  -58.4371 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.002376438615955294 values:  -58.343834 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.002204422005010096 values:  -58.273327 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.002733331847252891 values:  -58.19253 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0021001573895329706 values:  -58.0865 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.00232873505055872 values:  -58.07883 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0017509424375362077 values:  -57.976482 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0020701172175501856 values:  -57.929993 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0024570323887609853 values:  -57.927708 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0017615199277355037 values:  -57.85812 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.002382621993143266 values:  -57.707287 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.002147996849393815 values:  -57.616047 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0027706966007522574 values:  -57.480766 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.002369423730762648 values:  -57.390503 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0026178672415989785 values:  -57.233906 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0028063978819060456 values:  -57.074123 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0028039693978361333 values:  -56.96868 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0017219322819115779 values:  -56.894646 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0016027888599906722 values:  -56.780964 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0020516323360463187 values:  -56.672344 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0020135325025091117 values:  -56.634243 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0022856555677951635 values:  -56.50228 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9133983053321962 values:  -65.063675 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004953801074169982 values:  -65.03567 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003851859126865964 values:  -65.06426 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0033480725460229587 values:  -65.045395 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028469369051958657 values:  -65.12517 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0031978566673149644 values:  -65.10768 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0032405523933205943 values:  -65.153114 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.003107917517869018 values:  -65.19129 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0032072075778459253 values:  -65.283615 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.003187042971054388 values:  -65.29093 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002270659160991822 values:  -65.341576 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002036645467644291 values:  -65.33754 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016060108299666457 values:  -65.42159 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0027486296743911317 values:  -65.43971 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0015689484742312221 values:  -65.45443 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0020669672185735267 values:  -65.45806 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020434241049718978 values:  -65.48141 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002005321259228799 values:  -65.5126 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002131624844090776 values:  -65.49858 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0021941200537075795 values:  -65.48899 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0025335626174583814 values:  -65.51739 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0019419943406161792 values:  -65.53123 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_30000.ckpt22\n",
      " target diff:  0.002412619770356321 values:  -65.52588 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0024423551933741594 values:  -65.56317 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0032047600750718308 values:  -65.62237 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.00278578048084002 values:  -65.66631 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0029448271562578215 values:  -65.684425 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002889932463118073 values:  -65.717735 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0022496599751159617 values:  -65.73814 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002804087723261852 values:  -65.734955 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002493126920419001 values:  -65.70471 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0033706968842303784 values:  -65.69157 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002327419069685645 values:  -65.689896 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0035919367960097824 values:  -65.67779 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0034892557722842467 values:  -65.639595 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003339093576310953 values:  -65.57603 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.004115422974338406 values:  -65.52369 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.00357228487614991 values:  -65.50135 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.004721743168920728 values:  -65.41922 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.003913141927111138 values:  -65.39144 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0029288655345280916 values:  -65.3115 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.00304614279070831 values:  -65.27804 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.003563422197281919 values:  -65.29987 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0037184913091534906 values:  -65.3083 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003893348018114901 values:  -65.3093 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003928245342228609 values:  -65.28338 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0037724448204564604 values:  -65.26269 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  47 target diff:  0.0038418384642487794 values:  -65.166534 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.003145036994477796 values:  -65.10887 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0030229754731655534 values:  -64.95476 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0036251277568396475 values:  -64.89511 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0026431420277557493 values:  -64.79308 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.003156257168165119 values:  -64.71972 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0022380137442859424 values:  -64.66375 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0027627777080504374 values:  -64.566734 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  55 target diff:  0.0026691126626541824 values:  -64.48079 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0024084254905319615 values:  -64.41327 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002256029115922786 values:  -64.384415 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002297419469842885 values:  -64.33277 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002282034059009281 values:  -64.195015 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0029062246276356065 values:  -64.112915 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.003367581215123275 values:  -64.07996 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0027924954619621832 values:  -64.04496 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0027120574414224437 values:  -63.96705 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002342797672622459 values:  -63.895203 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0026120898585910894 values:  -63.82141 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0021191777807010323 values:  -63.759346 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0030626773923401506 values:  -63.71873 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  68 target diff:  0.0020810613681923897 values:  -63.626743 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0023322944188880986 values:  -63.54043 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002360036190936598 values:  -63.5029 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.00339706001042914 values:  -63.449238 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002426083814927471 values:  -63.418495 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002251513867371215 values:  -63.376587 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0023966270724825093 values:  -63.375557 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0020901842250328866 values:  -63.350822 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002125872638264981 values:  -63.30971 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0020374283175230916 values:  -63.31014 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.00203212984671429 values:  -63.25995 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0018714028903889636 values:  -63.224453 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.002415346500713434 values:  -63.188137 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0020252261428632145 values:  -63.134174 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0020889025749087145 values:  -63.081055 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002103730102433605 values:  -63.042133 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0021670274673226816 values:  -63.012745 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.002027992234947011 values:  -63.0389 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0026186619111492693 values:  -62.98571 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.002010523118753738 values:  -62.919697 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0023843756355728858 values:  -62.851044 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0034997455253915274 values:  -62.90506 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0020033435009733733 values:  -62.86601 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.002715236410544016 values:  -62.79731 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.00204130473462478 values:  -62.801514 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0017609986663494877 values:  -62.726135 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0022025866384725095 values:  -62.702793 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  95 target diff:  0.0018371212115344236 values:  -62.619446 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  96 target diff:  0.003731452433511485 values:  -62.688267 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0020108898222316314 values:  -62.692966 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0021616278699913834 values:  -62.575603 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0023780353877740717 values:  -62.57223 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold2/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9129059270338203 values:  -64.30162 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004945560086536191 values:  -64.3785 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0046651605517373075 values:  -64.385056 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0038375062342075918 values:  -64.44894 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.004184174609751229 values:  -64.43538 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0029981668725249854 values:  -64.437485 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026448562109752665 values:  -64.46317 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0026828957553593218 values:  -64.465355 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  8 target diff:  0.0025163705091896045 values:  -64.450035 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00253103337631849 values:  -64.42266 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0023230806520135243 values:  -64.47146 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0022322905953015186 values:  -64.51074 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002534525756104449 values:  -64.47317 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  13 target diff:  0.0024428016721875735 values:  -64.43742 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0027938743348708823 values:  -64.408806 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.003823913912213448 values:  -64.3705 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.003410977163188797 values:  -64.3072 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0030691417832615286 values:  -64.34388 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0032449421521313555 values:  -64.24358 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.003962903899375319 values:  -64.20025 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003850703570045503 values:  -64.18638 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002805962703823462 values:  -64.17069 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0028211729251072597 values:  -64.14477 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0030479375537957867 values:  -64.1334 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.003204945174363495 values:  -64.01098 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.003331667621606155 values:  -63.919514 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0024906125613728966 values:  -63.86908 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003099914172966403 values:  -63.73284 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.003495020638949705 values:  -63.66756 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0029159768057139828 values:  -63.561043 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.003639050221411451 values:  -63.490093 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0032745097998624485 values:  -63.43845 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003826953959170138 values:  -63.373055 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0037013367121880515 values:  -63.189785 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.004371814806193145 values:  -63.08944 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  35 target diff:  0.003543172594095389 values:  -62.949734 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0034723416648641207 values:  -62.87466 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0030927320612087767 values:  -62.82843 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0032845033785050956 values:  -62.65742 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.00323653025068312 values:  -62.489994 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0032684317223728916 values:  -62.406963 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0030411178504708134 values:  -62.297375 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0029330693599527867 values:  -62.22705 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0029596514139918774 values:  -62.133953 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0029494261956379744 values:  -62.04328 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0028448670115949343 values:  -62.031765 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.00318643996791915 values:  -61.753216 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.004021493602526977 values:  -61.556866 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0035194886228679355 values:  -61.446037 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0025067706573341795 values:  -61.357822 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002535222151533982 values:  -61.17392 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.003605721439876766 values:  -61.059048 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0031563644355232564 values:  -60.992153 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0029392680084676256 values:  -60.846714 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0029894915852282703 values:  -60.78097 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0039497652181317245 values:  -60.636833 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0028578247852760565 values:  -60.49627 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.003571156293656785 values:  -60.39405 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002694989504534564 values:  -60.32014 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "-----iteration:  59 target diff:  0.0027119462996662916 values:  -60.21963 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  60 target diff:  0.0028519522508692044 values:  -60.145054 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  61 target diff:  0.002800371704583985 values:  -60.018585 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0027343051997931883 values:  -59.87 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002849654106165789 values:  -59.84067 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002893237204355813 values:  -59.695435 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002562916330780716 values:  -59.663208 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002815370976902707 values:  -59.550087 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0026542762356165945 values:  -59.497044 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0033895392536834406 values:  -59.392605 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0025576555230383425 values:  -59.32552 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002447428858714427 values:  -59.241764 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0025562158290678163 values:  -59.235874 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002478590554612057 values:  -59.2226 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0026681986687917417 values:  -59.079487 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.002862956012438686 values:  -59.04171 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002294634010024532 values:  -58.95298 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0027969703869708856 values:  -58.944378 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002578054708001704 values:  -58.767204 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.002696679217465589 values:  -58.68888 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0021968257123876414 values:  -58.636074 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0021657551585649508 values:  -58.597786 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0025803881420946697 values:  -58.602303 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0026882723256775503 values:  -58.515083 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0023403637249562225 values:  -58.439007 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0023905668788101195 values:  -58.35757 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0027145935596737973 values:  -58.355835 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  86 target diff:  0.002992169461022749 values:  -58.292656 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.002317372987053993 values:  -58.254402 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0025852738643100275 values:  -58.18274 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0026339190224765135 values:  -58.158527 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.002270547977646711 values:  -58.11758 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0029430014493195687 values:  -58.01711 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0029216261331534606 values:  -57.967022 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.003203763601007599 values:  -57.954174 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.002295452513115584 values:  -57.860054 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.002515877174835806 values:  -57.81191 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.002545472843356049 values:  -57.82121 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0023417884466005907 values:  -57.761635 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0023200964062988117 values:  -57.704926 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.00259485877991149 values:  -57.670383 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9136855077310262 values:  -65.29995 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004968272991232684 values:  -65.214645 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0040167278081078145 values:  -65.27574 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0036951547398845694 values:  -65.372284 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.003719684213398024 values:  -65.33854 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0026172499202163114 values:  -65.37591 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0025974411822958124 values:  -65.45093 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0027152060132636067 values:  -65.563156 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.003231735473520485 values:  -65.61279 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021888035866908327 values:  -65.66826 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0021925878254854185 values:  -65.77375 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0029683155040546266 values:  -65.81226 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  12 target diff:  0.0025780073908095395 values:  -65.80117 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0022268214590593165 values:  -65.77808 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0016297597174036056 values:  -65.88188 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0022518024140912724 values:  -65.836716 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002304717180003642 values:  -65.82647 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.00206117265452015 values:  -65.79557 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002716481747694991 values:  -65.85231 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0026795728544322444 values:  -65.83634 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0028111389415987962 values:  -65.860634 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0035720544761766245 values:  -65.73842 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.003647393444244785 values:  -65.61883 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.003392196154917052 values:  -65.56121 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.004016372268845066 values:  -65.45139 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.004155990466427836 values:  -65.45884 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.004234191536694492 values:  -65.46753 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0049692320432759 values:  -65.44649 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.004803450840770113 values:  -65.466515 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.004687845474213181 values:  -65.45308 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.005110959551976652 values:  -65.41606 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.005093399442110479 values:  -65.31946 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0047681481157012305 values:  -65.351326 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.004573103518260454 values:  -65.26322 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.004291036938267588 values:  -65.09252 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.004327085369588333 values:  -65.011955 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.00508406786257173 values:  -64.84462 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.004381395579496032 values:  -64.72512 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.004040374949458849 values:  -64.62077 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.004814902365702269 values:  -64.506775 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.005145738588305533 values:  -64.41304 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0038742990290747304 values:  -64.22878 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  42 target diff:  0.005142326359733019 values:  -64.14668 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  43 target diff:  0.004092088935366334 values:  -64.06928 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.005258387503551289 values:  -63.989445 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0036419908006689755 values:  -63.891064 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.004268983774267976 values:  -63.823853 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0037323613911462053 values:  -63.74571 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.004095680112325449 values:  -63.691433 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0033295349776894835 values:  -63.598427 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.003980468043930604 values:  -63.53775 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  51 target diff:  0.0032234002694515674 values:  -63.403675 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0038887303743098075 values:  -63.340473 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0031951967882701444 values:  -63.285828 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0035094979571182036 values:  -63.191463 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0029325082453721305 values:  -63.170452 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0037687000321625745 values:  -63.052925 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.003763810862620099 values:  -63.060364 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0033183976976371952 values:  -62.92008 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0033657839695685502 values:  -62.833523 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0030668612708820366 values:  -62.737186 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002877973825984228 values:  -62.688404 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.003074201468865541 values:  -62.62439 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.00297604208936311 values:  -62.558514 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002856560705627538 values:  -62.43329 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  65 target diff:  0.002978590343078643 values:  -62.456734 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0034342532509453096 values:  -62.394398 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.003216269008636721 values:  -62.323357 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0031186405148533923 values:  -62.25585 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0036865865631258744 values:  -62.189667 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.00279241201254187 values:  -62.148323 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002957089793505207 values:  -62.13616 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0030918411571832106 values:  -62.067265 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0028580401187804625 values:  -62.03097 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0026765556663964716 values:  -61.989258 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002681025887309307 values:  -61.922474 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002565305212286341 values:  -61.838146 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0025270804112083626 values:  -61.78533 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.002423072384963769 values:  -61.770657 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0024820430563593076 values:  -61.727703 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0026093021250404094 values:  -61.64078 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0027392592732274766 values:  -61.577953 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.002702160625409914 values:  -61.550198 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002457052254669047 values:  -61.49707 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.002364814523567666 values:  -61.465916 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.002361017216331248 values:  -61.455654 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.002052927836949274 values:  -61.426094 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0023976678218324515 values:  -61.378944 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.002085008713936428 values:  -61.40918 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0018544086415325303 values:  -61.416653 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.002120918251163187 values:  -61.437336 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.001701870331278003 values:  -61.42371 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.002079856266800782 values:  -61.353184 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0022415707128623126 values:  -61.36786 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.001632812409455698 values:  -61.321938 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0018521133288993568 values:  -61.34072 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0016382017597536438 values:  -61.360615 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0018558394399613857 values:  -61.352757 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0017959077643961477 values:  -61.3349 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0016158672595180815 values:  -61.394367 ----- \n",
      "\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.913344050236424 values:  -61.427395 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0016561825156041466 values:  -61.372166 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-----iteration:  2\n",
      " target diff:  0.0015045475694569635 values:  -61.391087 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001352954033860169 values:  -61.36082 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9233399523742919 values:  -56.77729 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026905938189185482 values:  -56.763386 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9151231076545989 values:  -57.109867 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001862436906168409 values:  -56.76191 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001445954159761127 values:  -56.7028 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002641181224472719 values:  -57.16938 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002130815072745 values:  -57.16139 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018387941649363512 values:  -57.214275 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019147337657911103 values:  -57.253418 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018036905215822502 values:  -57.279865 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016265526391157645 values:  -57.388042 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023528121591237174 values:  -57.471783 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8 target diff:  0.0012643338168327322 values:  -57.573586 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  0 target diff:  0.9243186695163517 values:  -56.87319 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002213582538218753 values:  -56.92857 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0023755952434161708 values:  -56.947964 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020207557121843804 values:  -56.95492 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023335928650839314 values:  -56.924603 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  5 target diff:  0.0014553134236657374 values:  -56.911217 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9145468052483703 values:  -58.140415 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.003520310000248511 values:  -58.099968 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002497027159942283 values:  -58.09988 ----- \n",
      "\n",
      "-----iteration: -----iteration:   03  target diff: target diff:  0.9237473194925743  0.0014186446402343208values:   values: -57.682354  ------58.094673  ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  1 target diff:  0.0028027516396686393 values:  -57.712902 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002231813466744128 values:  -57.71805 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0027070716032173243 values:  -57.74863 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002310495392967973 values:  -57.727993 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  5 target diff:  0.001919451443236771 values:  -57.757366 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020868086142788586 values:  -57.792732 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016658949758249176 values:  -57.909313 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8 target diff:  0.0021607807532081375 values:  -57.909035 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002034707502262586 values:  -57.880886 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9148550446912772 values:  -57.70702 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002060702936439936 values:  -57.892006 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0019397537893745525 values:  -57.683437 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018262184047265072 values:  -57.8978 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001745658316456406 values:  -57.783695 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0017813636518605068 values:  -57.898872 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001589682061339307 values:  -57.781273 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002032229601093266 values:  -57.922062 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  14-----iteration:   target diff:  4 0.002661843925101078target diff:   values: 0.0016953408304232528 -57.965435  -----values:   \n",
      "-57.71174 \n",
      "----- \n",
      "\n",
      "-----iteration:  15 target diff:  -----iteration:  0.0020109463420987575 values:   -57.84735 -----target diff:  \n",
      " \n",
      "0.0016639280206571523 values:  -57.62921 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020867871744765904 values:  -57.813824 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0025374579788343984 values:  -57.88828 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0014376255354207705 values:  -57.738132 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  17 target diff:  0.0023558210247221975Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl! \n",
      "values: Refresh buffer every 1000000 sampling! \n",
      "-57.89268 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  18 target diff:  0.0024549997024046356 values:  -57.808895 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0022237924223245504 values:  -57.85285 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002575750129054017 values:  -57.820183 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002366588388175935 values:  -57.82617 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0017715646637000782 values:  -57.82662 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0015161839480339117 values:  -57.828716 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  24 target diff:  0.0013597330035441048 values:  -57.745266 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9141493676720656 values:  -60.41889 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9235895228345464 values:  -57.072056 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005693359695538854 values:  -60.437527 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021008826907593786 values:  -57.101746 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025655152434769586 values:  -60.42126 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002325008158414515 values:  -57.07019 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001740406048319465 values:  -57.11184 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023229729199788444 values:  -60.44221 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020654499359054955 values:  -57.136986 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024888530216781173 values:  -60.45954 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001817802606023893 values:  -57.154144 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018741169975145325 values:  -57.242207 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020925703369027385 values:  -60.437836 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0026038869967222548 values:  -57.264248 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002516659250034032 values:  -60.40722 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020921691089708346 values:  -57.332096 ----- \n",
      "\n",
      "-----iteration:  7 -----iteration: target diff:   90.0026218388165291837  target diff:  values:  0.0021479904272107254 -60.45678 -----values:   \n",
      "-57.337646\n",
      " ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002028247423048448 values:  -60.43819 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015861508752246034 values:  -57.24371 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0033391967388470174 values:  -57.275093 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022924822175782993 values:  -60.50061 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001847989117631069 values:  -57.254475 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002110723348771528 values:  -60.454487 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001502366712914362 values:  -57.195503 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020238943615205765 values:  -60.38978 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0011816689150384607 values:  -57.246376 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  12 target diff:  0.002395311763858574 values:  -60.41641 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  13 target diff:  0.0016138906493358216 values:  -60.382057 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002898479793854857 values:  -60.33686 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002461825084805242 values:  -60.324932 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  16 target diff:  0.0018112976609772982 values:  -60.38644 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0020521812451918687 values:  -60.36469 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0019605223988333692 values:  -60.389343 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  19 target diff:  0.0018416574392045757 values:  -60.370796 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9242051608543902 values:  -57.581055 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002086186999791454 values:  -60.421528 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0022651569369219675 values:  -57.59873 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017011287666263027 values:  -60.450188 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002195771952272525 values:  -57.756527 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003144569394137211 values:  -57.67287 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001901458703930397 values:  -57.803955 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0017685086818310485 values:  -60.458305 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002716452844814667 values:  -57.88194 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  -----iteration:  0.0019816830142784614 23 values: target diff:   -57.942110.0027948336562286596  -----values:   \n",
      "\n",
      "-60.42647 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022315056788056375 values:  -58.001648 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018216020493881104 values:  -60.334377 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001565325072695989 values:  -60.30467 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016939142692336132 values:  -58.025433 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017329375945225832-----iteration:   26values:   target diff:  -57.9880180.001760743165161341 -----  \n",
      "\n",
      "values:  -60.28602 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015808506466025865 values:  -58.01388 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018901730771482327 values:  -60.16695 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001602306482717334 values:  -58.07201 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021091059484964784 values:  -58.102478 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0019894802319971455 values:  -59.983677 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0015761330764252383 values:  -58.17642 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018380157514351304 values:  -58.06652 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0023661744946529544 values:  -59.884296 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0020885548051387307 values:  -58.131603 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0027759212629088763 values:  -59.77438 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017464767337367901 values:  -58.195248 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002278224420432905 values:  -59.630806 ----- \n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "\n",
      "-----iteration:  17 target diff:  0.0018772532191809986 values:  -58.193592 ----- \n",
      "\n",
      "-----iteration: -----iteration:   3218  target diff: target diff:   0.00231142129065260460.0018659139272882352  values: values:   -58.194332-59.530083  ----- \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0017551856911180918 values:  -59.472847 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0015542721550275114 values:  -58.18957 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002133713975338652 values:  -59.415398 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0024993175186664145 values:  -58.220093 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002121949499067452 values:  -59.27482 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002131084302565427 values:  -58.2468 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019156550579018336 values:  -59.148956 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019904649140791986 values:  -58.149963 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0018746655566948649 values:  -58.937214 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.00235948042009164 values:  -58.086365 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002217751979655801 values:  -58.836304 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.00228231353108322 values:  -58.08498 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0016432013028836276 values:  -58.700188 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0023259881437163155 values:  -58.050213 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002322339051505122 values:  -58.06548 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.00202403278153443 values:  -58.647038 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002566466552017007 values:  -58.01585 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0019409964064550887 values:  -58.021084 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0028109530901477033 values:  -58.404743 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0019585933327989132 values:  -58.055286 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.001991505815742298 values:  -58.200115 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0019562692587932035 values:  -57.96714 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002377342658321998 values:  -58.053738 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002217548596251483 values:  -57.94199 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0021048482458775842 values:  -57.935047 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0018827811560476538 values:  -57.771545 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0024282270058010843 values:  -57.93289 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.001762206982182268 values:  -57.641216 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001985723167619279 values:  -57.92483 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0020134834330622817 values:  -57.617573 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0017768690917062285 values:  -57.876957 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002038698912760628 values:  -57.765522 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0024253556249280647 values:  -57.33606 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0026859332122602386 values:  -57.248394 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019836306398412964 values:  -57.73276 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0022083224353207647 values:  -57.291935 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0018464847883724056 values:  -57.51511 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0020638499358983406 values:  -57.183556 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0023346757548953646 values:  -57.38827 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002241953990011887 values:  -57.104893 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0021166917250675637 values:  -57.32078 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002552573755676907 values:  -57.06522 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0017813207424208404 values:  -57.208614 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002722276690027531 values:  -56.944492 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017071676783508396 values:  -57.154095 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0018745373376364539 values:  -56.819416 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.001588985744847366 values:  -57.06305 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0023602529397842658 values:  -56.78412 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0017803191568861042 values:  -56.959904 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0024446708526917335 values:  -56.6941 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0016058286282549265 values:  -56.85509 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0025487611926615183 values:  -56.65671 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.00171567753180197 values:  -56.802032 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0018075060208861057 values:  -56.61192 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0014326324166175142 values:  -56.6543 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0022759598831003456 values:  -56.621887 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002513420745186779 values:  -56.518623 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0031457834294037097 values:  -56.46935 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0023713123968066934 values:  -56.413445 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  64 target diff:  0.0024714775051525913 values:  -56.42109 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0018581062561322031 values:  -56.44656 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9233343455903498 values:  -57.51294 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0016552494523821954 values:  -56.517933 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0022953683559684274 values:  -57.56203 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.001961253901012019 values:  -56.532505 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020643903950182995 values:  -57.519707 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0024460070662678797 values:  -56.569305 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020757618010183274 values:  -57.480022 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001926718214539083 values:  -57.543877 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0022438993025490515 values:  -56.567226 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025613777300539887 values:  -57.5313 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.00232719046713642 values:  -56.567776 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  6 target diff:  0.001423811790781161 values:  -57.519096 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  71 target diff:  0.0018823718044441095 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "values:  Refresh buffer every 1000000 sampling!-56.552914\n",
      " ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  72 target diff:  0.002176353993991005 values:  -56.538246 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0017993405544052508 values:  -56.48358 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0018319111940754676 values:  -56.415676 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0018280390231380787 values:  -56.368977 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0014040828862380782 values:  -56.371067 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9155298962054798 values:  -59.240078 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.0031255015046267403 values:  -59.217537 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9234190969875371 values:  -56.88809 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00153250118003975 values:  -59.275635 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028642127656361375 values:  -56.908997 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020601342341334435 values:  -59.33121 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027324076902839295 values:  -56.950172 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0014993310929006104 values:  -59.285282 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  3 target diff:  0.002574687009268274 values:  -56.97713 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  4 target diff:  0.0023882139683676284 values:  -56.970882 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016970450263732828 values:  -57.002472 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019585167578055735 values:  -57.043663 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0028422472957066254 values:  -57.076965 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021759028290520726 values:  -57.065197 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001513703630161385 values:  -57.205788 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  10 target diff:  0.002442883655068649 values:  -57.10101 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002674975196584392 values:  -57.114704 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022802846389930256 values:  -57.173122 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0023356365043362202 values:  -57.21234 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0017777119646895574 values:  -57.12021 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002251301357539434 values:  -57.13965 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0015451434808767732 values:  -57.12151 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  17 target diff:  0.00220963060643714 values:  -57.172398 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  -----iteration:  0.00184955134698906770 values:   target diff:  -57.1726070.9160949350724449 values:   ----- -59.079678 \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020810075049985583 values:  -57.20065 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034238513039473945 values:  -59.033997 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002383061951168611 values:  -57.178547 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027649895373641695 values:  -58.995052 ----- \n",
      "\n",
      "-----iteration: -----iteration:   3 21 target diff:  target diff: 0.0021906114268037268  0.0020148291107756895values:   values:  -58.952816 -57.19686-----  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020636352008685365 values:  -58.87663 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002653320528358921 values:  -57.159 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019612023074344195 values:  -58.915325 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002238838225577059 values:  -58.84784 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002380702179430287 values:  -57.159374 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0023293696981843883 values:  -57.086372 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019199363951103972 values:  -58.89379 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016944858925924842 values:  -58.8391 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0022674220527017053 values:  -57.103565 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017657448480550527 values:  -58.778313 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002265185268848471 values:  -56.964485 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017597144715396846 values:  -58.813263 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002700868981912593 values:  -58.858143 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0021742582608650198 values:  -56.892666 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002601329009246794 values:  -58.900463 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0020407310216829016 values:  -56.805237 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0017307573999923804 values:  -58.783806 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0019074103907705856 values:  -56.762093 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002497963548457636 values:  -58.76423 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0016045916984080992 values:  -56.727604 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0014791823080584391 values:  -58.679253 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0016599215056858443 values:  -56.586308 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0016765141312082281 values:  -56.61244 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001770370574313409 values:  -56.547943 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0020150475922331274 values:  -56.483925 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  35 target diff:  0.0018687361924139972 values:  -56.331326 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9157619362862994 values:  -58.63779 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0016847701089570814 values:  -56.296284 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0021031186373401665 values:  -56.2176 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002630625181951226 values:  -58.60729 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0015937582887619423 values:  -56.15497 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027743248542621305 values:  -58.624146 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017171493071783824 values:  -58.577404 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.001395664839835879 values:  -56.110973 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002162455753939359 values:  -58.56075 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017786977432842914 values:  -58.548622 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020071124609779513 values:  -58.57782 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001603356723075503 values:  -58.450745 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015007386604959274 values:  -58.432976 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001484824068174137 values:  -58.441143 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9220516292699913 values:  -57.226494 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0031966526741317976 values:  -57.266563 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0031449907487237664 values:  -57.314373 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002525867326168068 values:  -57.380714 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023224161615955008 values:  -57.349148 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  --------------------0.0017360673936289036  values: fqe on dqn & sale  -57.3735 --------------------\n",
      "----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  6 target diff:  0.0020354497051354734 values:  -57.344463 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002179857857560133 values:  -57.3498 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002036985054746705 values:  -57.43591 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021958045367103077 values:  -57.530003 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018217775046633366 values:  -57.553143 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019340760229162055 values:  -57.525654 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001781996689008103 values:  -57.483734 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001458606989930156 values:  -57.45133 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  0 target diff:  0.9142431853258947 values:  -57.873753 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004713508118009533 values:  -57.83432 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  2 target diff:  0.0025811184068851023 values:  -57.85266 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019653938972966916 values:  -57.85947 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002156768253471903 values:  -57.838936 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019493345911384644 values:  -57.77322 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  6 target diff:  0.0023484548320819257 values:  -57.770508 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0023831095933362803 values:  -57.774822 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9233766257194751 values:  -56.458443 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 1  8target diff:   target diff: 0.002130877877425725  0.0017024425957737148values:   -56.568928values:   -57.658165 ----- \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021981996338769705 values:  -57.533527 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025876037749321752 values:  -56.55501 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018427154361303029 values:  -56.54497 ----- \n",
      "\n",
      "-----iteration:  10 -----iteration: target diff:   40.0019936708090805243  target diff: values:   0.0016921135210537926 -57.49455values:   ------56.619682  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020593758679682776 values:  -56.686626 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  6 target diff:  0.0020163586311163335 values:  -56.706673 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001856730516895211 values:  -57.600666 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002363163074833901 values:  -56.674126 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023817868541365483 values:  -57.626484 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018311911434747822 values:  -56.7328 ----- \n",
      "\n",
      "-----iteration:  9-----iteration:   target diff: 13  0.001923906868567433target diff:   0.002145563738346216values:   values: -56.755413  -57.641987 ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  10 target diff:  0.0018658245349483904 values:  -56.81278 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019798707032587875 values:  -57.665607 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias11\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kerneltarget diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias0.0019370404712550859\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelvalues: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias -56.82914\n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  15 target diff: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl! \n",
      "0.0026920904472945628Refresh buffer every 1000000 sampling! \n",
      "values:  -57.65354 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!-----iteration: \n",
      " Refresh buffer every 1000000 sampling!12 \n",
      "target diff:  0.0016926175425342083 values:  -56.90635 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  16 target diff:  0.002243218083435161 values:  -57.612278 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001708070608507974 values:  -56.853046 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0013858537535511412 values:  -56.888496 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001804547174141709 values:  -57.643036 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0020161751626020723 values:  -57.630093 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  19 target diff:  0.0019685293836868073 values:  -57.683342 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002011678238227263 values:  -57.75944 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  21 target diff:  0.0021834496096533908 values:  -57.773308 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  22 target diff:  0.002636931354407561 values:  -57.753445 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9230342942276908 values:  -56.899418 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0016652917623482268 values:  -57.753685 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002949618884131535 values:  -56.895817 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9180768169455865 values:  -62.48919 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020435544680838516 values:  -56.879963-----iteration:   -----24  \n",
      "target diff: \n",
      " 0.0023423898362755686 values:  -57.764606 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  3 target diff:  0.001818625525540426 values:  -56.949 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0019166458687918865 values:  -62.503704 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002245684270948812 values:  -57.732014 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002106087264311256 values:  -56.955982 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002155561633333788 values:  -57.68644 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001164239046415085 values:  -62.541298 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017213869463970374 values:  -57.037067 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002612302516173373 values:  -57.046562 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0017876276760892308 values:  -57.548943 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001474100817580344 values:  -57.01823 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.002543799116225973 values:  -57.48995 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  29 target diff:  0.002208261844026899 values:  -57.481743 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0016779723900948685 values:  -57.41067 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  31 target diff:  0.0024012160875229475 values:  -57.324898 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9202910609288425 values:  ---------------------64.430275  fqe on dqn & sale-----  \n",
      "--------------------\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "-----iteration:  WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.32 \n",
      "target diff:  0.0018659581682474056 values:  -57.328045 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0017464428390652747 -----iteration: values:   1-57.310616  target diff:  0.003435648425634215-----  \n",
      "values:  \n",
      "-64.467 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0015832950035750074 values:  -57.33852 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019028680650166043 values:  -64.623 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002338598950077836 values:  -57.380363 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019857479043970476 values:  -64.65811 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019690165833022412 values:  -57.350964 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0018555963924393787 values:  -57.29449 ----- -----iteration: \n",
      " \n",
      "4 target diff:  0.001852664333693223 values:  -64.77228 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023505528306603956 values:  -64.89656 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017442299480500776 values:  -57.2201 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001547596184732801 -----iteration: values:   39 -64.93843 target diff: ----- 0.0018020525402504233 \n",
      " \n",
      "values:  -57.177216 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.001855144891705054 values:  -64.96143-----iteration:  40  target diff: ----- \n",
      " \n",
      "0.001497386989942316 values:  -57.17719 ----- \n",
      "\n",
      "-----iteration:  8 -----iteration: target diff:   00.0013829196248102684  target diff: values:   -64.999250.9230055285862347  -----values:  -58.459236 \n",
      " \n",
      "----- --------------------\n",
      " ckpt:  10000\n",
      " --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.0029668718799059544 values:  ---------------------58.481205  -----adv learner  \n",
      "--------------------\n",
      "\n",
      "-----iteration:  2 target diff:  0.0022919739375664317 values:  -58.434906 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001905901425141098 values:  -58.467407 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002608807126440258 values:  -58.449833 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  5 target diff:  0.0021352539317822327 values:  -58.45944 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.0017240534767344754 values:  -58.426514 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023323812523953773 values:  -58.458195 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9150949488888631 values:  -58.91796 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023526210125788855 values:  -58.525635 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028303915483897544 values:  -58.822456 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002445867281384836 values:  -58.553776 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0016646201787152118 values:  -58.476555 ----- \n",
      "-----iteration: \n",
      " 2 target diff:  0.0021380533096768788 values:  -58.776768 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001863248243787994 values:  -58.777378 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.001858927589532094-----iteration:   11values:  target diff:   0.0018118026326098967-58.469116 values:   ------58.42901 -----  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  12 target diff:  0.0015318132134891625 values:  -58.464508 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0037619845847385743 values:  -58.390644 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9193447052414303 values:  -67.232834 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016712355071058103 values:  -58.51639 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020569031728360485 values:  -58.439167 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018520604422458582 values:  -58.56734 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016681008163600805 values:  -58.400005 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026425936596914403 values:  -67.29483 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015554336734555632 values:  -58.32559-----iteration:   ----- 15\n",
      " \n",
      "target diff:  0.0016594726296799108 values:  -58.546318 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019360026441000572 values:  -58.471367 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017161572238573986 values:  -58.577915 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002127405066832108 values:  -67.35917 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0016422687249576752 values:  -58.58909 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019836881015296215 values:  -58.439724 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001996467906843362 values:  -67.416794 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0017513958666554876 values:  -58.529793 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00181774916767005 values:  -58.425396 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0015929313755513425 values:  -58.445965 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001492225020150431 values:  -67.371925 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  -----iteration: 0.0014638051149072134  20values:   target diff: -58.35866  0.002265561466452102-----  values: \n",
      " \n",
      "---------------------58.361546 -----  ckpt: \n",
      "\n",
      " 30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  21 target diff:  0.002423182701734943 values:  -58.383595 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  22 target diff:  0.0018060135758542926 values:  -58.33292 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  23 target diff:  0.002860753613673905 values:  -58.263943 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9196372136081904 values:  -67.734764 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  24 target diff:  0.002411201458978223 values:  -58.256313 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003363380994719267 values:  -67.82041 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  2 target diff:  0.0019357502502309212 values:  -67.79533 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002166888951249768 values:  -58.223186 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001641044865168798 values:  -67.751656 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002501985229436823 values:  -67.74131 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016768247371579253 values:  -67.6826 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002489306487660903 values:  -58.127583 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017787018421953954 values:  -67.69303 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  27 target diff:  0.002281789483804258 values:  -58.05341 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9144578231540248 values:  -58.41216 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0012974869444449266 values:  -67.65365 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "-----iteration:  28 target diff:  0.0027446332323560743 values: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl! -57.96841\n",
      " Refresh buffer every 1000000 sampling!-----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.0038736220498349493 values:  -58.36433 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  29 target diff:  0.0027918015127663624 values:  -57.872166 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0034702208848759186 values:  -58.378635 ----- \n",
      "-----iteration: \n",
      " 30 target diff:  0.002274795334313234 values:  -57.745083 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002553644217433733 values:  -58.269714 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002296993874588999 values:  -57.666748 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002867670220378477 values:  -58.329494 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  32 target diff:  0.0016762762796802575 values:  -57.589973 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023491240112836114 values:  -58.35328 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001787137449097078 values:  -57.508797 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018092627319367654 values:  -58.413017 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0017799806167102675 values:  -57.508373 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0027139254860929587 values:  -58.41986 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021500583998470286 values:  -58.43273 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0030016197644979928 values:  -57.32489 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002786921098707707 values:  -58.446606 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0021146042053690407 values:  -58.497948 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  11 target diff:  0.002545419747267514 values:  -58.450367 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019541374922469046 values:  -57.133232 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018130018219468579 values:  -58.435062 ----- \n",
      "\n",
      "-----iteration: -----iteration:   370  target diff: target diff:   0.91885762852665830.0018681670042496065  values:  values: -56.98562 ----- -63.15583 -----  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  13 target diff:  0.0018398608515718352 values:  -58.39959 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001529168848324416 values:  -56.874245 ----- \n",
      "-----iteration:  \n",
      "1 target diff:  0.0022720545927897755 values:  -63.239326 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018025917359026538 values:  -58.403015 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0014926343580913162 values:  -56.784924 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0023480920182770352 values:  -63.20062 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002578554955949529 values:  -58.38631 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016934638794193159 values:  -63.118877 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019159004735623004 values:  -58.40761 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0025405245025656126 values:  -63.149117 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021451781130819607 values:  -58.455776 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002035026645874756 values:  -63.15676 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002286921089707499 values:  -58.482475 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001696472987492037 values:  -63.169376 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0023160994499458287 values:  -58.530846 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0017193948736645961 values:  -63.216816 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002103648140938111 values:  -58.57037 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.924270208211621 values:  -55.95404 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.001977822492269336 values:  -58.55042 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001713962228164415 values:  -63.218662 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002876078094617737 values:  -56.068813 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002428236862319354 values:  -58.56913 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002863830998061173 values:  -56.06024 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016802807018424654 values:  -63.239906 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001754601834592191 values:  -56.037327 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002596710019727144 values:  -58.61855 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020889770795843414 values:  -55.994427 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001679105523854423 values:  -63.28353 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024383093304455217 values:  -56.039986 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0023166040127956334 values:  -58.61835 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015892778922316352 values:  -63.377556 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019431555503852198 values:  -55.98659 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  7 target diff:  0.0015938082488506328 values:  -56.086796 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001999918516143735 values:  -58.51587 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0025186375623279943 values:  -63.350925 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019401131510753944 values:  -56.173367 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0024225219928246207 values:  -58.59184 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0014000828890280003 values:  -63.438416 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016029465717415214 values:  -56.25478 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0027811891027287763 values:  -58.68475 ----------iteration:   10\n",
      " \n",
      "target diff:  0.0014214885792039132 values:  -56.282387 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  28 target diff:  0.002415416204996154 values:  -58.718807 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0023108164551954363 values:  -58.7075 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002269052013477954 values:  -58.63578 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0022152152573959734 values:  -58.54889 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.001908604237122954 values:  -58.484837 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0024903227129081575 values:  -58.448906 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  34 target diff:  0.0017796161888146483 values:  -58.446785 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9187509364015553 values:  -62.680733 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002121890749936307 values:  -58.42313 ----- \n",
      "\n",
      "-----iteration:  1 -----iteration: target diff:   360.002576178755496836  target diff: values:   0.0019940639606302163-62.759857  values:  -58.37638----- ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019638103719546033 values:  -58.371025 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018513957751514832 values:  -62.84237 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019336175058812946 values:  -62.921955 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0018491316885170651 values:  -58.30161 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002017778071095928 values:  -58.2738 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00223419121454745 values:  -62.94213 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0015917209121181271 values:  -58.27395 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019146801510301996 values:  -62.861042 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0019949538577812703 values:  -58.26975 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023493989215407638 values:  -62.872265 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018417387844236479 values:  -58.287067 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.001487866385476941 values:  -62.882366 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  43 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!target diff: \n",
      "Refresh buffer every 1000000 sampling! 0.0018151750382458343\n",
      " values:  -58.253193 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  44 target diff:  0.0015045659963792797 values:  -58.230145 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0013646456287808408 values:  -58.269897 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9241116426228851 values:  -56.117756 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002251471838287825 values:  -56.21561 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0030778692911853085 values:  -56.299988 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  3 target diff:  0.0022482008081207276 values:  -56.398396 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023679275360722406 values:  -56.42083 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018768076684420804 values:  -56.543476 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002339803357470129 values:  -56.621723 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0018876744733463807 values:  -56.63619 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9144261258705049 values:  -57.683434 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.00208832926849404 values:  -56.69837 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0024644100116347025 values:  -56.781303 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003810259435528601 values:  -57.729595 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018518075886847605 values:  -56.87517 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002918779516018917 values:  -57.783894 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  11 target diff:  0.0016438278368137175 values:  -56.825176 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002122951817634624 values:  -57.701958 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9192478668728927 values:  -62.88312 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 12  4target diff:  target diff:   0.00150847114053231250.0021136772008934507 values:  -57.67844 values:   ----- \n",
      "-56.861286\n",
      " ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002507272596747153 values:  -57.69682 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016930886102645643 values:  -56.78382 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0022420226877960807 values:  -62.809334 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0025711326677688106 values:  -57.600117 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019003398867824218 values:  -62.83264 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002314136074743495 values:  -----iteration: -56.752956 7  target diff:  -----0.0022051386923427536  \n",
      "values:  -57.637215 -----\n",
      " \n",
      "\n",
      "-----iteration:  15 target diff:  0.001420387888546782 values:  -56.72262 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002082026145769952 values:  -57.716484 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018420325267754045 values:  -62.844883 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023163700078664123 values:  -57.657192 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0015620482308483904 values:  -62.85412 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002392413698317727 values:  -57.650593 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016972310961942032 values:  -57.5907 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018605097876044524 values:  -63.016716 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018610041685017363 values:  -57.617805 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0025499938601944053 values:  -63.161186 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002226483158903525 values:  -57.56779 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  -----iteration: 0.0015009090342224056 7  values:  -57.50651 -----target diff:   \n",
      "0.002270535341611218\n",
      " values:  -63.192364 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  15 target diff:  0.00210014842124778 values:  -57.57224 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001769838420218339 values:  -63.152195 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9239650251399345 values:  -56.253178 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0021928300731977935 values:  -57.552185 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019388183668718195 values:  -63.371593 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003848243004609779 values:  -56.28506 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018909725247205009 values:  -57.572258 -----iteration: -----  \n",
      "10\n",
      " target diff:  0.0020513494982153622 values:  -63.409454 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0036651713254207837 values:  -56.325127 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0016730824434668932 values:  -57.445675 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018873649356209552 values:  -63.440727 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0028474492479250526 values:  -56.348824 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0021116866950173056 values:  -57.415043 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.003477477114574898 values:  -56.31058 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016604634580911428 values:  -63.438374 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002687637322357635 values:  -56.38111 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002396821039538893 values:  -57.426662 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.00211728278667389 values:  -63.52375 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.003072262159686587 values:  -56.420593 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0023090020994341763 values:  -57.387356 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0024383124935620113 values:  -56.44504 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018706222148805174 values:  -63.43687 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0020333510826111827 values:  -57.450672 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002003562862467477 values:  -63.520016 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019692025907125875 values:  -56.3684 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002754629765186825 values:  -57.434258 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002130482228445316 values:  -56.344822 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  -----iteration:  24 target diff:  0.001970361257490806 values:  0.0025788366352278115-57.406445 ----- \n",
      "\n",
      " values:  -63.61987 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019116818349894304 values:  -56.317753 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0024291649808616733 values:  -57.41729 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0023533272557523474 values:  -63.6169 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001804019527542098 values:  -56.28228 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023682422420756117 values:  -56.28043 ----- \n",
      "\n",
      "-----iteration:  26 target diff: -----iteration:   0.002181145423104135 values:  18-57.40542  target diff: ----- 0.0026398962824938214 \n",
      " values: \n",
      " -63.657513 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018390521730418789 values:  -56.353252 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0024476375767097554 values:  -57.366882 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002554125692915127 values:  -63.605095 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0016891869065752537 values:  -56.362583 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001762860649078611 values:  -56.386585 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022553645325773864 values:  -63.525127 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0021029080979669363 values:  -57.4044 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0014098345945009014 values:  -56.43012 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias-----iteration:  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel29\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biastarget diff: \n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0038973862552405102\n",
      " values:  -57.38752 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      " target diff:  0.00221918022419026 values:  -63.43042 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  22 target diff:  0.002120172254044974 values:  -63.485596 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002950788434246978 values:  -57.419643 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0023004096938123836 values:  -63.417168 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0032886225656328363 values:  -57.446575 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002598904572965702 values:  -57.421467 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002307799426184852 values:  -63.423687 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002452286360164011saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_10000.ckpt \n",
      "values:  -57.49302 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0019778939313401063 values:  -63.343357 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  34 target diff:  0.0038364624402843807 values:  -57.366333 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0017883545426194446 values:  -63.390602 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0027951453172167778 values:  -57.19096 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0017905567983093282 values:  -63.30575 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018244276744576213 values:  -----iteration: -63.309666  36-----  target diff: \n",
      " \n",
      "0.0024337770321940662 values:  -57.04294 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0016677373205150644 values:  -63.302166 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002467647602311599 values:  -57.04908 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001753815102771418 values:  -63.2761 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002591396587060871 values:  -56.98765 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  31 target diff:  0.0016411255968963897 values:  -63.23103 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0019355650334353259 values:  -56.925842 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0015767971069785118 values:  -63.06983 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9233545326103679 values:  -55.914787 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0026166911262959685 values:  -56.698425 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0021354157029136477 values:  -63.042664 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0032659314436406365 values:  -56.007652 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0027207060586969165 values:  -56.626133 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002317922116924343 values:  -55.99899 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0022024888445187013 values:  -63.162407 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002022602228295049 values:  -56.030037 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  -----iteration: 0.002408117009509953  42values:   target diff: -63.135628 0.001994345863228867  ----- \n",
      "values: \n",
      " -56.587193 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0026078115388769017 values:  -56.03106 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0015164175191927835 values:  -63.144478 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002200554457983926 values:  -56.012596 ----------iteration:   43\n",
      " target diff:  \n",
      "0.0026364630010287105 values:  -56.561687 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0016410936640175687 values:  -63.10262-----iteration:   6 -----target diff:  0.0017460653630421647 values:   -56.045254 ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  44 target diff:  0.0024027436761770416 values:  -56.378716 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021365654587544836 values:  -56.043633 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.00172958337572626 values:  -63.149204 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002505171832493552 values:  -56.37562 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002039671275520262 values:  -56.122917 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0018028392177462187 -----iteration:  values:  9 target diff:  0.0020192041502335445 -56.220604 values: ----- -56.178955 ----- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  39 target diff:  0.002329328611440248 values:  -63.072598 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0021122424417732133 values:  -56.19106 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022722611281199485 values:  -56.132236 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0018602718870015607 values:  -56.154076 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023749716712645895 values:  -56.190838 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.001742826633521816 values:  -62.98276 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.001974278517399752 values:  -56.13275 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001672923602949448 values:  -56.088993 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0016650589843610966 values:  -62.903393 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0018105522712659817 values:  -56.09982 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0018275535958890345 values:  -56.150936 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002176812969743355 values: -----iteration:  -56.06945 -----  42\n",
      "\n",
      " target diff:  0.0015514052544311069 values:  -62.821583 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0023137572580869178 values:  -56.143528 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0014390497624212615 values:  -62.81961 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018372269684150718 values:  -56.099243 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.00203205649607205 values:  -56.113167 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0023624008463362977 values:  -56.23297 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0019084521912576004 values:  -56.116127 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002545621169192869 values: -----iteration:   55-56.27411 target diff:  -----  0.0022196809661997807\n",
      " \n",
      "values:  -56.119453 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.001975010816167105 values:  -56.047993 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0028792583760192552 values:  -56.35452 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002201852051562781 values:  -55.874973 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002417660489306618 values:  -55.827847 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002169403032560796 values:  -56.18113 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0022011634974341537 values:  -55.735386 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0027991768183302044 values:  -56.119812 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  60 target diff:  0.0019290184514204121 values:  -55.65933 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0019929672217068456 values:  -55.951935 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0024678877838553498 values:  -55.59683 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9189693006340852 values:  -62.93653 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0022324072931305602 values:  -55.59347 ----------iteration:   \n",
      "21\n",
      " target diff:  0.0026332944397147234 values:  -55.9336 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003589949647855463 values:  -62.997864 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0017424961033895286 values:  -55.577637 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024606833349882446 values:  -63.03875 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0022782262466667573 values:  -55.57577 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0018662694245376167 values:  -55.8917 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0018940499646532495 values:  -55.574566 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021715146847101916 values:  -62.97376 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002443798072019539 values:  -55.92709 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0019157491630373777 values:  -55.562218 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023328673789275466 values:  -62.868267 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002298520635155542 values:  -55.910286 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016538508108325206 values:  -62.90762 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0023795832622669024 values:  -55.594353 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024130890733372115 values:  -62.945705 ----- \n",
      "\n",
      "-----iteration:  68 target diff: -----iteration:  0.002795561619320447 25 values:  target diff:   -55.5813940.0019031900601821075 -----  values:  \n",
      "-55.828327\n",
      " ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023232603119601124 values:  -62.958748 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.002026761595300597 values:  -55.51766 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019457384816377525 values:  -63.037987 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0023092511427634755 values:  -55.47473 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0024079265609497705 values:  -55.8476 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002140407929052799 values:  -63.086304 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002016137009491016 values:  -55.46847 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0024111182318973666 values:  -55.83346 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002305962073834575 values:  -63.16973 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0019668492149633957 values:  -55.37063 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021733685397025892 values:  -63.113377 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0021838523618983117 values:  -55.845497 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0022640625460225187 values:  -55.315308 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0017526121649404708 values:  -63.100494 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  29 target diff:  0.0017568046603329605 values:  -55.795727 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0017298101397103121 values:  -63.133846 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0019017229198040077 values:  -55.24323 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021072541708262236 values:  -63.04554 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002193523106821614 values:  -55.720207 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0019627039141788946 values:  -55.201405 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001950944190482339 values:  -63.108303 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002085808363326072 values:  -55.20214 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002091905948716289 values:  -55.678585 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018412661041983084 values:  -63.12575 ----- \n",
      "\n",
      "-----iteration:  17-----iteration:   77-----iteration:  target diff:  target diff: 0.0020723696169448022  values: 0.0020077605869041836  -55.153282 values:   ------63.193962  \n",
      "32-----\n",
      "  target diff:  \n",
      "0.0016407564520310367\n",
      " values:  -55.609226 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.002002143720427679 values:  -55.14028 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.001984102943646252 values:  -63.14829 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0016604589438041115 values:  -55.517487 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0018855671530348356 values:  -55.091206 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0020742743992438815 values:  -55.47115 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0022608805249270795 values:  -63.095757 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.00189654718172684 values:  -55.060787 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  35 target diff:  0.001544573854585739 values:  -55.392246 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023040641503040424 values:  -62.992485 ----------iteration:   \n",
      "81\n",
      " target diff:  0.00187444689399799 values:  -55.059002 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0017027026009559735 values:  -55.31693 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002452895814278958 values:  -63.0024 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0017465895591750812 values:  -55.028065 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019017786029749497 values:  -55.2136 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0021269652537154317 values:  -55.02517 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0018930408086812222 values:  -62.94475 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0023523865915048947 values:  -55.014194 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0019932438180245322 values:  -55.0033 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0019532036444338536 values:  -54.972603 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0017728594731200183 values:  -62.89693 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.001908730103599617 values:  -54.940613 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0017874144723776942 values:  -54.9695 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002305317308083292 values:  -62.86219 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0016835780366653242 values:  -54.825047 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0019216835001156524 values:  -54.91563 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0018225995525410035 values:  -62.828205 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001540432092386374 values:  -54.69391 ----- -----iteration:  \n",
      "\n",
      "88 target diff:  0.0019476746487753307 values:  -54.876545 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018778502057919056 values:  -54.615417 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0020727068595925735 -----iteration: values:  -62.758873  -----89 \n",
      "\n",
      " target diff:  0.0017607868424335874 values:  -54.86574 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0013258685170204024 values:  -54.537056 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0019070079541362451 values:  -62.689873 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0018341237813202882 values:  -54.83073 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018016618346526957 values:  -62.67838 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.002042196671143661 values:  -54.853756 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.001681684408805037 values:  -62.68649 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0018872811599295737 values:  -54.845642 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0015664940731753097 values:  -54.83939 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0017510607799994529 values:  -62.6742 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.001659577927626966 values:  -54.870975 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0017666722074602618 values:  -54.89039 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0018771908860172584 values:  -62.6711 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.001610990312764874 values:  -54.808662 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  97 target diff:  0.001591590522867634 values:  -54.793194 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0016767735130687916 values:  -62.59605 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0014591664907483092 values:  -54.833748 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  33 target diff:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!0.0018007767110473118\n",
      " Refresh buffer every 1000000 sampling!values: \n",
      " -62.637608 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  0 target diff:  0.9231075096504988 values:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-56.29582 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  34 target diff:  0.002003781793277544 values:  -62.596416 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004143612036960931 values:  -56.254696 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0016084144990546818 values:  -62.60322 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0014195531312794262 values:  -62.578518 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias-----iteration: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel2\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "target diff:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel0.003467094262017858\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biasvalues: \n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-56.1702\n",
      " ----- \n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.003286750443389773 values:  -56.16933 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023826860411700246 values:  -56.127247 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024247535945752046 values:  -56.044857 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  6 target diff:  0.0025880644505630926 values:  -56.04309 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  7 target diff:  0.0022615810997399003 values:  -56.005684 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020960034540191013 values:  -56.046547 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019496053844538623 values:  -56.089252 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002044798302408982 values:  -56.143867 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002039963803426427 values:  -56.20296 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018799364642799765 values:  -56.31255 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024802882041024153 values:  -56.31672 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.002028990005547071 values:  -56.29778 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  15 target diff:  0.0024053267011853088 values:  -56.29552 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9151042949378707 values:  -57.6066 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9186279903706094 values: -----iteration:   -62.20190416  -----target diff:  \n",
      " 0.0015968969416252524\n",
      " values:  -56.364353 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.005295888986791957 values:  -57.615215 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019120238796849407 values:  -56.307404 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00273742526156874 values:  -62.19904 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018143017864701446 values:  -56.301025 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024230662006519106 values:  -57.613953 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.001396544334339589 values:  -56.36266 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.002116378536764526 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!values: \n",
      " Refresh buffer every 1000000 sampling!-62.172565\n",
      " ----- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.002382989779282085 values:  -57.578255 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001953543860523412 values:  -62.1933 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002067486248767126 values:  -57.581646 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00284451263521025 values:  -62.352413 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020051560250907963 values:  -57.542515 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002081065765053983 values:  -57.628242 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0034171136064886673 values:  -62.345146 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002660036942870501 values:  -57.657085 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023929871610108757 values:  -57.627544 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015597940107338311 values:  -62.338768 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  9 target diff:  0.0014913562149710046 values:  -57.541218 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020188337793903854 values:  -62.32193 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015376033675998106 values:  -62.29562 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019143431681404818 values:  -62.245476 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020571300968018906 values:  -62.270176 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  11 target diff:  0.0022856682094841555 values:  -62.24149 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9235839441750409 values:  -55.398857 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002353299103651613 values:  -62.1493 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9156666632471525 values:  -59.403923 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027290824095189425 values:  -55.373543 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004465957861674303 values:  -59.446133 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020558861004191485 values:  -62.12283 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00243451487349825 values:  -55.432426 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024605062269889445 values:  -59.488777 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026511789307884065 values:  -55.418587 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021138850358883433 values:  -62.131207 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020178857550214703 values:  -55.436314 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025661337654058784 values:  -59.445354 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002123253120812696 values:  -62.09347 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020419239045171107 values:  -55.4753 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024052921725254053 values:  -59.469074 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0021899281072517984 values:  -62.09084 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001740876705884455 values:  -59.41502 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002084601585305221 values:  -55.5947 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0014035074961699981 values:  -59.447605 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias7 \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kerneltarget diff:  0.0017670929425187224 values:  \n",
      "-55.753235WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias \n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "-----iteration:  WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.17 \n",
      "target diff:  0.00212177648485831WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel values: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias -62.05493\n",
      " -----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  8WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "target diff:  0.002730013588354002 values:  -55.80434 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  18 target diff:  --------------------0.0018300675168142558  values: adv learner  ---------------------62.104706\n",
      " ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019442945230552385 values:  -55.80088 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  10 target diff:  0.0018797210569320001 values:  -55.812675 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0022682026763332307 values:  -62.136616 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0014623879930733268 values:  -55.865124 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002114146619918537 values:  -62.09472 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.001993105425267619 values:  -62.120686 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00202857344660024 values:  -62.161335 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  23 target diff:  0.0024459160658980277 values:  -62.193134 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  24 target diff:  0.002239724889764494 values:  -62.16817 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9226143865931966 values:  -57.42707 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0022143533843890064 values:  -62.120415 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004114230070144865 values:  -57.410625 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018263049865728496 values:  -62.016376 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0017506120355313944 values:  -62.027287 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003437700740515813 values:  -57.312534 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration: -----iteration:   328  target diff: target diff:   0.00184952962309027980.0031203585795501585  values: values:   -57.266766-61.99441  ---------- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028031363603874117 values:  -57.357605 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018459809995965317 values:  -62.086452 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0028654217476545138 values:  -57.370792 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002168014754676697 values:  -62.15545 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9148161267679126 values:  -59.75361 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0021860386921796196 values:  -57.419067 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.00223111943419233 values:  -62.19394 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002837089485086253 values:  -57.461723 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0036628075429814577 values:  -59.84598 ----- \n",
      "\n",
      "-----iteration: -----iteration:  32  target diff:  0.002124340540071918 values:  -62.157988 ----- \n",
      " target diff:  0.002645223611411681 values: \n",
      " -57.394756 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0033062813462036845 values:  -59.92008 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0014740639530542003 values:  -62.13139 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0028957317587800925 values:  -57.43076 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002854242980848657 values:  -59.86115 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018225799495748805 values:  -57.52124 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024533401258653893 values:  -59.837543 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002143697969795627 values:  -57.5469 ----- \n",
      "\n",
      "-----iteration: -----iteration:   512  target diff: target diff:   0.00177685546261009360.0026253922589551627  values: values:  -59.81004 -----  \n",
      "\n",
      "-57.516685 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018787767184810392 values:  -57.565556 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.00196726332811194 values:  -59.838696 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002120122033976188 values:  -59.78799 ----- -----iteration: \n",
      "\n",
      " 14 target diff:  0.00229513597786848 values:  -57.49428 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0017231377915849905 values:  -57.501717 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0026654755771569217 values:  -59.782078 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  16 target diff:  0.0023922988025410455 values:  -57.509922 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020774643012726147 values:  -59.86582 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001763088361787847 values:  -59.715214 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.00178892924751958 values:  -57.498043 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9190377717949205 values:  -63.123756 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002119571889125345 values:  -57.475315 ----- \n",
      "-----iteration: \n",
      " 11 target diff:  0.0024403444241127667 values:  -59.653233 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004195934955125151 values:  -63.078823 -----iteration: -----  19\n",
      "\n",
      " target diff:  0.001314161963860177 values:  -57.494717 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  12 target diff:  0.0017378273617161104 values: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent1/trajs1.pkl! -59.553974 \n",
      "Refresh buffer every 1000000 sampling!-----\n",
      " \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  2 target diff:  0.0020722876214568234 values:  -63.05086 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019876223510916407 values:  -59.56928 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0015517897689661339 values:  -59.520317 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018618642871563386 values:  -63.1274 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002472171982810356 values:  -59.53964 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022218209526546433 values:  -63.16889 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018178507831881345 values:  -59.512123 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001501495992210615 values:  -63.161777 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002109226708475016 values:  -59.50556 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022182750887926473 values:  -63.28713 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018005474079043828 values:  -59.479626 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  19 target diff:  0.0021280113501182837 values:  -59.37384 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0024406640199554973 values:  -63.223347 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.001728223726744901 values:  -59.356438 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017267086118571918 values:  -63.049465 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016759892459858132 values:  -62.887566 ----- -----iteration: \n",
      " 21 \n",
      "target diff:  0.002150478728082794 values:  -59.39153 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0026617748300004993 values:  -59.228188 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001729762407616079 values:  -62.815575 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0012899735591124113 values:  -62.870354 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----iteration:  \n",
      "23WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kerneltarget diff:  \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias0.002055426269910178\n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.values: \n",
      " -59.23911 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  24 target diff:  0.002088864123478326 values:  -59.209106 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9233915343892113 values:  -57.591972 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002033033848433142 values:  -59.201702 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  1 target diff:  0.0027847802410225666 values:  -57.636875 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022483217515782785 values:  -59.072735 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.0021706244899391282 values:  -57.67027 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0023492828783112252 values:  -59.038525 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024114820475847126 values:  -57.705784 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0021300461920634455 values:  -58.888027 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001699233638736167 values:  -57.848644 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.003302335154090756 values:  -58.793552 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022870105974539625 values:  -57.836826 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018582284471808052 values:  -57.854282 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0019394112001809491 values:  -58.672344 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020119490839417735 values:  -57.827785 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020567777056738623 values:  -57.82337 ----- \n",
      "-----iteration: \n",
      " 31 target diff:  0.0021217997908731493 values:  -58.512962 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0014423229666568663 values:  -57.793392 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0024273135834248236 values:  -58.38041 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  33 target diff:  0.0024129536369133127 values:  -58.254337 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0022910235851227533 values:  -58.280094 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9211275919549992 values:  -68.62875 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002217884652032031 values:  -58.135777 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025400913452547362 values:  -68.62751 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019806946774275132 values:  -57.986347 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002288353771665657 values:  -68.69407 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0016552943431924207 values:  -57.83148 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002321209386075716 values:  -68.74251 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001795164914857014 values:  -57.67356 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.0021938139234016804 values:  -68.72273 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0022060591814604567 values:  -57.60737 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0016918335602709828 values:  -57.55175 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9236304418179139 values:  -56.455288 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024796204991754025 values:  -68.681984 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004641069183321036 values:  -56.442104 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0016706028783606208 values:  -57.60329 ----- \n",
      "\n",
      "-----iteration:  6 -----iteration: target diff:   20.002025199960216588  target diff: values:   -68.6500550.005002814739543356  -----values:   \n",
      "\n",
      "-56.48151 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0017498226333065527 values:  -57.68122 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0029471535006073105 values:  -56.49999 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002250388847175717 values:  -57.686012 ----------iteration:   \n",
      "7\n",
      " target diff:  0.002088929036561978 values:  -68.66431 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002390040406375297 values:  -56.439278 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017029156476000556 values:  -68.65987 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.001394292459493003 values:  -57.63793 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023972865887653214 values:  -56.60661 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0013274076243256073 values:  -68.685715 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024810677447793354 values:  -56.67633 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0023029252962508077 values:  -56.69131 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017468399256885304 values:  -56.73277 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023642289059479845 values:  -56.62344 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017858272700824612 values:  -56.564537 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019278008474839672 values:  -56.681087 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0027868395778007683 values:  -56.605316 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  13 target diff:  0.002001762558821674 values:  -56.671307 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0014708690056651837 values:  -56.653084 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9151644511661585 values:  -58.36491 ----- \n",
      "\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.0036088240155815513 values:  -58.504482 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.920233227776398 values:  -62.133392 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0013623076382412215 values:  -62.19355 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.0025902955508679713Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl! values:  \n",
      "-58.531887Refresh buffer every 1000000 sampling! ----- \n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.0024579624582626042 values:  -58.635017 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020990578907446517 values:  -58.669697 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016283753001675972 values:  -58.553307 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002095386411018022 values:  -58.674603 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  7 target diff:  0.001983900598627682 values:  -58.589752 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002694413539649715 values:  -58.70908 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018964658391472443 values:  -58.63398 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020574265472735223 values:  -58.682526 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018886485313769493 values:  -58.751263 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019919649586338573 values:  -58.74338 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  13 target diff:  0.0024406528315294436 values:  -58.74748 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9197485134043127 values:  -65.19672 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001917175991809056 values:  -58.721638 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021092386176326115 values:  -65.23829 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0016462479664197092 values:  -58.75763 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002356589063697511 values:  -65.276726 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019528612169605818 values:  -65.3476 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017859329514604515 values:  -58.70701 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018944715011585764 values:  -58.716557 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023947493962252903 values:  -65.36755 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0015612241440318606 values:  -65.43025 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002094724807102659 values:  -58.68057 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023325581533996274 values:  -65.458046 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0023861178768997105 values:  -58.686314 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017508857117581997 values:  -65.50188 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002556375532772883 values:  -58.697155 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015444692741941185 values:  -65.62807 ----- \n",
      "\n",
      "-----iteration:  9 target diff: -----iteration:   0.002035451979819263721  values: target diff:   -65.67012 ----- 0.002745351860436344 \n",
      "values: \n",
      " -58.735027 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017545275486086738 values:  -65.78091 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020726121940877417 values:  -65.856865 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002223495520455846 values:  -58.750286 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019069689359780158 values:  -65.970345 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.003062762933555032 values:  -58.755257 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002750301378863129 values:  -58.753693 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001986288286740785 values:  -65.95347 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0024286876562089406 values:  -58.685802 ----------iteration:  \n",
      "\n",
      " 14 target diff:  0.0014920169610691438 values:  -65.9497 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.00238927059494458 values:  -58.542683 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0028681922939832283 values:  -58.468513 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  28 target diff:  0.003196421183263685 values:  -58.39032 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  29 target diff:  0.002836678681526764 values:  -58.245777 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0033829276624348405 values:  -58.213604 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9205764031997177 values:  -66.56393 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002922704188162292 values:  -58.12377 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020344623531342388 values:  -66.54961 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0030687125981178503 values:  -58.028896 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0014966294910784873 values:  -66.506256 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  33 target diff:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel0.003225211747206953\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-57.939526WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "34 target diff: \n",
      " 0.002773313458265159 values:  -57.777824 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  35 target diff:  0.0028611316733968112 values:  -57.682922 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002383643529791027 values:  -57.554604 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.00242845510023205 values:  -57.47958 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  38 target diff:  0.002178049998639877 values:  -57.45682 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0026440945997222385 values:  -57.332817 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020997049106118012 values:  -57.25771 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0019266639344368733 values:  -57.15502 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018939580606572857 values:  -57.02465 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0025489851853334727 values:  -56.829685 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002458335336104698 values:  -56.814148 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  45 target diff:  0.002012817888656393 values:  -56.675625 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0024311528409207174 values:  -56.599445 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9197654929439761 values:  -61.76525 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0021503966860502784 values:  -56.544827 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003079037871265352 values:  -61.799595 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0023102715372662654 values:  -56.295986 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002668297315245679 values:  -61.765198 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0028685571466992494 values:  -56.189304 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002557578948887543 values:  -56.10562 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026579691980395123 values:  -61.761543 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0021274365402463966 values:  -55.99517 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0030177994091707895 values:  -61.807407 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0019664976861290834 values:  -55.864582 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019388665059635098 values:  -61.813362 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0020390086488356186 values:  -55.841045 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024802667986378486 values:  -61.808437 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0017676005340662463 values:  -55.78137 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00201561208129662 values:  -61.804493 ----------iteration:   \n",
      "55\n",
      " target diff:  0.0021780771683170596 values:  -55.711773 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.001681684239843966 values:  -55.703133 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019380446439400726 values:  -61.80112 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002614857063686089 values:  -55.709805 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002039933469782312 values:  -55.755337 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002338407843370644 values:  -61.791332 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002613531105114506 values:  -55.699303 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019636119826221586 values:  -61.76197 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.001762301144092541 values:  -55.68206 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018162304153000821 values:  -61.903313 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002507972184927107 values:  -55.688843 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.001807931392841564 values:  -55.60661 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019353307241235912 values:  -61.917805 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.001607273602235152 values:  -55.603394 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002049860711657152 values:  -61.972267 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002009919006196614 values:  -55.491 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0020866694722915563 values:  -61.986134 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0016765245431795569 values:  -55.50608 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0017386926541147847 values:  -55.51418 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0016664225977105153 values:  -61.94755 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0015561499183293736 values:  -55.51294 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020849436286032425 values:  -61.959316 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0014883945779698318 values:  -55.483635 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  17 target diff:  0.001641637013825814 values:  -61.977303 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  18 target diff:  0.001683916921510316 values:  -61.921413 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0018156829855650227 values:  -61.99898 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.001939075911052595 values:  -62.024605 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018627410637388243 values:  -62.035145 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  22 target diff:  0.0018094575806265375 values:  -62.021503 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0015323215133846745 values:  -61.973026 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018399794170844874 values:  -61.87631 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0015092905287571463 values:  -61.87803 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0016014411018940768 values:  -61.810978 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  27 target diff:  0.0018625473898317738 values:  -61.81313 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9154230374851963 values:  -58.59147 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002201368323755606 values:  -61.694633 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034649447019201854 values:  -58.583706 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0020242466437996533 values:  -61.6073 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0023799936030913012 values:  -58.52384 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021224787294850016 values:  -61.595947 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001993334908868484 values:  -58.698555 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0021126285552097467 values:  -61.694824 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021830578820977078 values:  -58.723988 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0020811257957081748 values:  -61.736866 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019192386403328405 values:  -58.639935 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001800273411709388 values:  -61.649136 ----- \n",
      "-----iteration: \n",
      " 6 target diff:  0.0020816966572926488 values:  -58.438625 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0027568710480410812 values:  -61.647564 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002110407579000522 values:  -58.620068 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0021130076342493792 values:  -61.704475 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024939545370165576 values:  -58.63801 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 9  36target diff:   target diff: 0.0017615211610058933  values: 0.0026808283551770016  -58.56734values:   -61.64039----- ----- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  37 target diff:  0.0024756882787548497 values:  -----iteration: -61.571995  -----10  \n",
      "\n",
      "target diff:  0.002021923984998868 values:  -58.52246 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016416287067714825 values:  -58.47819 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001920257218878367 values:  -61.532368 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001731962039171994 values:  -58.403507 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0013739714370791278 values:  -----iteration: -58.36457  -----39  target diff: \n",
      " \n",
      "0.001880319122982534 values:  -61.4682 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0018755551993013195 values:  -61.49289 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0018440695417820763 values:  -61.551296 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  42 target diff:  0.0026204906196817344 values:  -61.597115 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0018728735317625291 values:  -61.630024 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  44 target diff:  0.0015823584199715637 values:  -61.551983 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0016350019818147908 values:  -61.56673 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9147756081769198 values:  -57.782055 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0046991034258661935 values:  -57.909966 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0022276872999764685 values:  -61.507202 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0053190418841576066 values:  -57.79972 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002076536985860409 values:  -61.49703 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002575378801106982 values:  -57.700405 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002337318978428926 values:  -57.602703 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0017075813306971922 values:  -61.445774 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002492789423376782 values:  -57.655117 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002249575987916993 values:  -61.45681 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020532986787384993 values:  -57.59135 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0018220326016733616 values:  -61.51325 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.003034683069667288 values:  -57.433067 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0017024876591613225 values:  -61.506287 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020723645851368636 values:  -57.419727 ----- \n",
      "\n",
      "-----iteration: -----iteration:   529  target diff: target diff:   0.00175724569985149480.0017670444494267184 values:   -57.460285values:   ------61.49001  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015523197831061773 values:  -57.287746 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0021109059054868046 values:  -61.516365 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002436357856217105 values:  -57.318493 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0017440696059792824 values:  -61.510105 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002200829857266238 values:  -57.40249 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0016595519424496905 values:  -61.518314 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019731797586056065 values:  -57.446453 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0017436439827462709 values:  -61.578106 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0014902072569211217 values:  -57.377342 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  57 target diff:  0.0018090351472441933 values:  -61.62954 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  58 target diff:  0.0017261636501811042 values:  -61.595833 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0017925784957299991 values:  -61.457882 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0023634211569066015 values:  -61.44799 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0016321658970533434 values:  -61.410095 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.001394259164066276 values:  -61.419155 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9193117230269399 values:  -64.37911 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9148895103278348 values:  -59.417473 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0012008195836478528 values:  -64.37937 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel1 \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias 0.002833010499652835\n",
      " values: WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. -59.403255 \n",
      "----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  2 target diff:  0.0026706473064307882 values:  -59.364025 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002065193750144987 values:  -59.344505 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002833510322941747 values:  -59.380756 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "-----iteration:  5WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel target diff: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias0.002118513554092864 \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.values:  \n",
      "-59.400043 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0021584332944250915 values:  -59.359367 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001814133442985667 values:  -59.327454 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002058055754050622 values:  -59.309757 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001688955331243524 values:  -59.357098 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017241088668059432 values:  -59.304836 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00200863123455692 values:  -59.328194 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016133417569258808 values:  -59.36289 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018530908064114937 values:  -59.250942 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  14 target diff:  0.0024408785139166615 values:  -59.27055 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001954887932663916 values:  -59.218914 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9181695907780341 values:  -63.59946 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002158162127825661 values:  -59.257385 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004754551305381361 values:  -63.69826 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0024546053849181897 values:  -59.183826 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002479978202189455 values:  -63.6715 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0028066403965099317 values:  -59.12689 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021327650949950648 values:  -63.75721 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0022112291762317 values:  -59.122463 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023350667014900885 values:  -63.69519 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002337339107098413 values:  -63.753834 -----iteration: -----  \n",
      "20\n",
      " target diff:  0.0023957166357555884 values:  -59.07559 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024267837298331814 values:  -63.7721 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019297045218191092 values:  -63.77107 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002428538219788394 values:  -58.98167 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002033095234184359 values:  -63.87849 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019913727212278725 values:  -58.934326 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002278004029694794 values:  -63.84675 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002383945653717305 values:  -63.762745 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0021830940506108827 values:  -58.7925 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0026913391528459074 values:  -63.76304 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002143501195096157 values:  -58.863823 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019481436638141402 values:  -63.805683 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0022498809010642546 values:  -63.769794 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0032977507392080384 values:  -58.674377 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021728573742297494 values:  -63.69837 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023900207300674653 values:  -58.4294 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001952390044763271 values:  -63.688416 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017404699927553208 values:  -63.634552 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002017868697238153 values:  -58.210472 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018067944660085493 values:  -63.628895 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.001993309799863372 values:  -63.607788 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0023159447843096232 values:  -57.99014 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.001465732163373638 values:  -63.643368 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0020395796693035606 values:  -57.852783 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001609815443051809 values:  -57.687096 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0021256959247206164 values:  -57.522923 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002189348885320668 values:  -57.39898 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  33 target diff:  0.002292765502021245 values:  -57.15633 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0021477848493950363 values:  -56.965767 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  35 target diff:  0.0020771469271235092 values:  -56.8968 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.00193699814038987 values:  -56.830746 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9191894603796298 values:  -61.91198 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0023242853082034443 values:  -56.756565 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0019355944362142838 values:  -56.553867 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0008061641557337364 values:  -61.85621 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----iteration:  \n",
      "39 target diff:  0.0024144264241602125 values:  -56.385323 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  40 target diff:  0.00188371456417178 values:  -56.33242 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001697587526709894 values:  -56.25033 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018828400265386725 values:  -56.147488 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0014861669680212109 values:  -56.005524 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9144380398785389 values:  -58.315155 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9184519432960816 values:  -62.444904 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004235470568960301 values:  -58.3342 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002096574444987748 values:  -62.502583 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0030367127255588084 values:  -58.31915 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018537552241622791 values:  -62.57525 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025336086542163045 values:  -58.31738 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.00195758046406516 values:  -62.575893 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0027434268539142347 values:  -58.44736 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017819817778922482 values:  -62.562893 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025625256502862038 values:  -58.466198 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017213987112330155 values:  -62.638298 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  6 target diff:  0.0024376352838334473 values:  -58.429783 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015427865321643614 values:  -62.61552 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015521836259374162 values:  -62.63581 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0027168515531425 values:  -58.363316 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001888893618465167 values:  -62.685192 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021612932736703346 values:  -58.515842 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001803294272187587 values:  -62.653355 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022290750585658645 values:  -58.553467 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015935004006966192 values:  -62.69262 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002524819082573881 values:  -58.54674 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016956134796127708 values:  -62.784542 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002142710410701103 values:  -58.550625 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023726489436510707 values:  -62.836235 ----- \n",
      "\n",
      "-----iteration: -----iteration:   13 12target diff:   0.0016525858785177824 target diff:  0.0017551953481559294values:   -62.927334 values:  ------58.576824  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  14 target diff:  0.00204236738313679 values:  -63.059353 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002084272083594408 values:  -58.570766 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002291145791770811 values:  -58.653584 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002406552866270962 values:  -63.340916 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0024028285679350146 values:  -58.63918 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.00294509161632066 values:  -63.32411 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002160389748244201 values:  -58.73093 -----iteration: -----  17\n",
      " \n",
      "target diff:  0.002198127238380013 values:  -63.289864 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002624330011053615 values:  -58.761295 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.001563838107600992 values:  -63.30457 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0023692239742971848 values:  -63.407104 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.001862784959756828 values:  -58.821495 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002323734480537805 values:  -58.79553 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002399243978923291 values:  -63.39435 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022747255390487063 values:  -58.841682 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0020935027595018665 values:  -58.753292 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002062597068320255 values:  -63.43575 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0017066404702985195 values:  -58.77764 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0025045012934986656 values:  -63.486275 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002059740742303786 values:  -58.799282 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0021492714498930624 values:  -58.739693 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019511528933441782 values:  -63.48257 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0018390017701046001 values:  -58.770996 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002292201325297364 values:  -63.50424 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023953559447127933 values:  -58.751152 ----- \n",
      "\n",
      "-----iteration:  25 target diff: -----iteration:   0.00256067401514698427 values:  target diff:   0.00256320977241868-63.413826  values: ----- -58.749798 \n",
      " -----\n",
      " \n",
      "\n",
      "-----iteration:  28 target diff:  0.0024630865080151154 values:  -58.787083 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0021385043603597454 values:  -58.68368 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0027718353855794545 values:  -63.33775 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021557400712101326 values:  -58.728054 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0026301683623105357 values:  -63.288662 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0032508224703851336 values:  -58.745213 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002220126744512541 values:  -63.277336 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0024328361617913623 values:  -58.799534 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018692470366138288 values:  -63.262146 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0023388667064507267 values:  -58.85199 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0022547731293268915 values:  -58.844902 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0016377988983724522 values:  -63.215813 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0020297828304163346 values:  -58.847942 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0023056322293287 values:  -58.857903 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0015161228363168155 values:  -63.274265 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0018098018351158094 values:  -63.240204 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0018884564123954068 values:  -58.84368 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0017033596200272253 values:  -63.27471 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.003179709062853462 values:  -58.823902 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.00195207316218476 values:  -63.22577 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002706491270241144 values:  -58.785347 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  35 target diff:  0.001962215060893452 values:  -63.294254 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0024911498864678 values:  -58.871468 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0025857609609610016 values:  -58.82591 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019244577659410752 values:  -63.286472 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0020036314903249513-----iteration:   values: 42 -63.284016  target diff: ----- \n",
      " 0.0023501019397002116\n",
      " values:  -58.88403 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017348182763159538 values:  -63.201702 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0024647694876385163 values:  -58.869965 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0019726116703027425 values:  -58.800987 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002023078687810043 values:  -63.14403 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002202452665795663 values:  -58.75138 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0016088858407111595 values:  -63.193806 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0023561752101489996 values:  -58.80304 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017550682761757086 values:  -63.342712 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0031062880702080694 values:  -58.795246 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0021291324794869954 values:  -63.338703 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0022990831855484732 values:  -58.7487 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0017633480094825702 values:  -63.340034 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0026107470662606724 values:  -58.736774 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002557723621507867 -----iteration: values:   44-58.743496 target diff:  ----- 0.0016433644448493009 values:  \n",
      " -63.307335 -----\n",
      " \n",
      "\n",
      "-----iteration:  45 target diff:  0.0019422375809967293 values:  -63.320774 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002136004527334241 values:  -58.700596 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0019690157059535675 values:  -63.275932 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0021642260385121214 values:  -58.643364 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002134408080687931 values:  -63.2327 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002200646463468476 values:  -58.667385 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.001957605980111665 values:  -63.202644 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002230904289649984 values:  -58.638813 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0019844652897542613 values:  -63.20957 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0016886546037192128 values:  -63.184834 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002778586661424254 values:  -58.566353 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.001737427141489633 values:  -63.121647 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.00231428926116053 values:  -58.50069 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0021979799633927606 values:  -63.08871 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0028713658799770594 values:  -58.42794 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0015100999305242176 values:  -63.050846 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002218757451627251 values:  -58.382103 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0023395285267890195 values:  -63.056946 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0019147852348168238 values:  -58.366447 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.001512550257220553 values:  -63.059917 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002147004275942767 values:  -58.36424 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0015222114221286251 values:  -63.06308 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002242176015838157 values:  -58.32632-----iteration:   ----- 57 \n",
      "\n",
      "target diff:  0.001426096326452885 values:  -63.042774 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0025803590020025097 values:  -58.317524 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002282435111376042 values:  -58.316692 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0024089149968151533 values:  -58.278076 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0019590727381906914 values:  -58.276802 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0028285880533676306 values:  -58.274136 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.002563829251426604 values:  -58.28315 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0027795096170306565 values:  -58.327305 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  69 target diff:  0.002312984893004118 values:  -58.329704 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9189180047783332 values:  -63.569683 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0023069742605529293 values:  -58.334026 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0008640070933918165 values:  -63.55481 ----- \n",
      "\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  71 target diff:  0.0030474888014544546 values:  -58.25503 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002260691178025768 values:  -58.181274 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.001963468119632742 values:  -58.17852 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.003092465872710655 values:  -58.13901 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002101897298195899 values:  -58.08077 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  76 target diff:  0.0021299263578254436 values:  -58.097786 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002493925796841926 values:  -58.05015 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.00195463790257646 values:  -58.03535 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0018921809425433557 values:  -57.979465 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0022185551454714262 values:  -58.01368 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0027552695493772185 values:  -57.938904 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.002250583792592618 values:  -57.956932 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002167170333371399 values:  -57.89339 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0021269869640737657 values:  -57.9343 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.002164788337441779 values:  -57.880154 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0021613107500341585 values:  -57.90033 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.001963831239532743 values:  -57.86908 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0024358410062523457 values:  -57.864353 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0017867588828716858 values:  -57.83549 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.002112529205764294 values:  -57.78597 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0019102741563751199 values:  -57.806145 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0021865726616909775 values:  -57.725826 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0019997484168261036 values:  -57.779423 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0020550627116954494 values:  -57.72714 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0019516685130756839 values:  -57.766724 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0021112414046913883 values:  -57.68971 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0019701474964275286 values:  -57.694702 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0017833087391862356 values:  -57.650623 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0018640605982951444 values:  -57.61211 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9183873098808276 values:  -66.712685 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0012614086540697306 values:  -66.6932 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9174191551150339 values:  -67.19169 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  1 target diff:  0.001742055240357708 values:  -67.162834 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  2 target diff:  0.0018000692166727668 values:  -67.191826 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0012883589338062748 values:  -67.30018 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9176157173790194 values:  -66.534615 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002047332196867959 values:  -66.65996 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028911464073963357 values:  -66.616615 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014480119582993385 values:  -66.670425 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9180991606063033 values:  -67.31904 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001901750103755803 values:  -67.33775 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001926306186869057 values:  -67.43132 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026241290142753108 values:  -67.49186 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0013851660395024575 values:  -67.52887 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9177808055562814 values:  -67.97301 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0029154142960543788 values:  -67.97835 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020182364598523425 values:  -67.88377 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002907935180677409 values:  -67.99825 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022052276510851985 values:  -68.079124 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002423973670657593 values:  -68.18304 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002094068702527433 values:  -68.196045 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001210062421275955 values:  -68.20881 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9175616897448837 values:  -64.601814 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001788035674919402 values:  -64.61987 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002136941644288172 values:  -64.65989 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017727397249737366 values:  -64.72298 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0013210312955872624 values:  -64.77749 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9172469567852823 values:  -67.23826 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020071226905926712 values:  -67.247505 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002069824536940605 values:  -67.221695 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018637104706417222 values:  -67.21933 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001604535382233336 values:  -67.19219 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016602115756553695 values:  -67.18978 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016505692431291357 values:  -67.35897 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0026873018115738073 values:  -67.38048 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  8 target diff:  0.0015432934703601053 values:  -67.3081 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001624454439251955 values:  -67.30774 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  10 target diff:  0.0017204948299450473 values:  -67.36521 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0014617859522505308 values:  -67.24379 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9172143301457719 values:  -67.45327 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002749850220443898 values:  -67.51039 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002147777044795015 values:  -67.47593 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017904166783415496 values:  -67.50352 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001587768564469213 values:  -67.52699 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018356272210887715 values:  -67.49511 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019519546770710682 values:  -67.390236 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002384408925498568 values:  -67.35686 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0014434988310041614 values:  -67.409935 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9178929189732179 values:  -68.937256 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002032421785213097 values:  -69.02368 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0023432064282301332 values:  -69.03829 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016666858491445058 values:  -69.08129 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0015211868179187934 values:  -69.10162 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0013280337264521306 values:  -69.21106 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9190792834283779 values:  -67.76457 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003807270573569515 values:  -67.86194 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0032368172629655603 values:  -67.84796 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025756076554500707 values:  -67.98406 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0030459161079765045 values:  -68.16395 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.00339057745668579 values:  -68.240524 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.003042497302721529 values:  -68.24651 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020415835697170006 values:  -68.30629 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  8 target diff:  0.0021622422312432645 values:  -68.36755 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021282077957333573 values:  -68.337364 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019210126969658474 values:  -68.32338 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0017369719727990548 values:  -68.422966 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002654862364507804 values:  -68.580505 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003001178371165402 values:  -68.62517 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  14 target diff:  0.0018477598602424337 values:  -68.6534 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018983868067335601 values:  -68.76518 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002894426435267537 values:  -68.89951 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.003135582185865541 values:  -68.933556 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0016941124819084038 values:  -68.918175 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0016550711324016091 values:  -68.97492 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0015637991846565503 values:  -68.99122 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0020004357967202363 values:  -69.035416 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00192019383912684 values:  -69.06624 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002279055290163748 values:  -69.047104 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0022480457074274627 values:  -69.03627 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0021254567308607044 values:  -69.01856 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002404433057257445 values:  -68.9739 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0022155060117093166 values:  -69.01203 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002326503991358647 values:  -69.06101 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0024480058336140585 values:  -69.0874 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0026198001263858955 values:  -69.03362 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0035173693591268192 values:  -69.02209 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003926881576309854 values:  -69.02488 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.003070261436002951 values:  -68.93217 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0031327948790347408 values:  -68.766304 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.004488364981527968 values:  -68.3913 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.005345272130976879 values:  -67.99083 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0051707328907351705 values:  -67.678535 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  38 target diff:  0.0038415680935316053 values:  -67.39103 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.003925322711856823 values:  -67.26387 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0032988269065688004 values:  -67.067795 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0030545366895010657 values:  -66.716446 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.005229165108364871 values:  -66.59534 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  43 target diff:  0.0036156372919789676 values:  -66.49062 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003477762822349561 values:  -66.43779 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003922222498007501 values:  -66.35795 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003024058498400738 values:  -66.22892 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0032729672349173 values:  -66.16461 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0028995425040511027 values:  -66.03035 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.003240446938366312 values:  -65.83874 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0032921763905520594 values:  -65.720505 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002882688251896287 values:  -65.45891 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.003956232863055318 values:  -65.36879 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0030470534450512694 values:  -65.29351 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0030456071603459913 values:  -65.15658 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0028499112367909247 values:  -65.1385 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0023970802407803984 values:  -65.14538 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0021660380251320626 values:  -65.08624 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.00228173056637854 values:  -65.05273 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002494722167638747 values:  -64.94065 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0032811488750350633 values:  -64.671196 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0026632986937933883 values:  -64.52529 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002025214984049511 values:  -64.45937 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0019499969763173853 values:  -64.4419 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0019208385935571 values:  -64.42967 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0017633753397609203 values:  -64.414795 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0018497051723877953 values:  -64.41283 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0018843927494085245 values:  -64.41189 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.001870664626638489 values:  -64.40299 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0018645627729022328 values:  -64.32544 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0016909182552645751 values:  -64.3075 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  71 target diff:  0.0019366603016454658 values:  -64.12616 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002384383583180569 values:  -64.11996 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0024370274911259568 values:  -63.877422 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.002706655487511034 values:  -63.796566 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002395400719313108 values:  -63.730156 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002351993443757753 values:  -63.69097 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.001697505836803371 values:  -63.66462 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0021246201867528725 values:  -63.557026 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0018484474020903823 values:  -63.49954 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.002195780358695388 values:  -63.284798 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0021059962658093044 values:  -63.159405 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0021363846951284195 values:  -63.13683 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0015262995716556341 values:  -63.154804 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.002269336834001944 values:  -63.093323 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.002090611378291258 values:  -63.091816 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.002207743051763008 values:  -63.05834 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.001878291679846097 values:  -62.974293 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.00199589643253302 values:  -62.964123 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  89 target diff:  0.0021522272414986952 values:  -62.912167 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0018644750452453975 values:  -62.9226 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.00212486675092767 values:  -62.84893 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0017479791536575992 values:  -62.855354 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.002032601177099235 values:  -62.793713 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.001656744923520859 values:  -62.79267 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0020294298033785804 values:  -62.718212 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0017502918436318414 values:  -62.71112 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0019119403042240667 values:  -62.622044 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0017581189347894892 values:  -62.539246 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0012219087829247043 values:  -62.45947 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9165176501031971 values:  -67.1587 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0022105746072639616 values:  -67.11605 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00213231979288418 values:  -67.16051 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001308392232622671 values:  -67.192276 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  0 target diff:  0.9185033307293775 values:  -68.57712 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00278107450395837 values:  -68.67025 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003484689065542691 values:  -68.76669 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002627013248634551 values:  -68.82108 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002921606773912674 values:  -68.9019 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024913512990667724 values:  -68.92365 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019565217731506044 values:  -68.91858 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018007201495043273 values:  -68.93501 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017354461353170955 values:  -69.0585 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023713401006331437 values:  -69.08892 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001733748453035566 values:  -69.10163 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018065504508064346 values:  -69.280205 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002778828320443237 values:  -69.32054 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019190358054592387 values:  -69.36581 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001975956406575984 values:  -69.34427 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0017589250587804605 values:  -69.361275 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0023001326670411388 values:  -69.35497 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  17 target diff:  0.0019535810471729086 values:  -69.32043 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0026412380914405615 values:  -69.27409 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019446899759654574 values:  -69.24291 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0018066913840505425 values:  -69.327 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0020375944475219602 values:  -69.31542 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0026060367429474405 values:  -69.243546 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0021410617934974276 values:  -69.13783 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0022649630969055383 values:  -69.01074 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0025123120716848803 values:  -68.987946 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0025899527621556337 values:  -68.79334 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.00237006303405651 values:  -68.64081 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0023088406353677414 values:  -68.47473 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  29 target diff:  0.0024949196309975922 values:  -68.460915 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0038085417262359957 values:  -68.407394 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0027100133432783426 values:  -68.416756 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002542983736367373 values:  -68.34291 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0022485039625014577 values:  -68.254196 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0020322681836379307 values:  -68.18874 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002258227938189625 values:  -68.04743 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0024144719374468633 values:  -67.80132 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0028745708328737937 values:  -67.43346 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0035141032671040734 values:  -67.13242 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0023319931349354453 values:  -66.95491 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0025118800418269882 values:  -66.76039 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.002442713294584762 values:  -66.49659 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0035668337113359478 values:  -66.23282 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.003625238196042953 values:  -66.031845 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0030284288262635785 values:  -65.67225 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003249844266119956 values:  -65.44224 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0025727881963871057 values:  -64.83694 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.003935652600594716 values:  -64.35203 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.003242003862033044 values:  -63.902824 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.003065397964041789 values:  -63.680855 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002622774916363378 values:  -63.46424 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0025240057504222185 values:  -63.159695 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0026633496962862936 values:  -62.87382 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002462311269172346 values:  -62.756016 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0015499381347674416 values:  -62.69676 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  55 target diff:  0.0019642505010659863 values:  -62.631718 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  56 target diff:  0.0015955657868345276 values:  -62.470116 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0018375454913972437 values:  -62.46282 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0015627742652510066 values:  -62.356743 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0016371397368061596 values:  -62.350586 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0018849631301083173 values:  -62.301758 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0015747032776894422 values:  -62.252476 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0017846556364274182 values:  -62.17089 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0016371993846914308 values:  -62.150215 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.001726380246784591 values:  -62.112957 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0015595545806806111 values:  -62.142998 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0016217725817099288 values:  -62.118076 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0017383239504167457 values:  -62.059452 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0016541950510909496 values:  -62.028362 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0016589503787500554 values:  -61.9847 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0016257861344905894 values:  -61.974407 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0016842109754000476 values:  -61.937904 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0015770970438908816 values:  -61.924656 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.001580419851713637 values:  -61.894924 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  74 target diff:  0.0016459992569456232 values:  -61.880486 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.001799899759750028 values:  -61.8492 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.001353818199128569 values:  -61.787937 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9173788668673354 values:  -68.1462 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001492440946921272 values:  -68.12919 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9173787231539735 values:  -67.4948 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003826707660711744 values:  -67.58694 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002619261423615068 values:  -67.62742 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026330641183640274 values:  -67.69183 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0026741556720804058 values:  -67.7974 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0024935134553619597 values:  -67.81343 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0031014484692490026 values:  -67.781685 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022920694648849316 values:  -67.693565 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002984617988093147 values:  -67.69599 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021738014395025498 values:  -67.72022 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001671899037326005 values:  -67.77577 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00198599479983802 values:  -67.79862 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018292948127689532 values:  -67.991615 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003575416246042271 values:  -67.93782 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021136540871348553 values:  -67.86586 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001953602693156639 values:  -67.84101 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018223754812510464 values:  -67.87592 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0026573157026916574 values:  -67.8491 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002539913980391158 values:  -67.89067 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0025581871423865773 values:  -67.91389 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003586505738395749 values:  -67.93559 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0031130525736042212 values:  -68.04171 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0037521313178086094 values:  -68.22541 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.005381013259966036 values:  -68.263115 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.005450297351515804 values:  -68.27865 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0052466596320327 values:  -68.014175 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.005141016505802447 values:  -67.658875 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  27 target diff:  0.004826910344917689 values:  -67.190994 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0053493267032946315 values:  -66.898155 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.005410927373918137 values:  -66.54255 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.006012108190222307 values:  -66.31682 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.005328449771819888 values:  -66.28475 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.005723543086160105 values:  -65.93214 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.006183603597829849 values:  -65.71289 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.004650432135586516 values:  -65.46195 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0039495473640250925 values:  -65.214676 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0040491617540260715 values:  -64.920334 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.004647839387482404 values:  -64.696465 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0033912323561591925 values:  -64.51781 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0036546283261577675 values:  -64.26969 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0038269052932859106 values:  -64.10002 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.003439030699508313 values:  -63.933678 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0036268385234840077 values:  -63.634052 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0034439526825172234 values:  -63.424778 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003992880128015215 values:  -63.150818 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0036126153306570794 values:  -63.02246 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003093744502425588 values:  -62.828136 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.003180474969492043 values:  -62.641533 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0036273988520915935 values:  -62.473248 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0040072428975901015 values:  -62.26254 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.003480545763625276 values:  -62.113804 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.004517014800669738 values:  -61.970497 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0030047491408350794 values:  -61.871014 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002921945656552623 values:  -61.71493 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  54 target diff:  0.003227673292176052 values:  -61.57476 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0038768267295809012 values:  -61.42624 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.003393516177774423 values:  -61.330727 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.003809618906237647 values:  -61.163174 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0029753615831229693 values:  -61.08285 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0031545549929586293 values:  -60.94287 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0029382846562780282 values:  -60.879986 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002850670167081065 values:  -60.88699 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0029137698267327145 values:  -60.889412 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0025508137530788886 values:  -60.88651 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002532170970636331 values:  -60.9304 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002762863304782993 values:  -60.95367 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0021388173166436535 values:  -61.002766 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.002354683582353217 values:  -60.980297 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0016423625807414073 values:  -60.95861 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0018248026251126942 values:  -60.91837 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0015496829421161207 values:  -60.897713 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  71 target diff:  0.0017508167960273535 values:  -60.847084 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0015116554662917335 values:  -60.84885 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0016944896900857604 values:  -60.811073 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0014859078398889803 values:  -60.797302 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9172620719195114 values:  -69.42984 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002313181235260228 values:  -69.49371 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0015425618079455666 values:  -69.561485 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0015818262051442544 values:  -69.54661 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0014658333215786393 values:  -69.51039 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.917138772546349 values:  -68.68608 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030449667750100987 values:  -68.76079 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024108123222978273 values:  -68.81227 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002131301609256829 values:  -68.9162 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0026924974067994733 values:  -69.017 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002054213493301486 values:  -69.14683 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002728392776937727 values:  -69.178406 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016237365126380563 values:  -69.13293 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017913790824534502 values:  -69.318924 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.003447213695854148 values:  -69.4221 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0023869503312812326 values:  -69.5346 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0032696610066930572 values:  -69.48641 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018871483360017331 values:  -69.49721 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0017392045520855074 values:  -69.58411 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.0020695120109613264 values:  -69.670906 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002558359828921251 values:  -69.686226 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002043166436162028 values:  -69.72334 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0014969795353420605 values:  saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_35000.ckpt-69.782295\n",
      " ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9174575772755459 values:  -67.013664 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020590452961949035 values:  -67.02967 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0013244123209013325 values:  -67.06693 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9184376941498639 values:  -66.22416 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003882036595389451 values:  -66.19427 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00343113512417189 values:  -66.20922 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0032838371589450637 values:  -66.38452 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0044358388814838955 values:  -66.41878 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002619961366294497 values:  -66.40121 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0030600565952811722 values:  -66.44077 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002413771355944443 values:  -66.54637 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.003054706316891058 values:  -66.57586 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0028339485440611787 values:  -66.628815 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0026802329511508723 values:  -66.67913 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021321399476899833 values:  -66.72699 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.00228816568272974 values:  -66.782646 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0017606353941413881 values:  -66.91781 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0025205810076637533 values:  -66.91793 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  15 target diff:  0.0021610403781001384 values:  -66.92503 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.001943146282741112 values:  -66.97021 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0022631960766778063 values:  -66.91679 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002507591682372642 values:  -66.92321 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020668074486798176 values:  -67.038826 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002491870074767753 values:  -66.98875 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0027716620785482884 values:  -67.0103 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0023592383045597204 values:  -67.0091 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0024246827862943444 values:  -67.02455 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0020238190121525204 values:  -67.01935 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0026934979598391244 values:  -66.910835 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002406296666581496 values:  -66.75847 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002898167517601907 values:  -66.51945 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0036230311669835265 values:  -66.28648 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.004493442775298331 values:  -65.99732 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.00420479514014333 values:  -65.92739 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002718110658065615 values:  -65.45747 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.004447557603910095 values:  -65.251205 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.003499074735881624 values:  -64.728294 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.006055863624579643 values:  -64.55739 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003930340193210417 values:  -64.13163 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.005643445987008968 values:  -63.840603 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.004410819170865347 values:  -63.841404 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.004041283140581853 values:  -63.790874 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.003337553380782677 values:  -63.288708 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.004675422360876532 values:  -63.191322 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0034640651874519664 values:  -63.074074 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0034078448293494105 values:  -63.010525 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_5000.ckpt-----iteration: \n",
      " 43 target diff:  0.004064593722696784 values:  -62.877567 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003440980635323637 values:  -62.787632 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003542549993565218 values:  -62.646667 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  46 target diff:  0.0033005474078122736 values:  -62.23456 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.004874640075302725 values:  -62.006954 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.004003451838561426 values:  -61.830914 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002357245440314702 values:  -61.683228 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0038901050622143904 values:  -61.55481 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.003037511224254295 values:  -61.589745 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0035872653039107144 values:  -61.643116 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002220997240661166 values:  -61.75136 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.003090944947263549 values:  -61.830235 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0027137660627504414 values:  -61.870247 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0024229100309976085 values:  -61.87739 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0023538736784621214 values:  -61.84934 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002434180308705251 values:  -61.84704 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002363242153163823 values:  -61.824566 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002114229206757606 values:  -61.806164 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0023760208706804955 values:  -61.792427 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0020314043237568504 values:  -61.755978 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  63 target diff:  0.002150018008085734 values:  -61.77665 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002232448685802357 values:  -61.72303 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002460916327154612 values:  -61.722378 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0016731128683132221 values:  -61.76252 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0022624165013401345 values:  -61.712517 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0021468311181962072 values:  -61.71839 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0017076427526646469 values:  -61.724148 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0019863886022390923 values:  -61.77946 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0020394027037366255 values:  -61.813576 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0017973670121622105 values:  -61.8545 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0013726801120140402 values:  -61.849007 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9175126774787361 values:  -67.14879 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002181753167901552 values:  -67.07763 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017024526410020094 values:  -67.076294 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014410585567247525 values:  -66.990135 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.918685399824548 values:  -66.585625 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004478946355790168 values:  -66.482346 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0039038644482364865 values:  -66.54221 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0033711791471262662 values:  -66.62913 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0031391069234323167 values:  -66.58952 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.003019516285229508 values:  -66.694664 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0033611555380337822 values:  -66.67429 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0029089286615527504 values:  -66.782364 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0029928936108402316 values:  -66.92872 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0026880235081165006 values:  -66.9113 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002389805724057209 values:  -66.99331 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023201779945671457 values:  -67.04328 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023351624252028165 values:  -67.05571 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002779660080003621 values:  -67.16195 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002257801608714476 values:  -67.174095 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002760987477419717 values:  -67.12584 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002878114543118223 values:  -67.23425 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002816921300429658 values:  -67.29044 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002622042757807163 values:  -67.31468 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0025440685320054666 values:  -67.37732 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0020502759588212484 values:  -67.27168 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002605539585953949 values:  -67.333595 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0022481502592760043 values:  -67.3765 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  23 target diff:  0.0026501434706843394 values:  -67.37278 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  24 target diff:  0.002544727260346444 values:  -67.33858 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0028666338889261544 values:  -67.348495 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002624300104118309 values:  -67.27882 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0032069682851792423 values:  -67.1428 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.003669583832344019 values:  -66.92511 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00502215228182818 values:  -66.8218 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.004612595964288825 values:  -66.46357 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  31 target diff:  0.005095966247344392 values:  -65.84079 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.006093421507058072 values:  -65.28302 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.005675393321448236 values:  -64.915764 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0052150436146198974 values:  -64.532936 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.004620362306025266 values:  -64.35368 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0040668088446333284 values:  -64.03744 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0038917376297686614 values:  -63.7775 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.004230004617186472 values:  -63.36657 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.00371835041274845 values:  -63.073986 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.003428441857767648 values:  -62.773914 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.003930289502664598 values:  -62.576664 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.003011874748610991 values:  -62.455402 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002786054561224693 values:  -62.31378 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  44 target diff:  0.002943369835704387 values:  -62.28874 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002721397749908884 values:  -62.29242 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0030965280971656027 values:  -62.253994 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002639064237029333 values:  -62.226894 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002465347848478427 values:  -62.184917 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0021323095095473264 values:  -62.164036 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0021680808498180234 values:  -62.106464 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0018449063577968977 values:  -61.954704 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002340226677283649 values:  -61.817547 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0023248182245142806 values:  -61.675346 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002693310809552536 values:  -61.561222 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0021143036418328574 values:  -61.4245 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0025979006985043505 values:  -61.316425 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.003392146953176137 values:  -61.233757 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0026087559821631 values:  -61.176136 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0025169870059722353 values:  -61.146038 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0020852154883437076 values:  -61.12049 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0018664674199839286 values:  -61.102634 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.001821198217986249 values:  -61.074078 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0017809267519148307 values:  -61.056225 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0020382028119354818 values:  -61.03201 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0016998512782723334 values:  -61.034065 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.001882537388166543 values:  -61.006977 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.001663519532001677 values:  -60.980915 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0016349739583426024 values:  -60.967197 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0016301291271507833 values:  -60.950905 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0016936998681084834 values:  -60.964546 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0019384944545933565 values:  -60.951057 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0019559483623196017 values:  -60.901302 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0014553837487268472 values:  -60.86922 ----- \n",
      "\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9233548246117782 values:  -48.697845 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028089474572727913 values:  -48.727764 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001940932014427078 values:  -48.78324 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002110119305946798 values:  -48.823635 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001779184372642092 values:  -48.86682 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017954606311677455 values:  -48.874817 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001854191519712197 values:  -48.88004 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0018862960402530116 values:  -48.925835 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016371747262845697 values:  -48.95356 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0014964589218636275 values:  -48.956997 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  0 target diff:  0.9232099423569192 values:  -47.50837 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0018603677023244286 values:  -47.504215 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002268777744871877 values:  -47.512306 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014583911440041238 values:  -47.514126 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9228865067646872 values:  -46.665222 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027451394544868095 values:  -46.72016 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003033691110136223 values:  -46.72059 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002333849382850586 values:  -46.75366 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0015158034723963829 values:  -46.814857 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022564495151302616 values:  -46.83237 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001862570494369478 values:  -46.825043 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  7 target diff:  0.0016855952334614936 values:  -46.857456 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0025013263843658537 values:  -46.904133 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  9 target diff:  0.002021309812552442 values:  -46.911503 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014230717704737045 values:  -46.914333 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9233082643188327 values:  -46.792454 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0017351868443155661 values:  -46.766273 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020626172460050784 values:  -46.79964 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  3 target diff:  0.0024206678359400473 values:  -46.83136 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001789517086654366 values:  -46.854668 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002114884247837139 values:  -46.928814 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002095976114881247 values:  -46.95324 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002371408059532717 values:  -47.047855 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023664263305092324 values:  -47.111847 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0033409552371095603 values:  -47.073303 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001779897561956089 values:  -47.09908 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015800609398613317 values:  -47.088142 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022360856976354187 values:  -47.093365 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001552822308225057 values:  -47.100166 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021479945027419968 values:  -47.057182 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001969739419579347 values:  -47.062775 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.001730404175526477 values:  -47.044582 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0020375493926910867 values:  -47.029217 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021885687512580437 values:  -47.014214 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0016528182710868723 values:  -47.04514 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022036563832213297 values:  -47.07116 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017125607585134757 values:  -47.083828 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0026664101459084257 values:  -47.045734 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019547511656762794 values:  -47.04878 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0015128138514506038 values:  -47.062843 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0015463983958731032 values:  -47.047443 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0019197923847190622 values:  -47.03974 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018208477744826497 values:  -47.06646 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0014325877723969603 values:  -47.015137 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  0 target diff:  0.9234043485689798 values:  -46.480927 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004245502224253898 values:  -46.528934 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0034122146535024533 values:  -46.540527 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002852207131540296 values:  -46.552094 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023001140491659944 values:  -46.59478 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019709304698602025 values:  -46.605843 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  6 target diff:  0.0021028192660474255 values:  -46.639484 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020423615454105855 values:  -46.665432 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024075066788608874 values:  -46.708164 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.003129485692293705 values:  -46.729317 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0016726870282934272 values:  -46.682423 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002403822801812632 values:  -46.74024 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0017678880536528487 values:  -46.73361 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019892905758733858 values:  -46.79126 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0017720966919823273 values:  -46.800426 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018412699383076538 values:  -46.82113 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  16 target diff:  0.0024002693188551836 values:  -46.854633 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0022870252648670075 values:  -46.88548 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0022356683811088794 values:  -46.955467 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002321699365937076 values:  -47.021793 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002204183684118657 values:  -47.02881 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.003340428059306943 values:  -47.04038 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0022562206026871365 values:  -47.054485 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002366868609493407 values:  -47.085155 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002611115713905013 values:  -47.108356 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002099490579406274 values:  -47.134125 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0019252496234870864 values:  -47.131893 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  27 target diff:  0.002106525589183244 values:  -47.147884 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002664926059039177 values:  -47.167137 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00259679546504871 values:  -47.17359 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002520034906659866 values:  -47.181915 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0024174067537274095 values:  -47.21474 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0025929882565988503 values:  -47.220562 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0025530307146881363 values:  -47.208126 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0025004732218886373 values:  -47.2756 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003388019737965206 values:  -47.279934 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0028131355832563573 values:  -47.281803 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002740456403235582 values:  -47.26831 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002918492169016884 values:  -47.24397 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  39 target diff:  0.0034157342593935116 values:  -47.232456 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002753005245293406 values:  -47.238873 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0027388374564536874 values:  -47.269444 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0028420705702818278 values:  -47.29086 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0029915468008748143 values:  -47.283344 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0027012827280788014 values:  -47.276634 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003474802905892371 values:  -47.280155 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0034330467591387297 values:  -47.313637 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002579706053215233 values:  -47.339382 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002582128379370409 values:  -47.374672 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002545036586919834 values:  -47.406 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002628659179768902 values:  -47.431824 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0024125419731700036 values:  -47.485264 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0028900212157036437 values:  -47.50636 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0022891118003577427 values:  -47.52901 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0024439296600015296 values:  -47.514957 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0024911861809901467 values:  -47.502834 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.00250490368751962 values:  -47.46395 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.001879665160502742 values:  -47.473915 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002252209581149762 values:  -47.510296 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002320840957507031 values:  -47.49872 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0028809438771490326 values:  -47.513878 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0027931856868063745 values:  -47.47857 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002036271208743183 values:  -47.47865 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0019903628073470753 values:  -47.46381 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0018944955599715777 values:  -47.437824 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0026499728068131857 values:  -47.50675 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0023548619364517497 values:  -47.50778 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.00239554365886998 values:  -47.508842 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0027916526051970187 values:  -47.51785 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0024761241624905563 values:  -47.56147 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0032400762974315635 values:  -47.634 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002913594406679603 values:  -47.652946 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002148950372825524 values:  -47.67574 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002203523705301755 values:  -47.710945 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0023217620234769034 values:  -47.802227 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0026191969451843148 values:  -47.805866 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002225744536679487 values:  -47.892536 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0027992769381515762 values:  -47.898594 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0021813971934233926 values:  -47.939617 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0019163861926022735 values:  -47.951458 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  80 target diff:  0.0018169076384239597 values:  -48.038296 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.002261489295905955 values:  -48.052494 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0019451611811585037 values:  -48.074463 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0016207309297300622 values:  -48.10725 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0018803192797962468 values:  -48.133617 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0017221978961232105 values:  -48.1498 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0014042892673853927 values:  -48.18845 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9241294831149715 values:  -48.253498 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002560584824578622 values:  -48.293545 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002158306473885752 values:  -48.329247 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0019300735233629509 values:  -48.31848 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017752432595603623 values:  -48.331207 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0011885220111461491 values:  -48.382725 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9240611193620246 values:  -47.052612 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038795095457391585 values:  -47.05727 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029616783163287797 values:  -47.038536 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022490145639770336 values:  -47.04328 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002768372506240459 values:  -47.05428 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001619242035039904 values:  -47.05586 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001630219003764917 values:  -47.06815 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00181059565572983 values:  -47.06606 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023373937389763524 values:  -47.10819 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0024036724807912527 values:  -47.142796 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001981021565177217 values:  -47.158962 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020234133813679506 values:  -47.17702 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019537514475738383 values:  -47.18863 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001278807769775862 values:  -47.19437 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9241562105035404 values:  -48.232674 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003158177476118345 values:  -48.303352 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00246588670012869 values:  -48.347504 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002311845308406449 values:  -48.3675 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00199299557792315 values:  -48.39129 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0015576277337703594 values:  -48.423992 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016038133905708467 values:  -48.43589 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0012993038125743794 values:  -48.458652 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9240492052037949 values:  -48.261883 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003358277415893486 values:  -48.34318 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029994819112727097 values:  -48.395935 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002218347790805671 values:  -48.4466 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022275537717556353 values:  -48.476772 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019981753900953237 values:  -48.55247 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001984341134822618 values:  -48.56618 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  7 target diff:  0.0018184471512775243 values:  -48.583412 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0015740248823448242 values:  -48.602898 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019466952612774335 values:  -48.58338 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015401930537142176 values:  -48.62339 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015971898534858427 values:  -48.623394 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.00134801384484796 values:  -48.693634 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9234949222546145 values:  -49.32516 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004220426445064726 values:  -49.39031 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0034141248129119024 values:  -49.38575 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002540255480347885 values:  -49.426304 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00276455628377082 values:  -49.470875 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  5 target diff:  0.0028350652235934032 values:  -49.541023 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.003416415542906772 values:  -49.574184 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0025326075678262414 values:  -49.58085 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0022536029680395356 values:  -49.610325 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00205198777172214 values:  -49.6369 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0023548879089012064 values:  -49.66697 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002032146421211095 values:  -49.628136 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002343242910589726 values:  -49.60763 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020639029255562157 values:  -49.629387 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0016602405916225894 values:  -49.60153 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0015592881686028748 values:  -49.60964 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0023445669055637357 values:  -49.608738 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0016414673171057093 values:  -49.58924 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0022540628919654766 values:  -49.573795 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020218878944158686 values:  -49.590584 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0019250131510282675 values:  -49.551777 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  21 target diff:  0.001628514780186876 values:  -49.51433 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.003415500602827449 values:  -49.469543 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0020048504783861075 values:  -49.42341 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0023109649685523668 values:  -49.453457 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002229057393810446 values:  -49.47647 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002101721956966454 values:  -49.40738 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0022868143656446264 values:  -49.41305 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002119172011221658 values:  -49.41361 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0017948479738391636 values:  -49.451813 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021415513184752087 values:  -49.450386 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0022358145281114496 values:  -49.469635 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002105568193570904 values:  -49.45408 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0019543740758086988 values:  -49.465515 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002042887533705063 values:  -49.465034 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001896424953425636 values:  -49.501385 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0020076563813643832 values:  -49.524 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0017489356961451496 values:  -49.54663 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0018076097363954342 values:  -49.59439 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0017318336504149883 values:  -49.607178 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.001687453583081425 values:  -49.627605 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017756763326455898 values:  -49.642933 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.00198023065865387 values:  -49.661377 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0018937238300594293 values:  -49.682106 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0019741989090675577 values:  -49.71511 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0018754574620791784 values:  -49.78294 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.001983221627514604 values:  -49.812874 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018011334927281175 values:  -49.837517 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.001785096617940263 values:  -49.869347 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.001771305589913252 values:  -49.887047 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0018080944945306331 values:  -49.907673 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0017767648053490983 values:  -49.93058 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0021148717596914134 values:  -49.947903 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0020163286127276706 values:  -49.973522 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  54 target diff:  0.0020768736486755355 values:  -49.98419 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002013406286595618 values:  -49.990784 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.002062318375840447 values:  -50.014553 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0021303247267771205 values:  -50.038395 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0020845138343240717 values:  -50.0755 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0021719598084094173 values:  -50.109417 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0022205813304055464 values:  -50.106236 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0020909308639923256 values:  -50.114006 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0022662134392626974 values:  -50.1508 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002590270928750776 values:  -50.204647 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0027612110857293095 values:  -50.24902 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0027732905172847913 values:  -50.282173 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0028429943868511992 values:  -50.322796 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0029317486365997435 values:  -50.343575 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002995043213008858 values:  -50.35642 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0029913380100704524 values:  -50.38067 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0031263579570807096 values:  -50.38465 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.003084101873164824 values:  -50.391174 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0032450216657309823 values:  -50.41929 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0032117340503243948 values:  -50.4705 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0031402204434032507 values:  -50.486507 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.003227140373147769 values:  -50.52369 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0030294573384517316 values:  -50.539524 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0029298754448076484 values:  -50.545216 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.003139059243923259 values:  -50.56735 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.003099564738081708 values:  -50.619946 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0032758178085443472 values:  -50.623848 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0031011484558095613 values:  -50.654385 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.003377200576755588 values:  -50.730526 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0034362531604982954 values:  -50.772083 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.003181465394802789 values:  -50.832867 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0029302049208695816 values:  -50.864998 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.002868564297509601 values:  -50.910946 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.002836485617076531 values:  -50.936436 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0028778094355620216 values:  -50.965637 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.002586436048699157 values:  -50.987114 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0027919365182601918 values:  -50.984917 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0025015978123400368 values:  -50.994892 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0023734817576050184 values:  -50.97978 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0022275754064830975 values:  -50.950775 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0022720202503102673 values:  -50.92285 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.002319039531490635 values:  -50.910072 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.002331700393536946 values:  -50.948944 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0022551348625224924 values:  -50.94967 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0023417151760059237 values:  -50.987225 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0021448859291642907 values:  -51.031075 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9234769595302549 values:  -46.660454 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038139732879236606 values:  -46.694515 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0038969552531774644 values:  -46.700756 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002769074972604367 values:  -46.68833 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002376955222897886 values:  -46.707756 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002187650276914608 values:  -46.694466 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015576071800549257 values:  -46.714092 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022424988896502 values:  -46.772755 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021461299007831153 values:  -46.829643 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019214821620211423 values:  -46.864586 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002568029223962433 values: saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_40000.ckpt \n",
      "-46.873806 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002082019934648679 values:  -46.889126 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002613218990487175 values:  -46.9309 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002528575445987246 values:  -46.948235 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0014608048652559962 values:  -46.979668 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9240134482145894 values:  -46.295105 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004094633595162376 values:  -46.31823 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0038714060310444296 values:  -46.306248 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026620579102371146 values:  -46.347797 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0029062346136795266 values:  -46.375786 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0026461287588332542 values:  -46.37977 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026277865345346054 values:  -46.364983 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00231031356930345 values:  -46.38354 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002565433546537576 values:  -46.425922 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00294805491499317 values:  -46.422905 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022003519047844324 values:  -46.45113 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020422907941247508 values:  -46.492737 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023404084863020225 values:  -46.49531 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0027568996092207053 values:  -46.533028 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002177499838883292 values:  -46.582584 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002048454959096404 values:  -46.56454 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  16 target diff:  0.0022449261010361833 values:  -46.589275 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0024914349057941236 values:  -46.56701 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002858723179242662 values:  -46.52657 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0027326725016076168 values:  -46.56538 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0027151204446507217 values:  -46.605137 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.00276916400898071 values:  -46.655037 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002884268800806182 values:  -46.65961 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0029626659691667787 values:  -46.625507 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0024872929838904508 values:  -46.639378 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0028008515009808267 values:  -46.624577 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.003115107272663929 values:  -46.546936 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003058237117833619 values:  -46.567417 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002767258667884282 values:  -46.587646 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002492042937390908 values:  -46.537476 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002775588498035904 values:  -46.58212 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0026900003379828332 values:  -46.547176 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003070011275755064 values:  -46.574593 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002647770249624828 values:  -46.589935 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002876677174451662 values:  -46.601406 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002785477764830295 values:  -46.624958 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002797540454899855 values:  -46.640827 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.003335499107292144 values:  -46.664303 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0028729518120154127 values:  -46.68158 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002614460320572955 values:  -46.709846 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0026572353169068788 values:  -46.731995 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0024099385969894196 values:  -46.73899 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0023276391113634743 values:  -46.75122 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0025849531188255155 values:  -46.74718 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002895290266800749 values:  -46.761375 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003112520055238291 values:  -46.743977 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003442206644143898 values:  -46.730694 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.00359579152619017 values:  -46.7377 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0031465676156530826 values:  -46.696873 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.003218898819930554 values:  -46.68513 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0034933734231224673 values:  -46.673847 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.003801482856059071 values:  -46.69424 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0035091015687452403 values:  -46.64239 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0035106762961654428 values:  -46.664394 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0027397215887074197 values:  -46.673725 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0025278177670837883 values:  -46.676105 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.00234908232794763 values:  -46.696247 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002468677723978681 values:  -46.66169 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  58 target diff:  0.00323040408953727 values:  -46.68559 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002897591772555616 values:  -46.74142 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002850640826000235 values:  -46.803623 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0030488315788477416 values:  -46.857002 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0034165234701243677 values:  -46.891033 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002373261312977618 values:  -46.91687 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0023893616743275877 values:  -46.93566 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0024299129053952004 values:  -46.96578 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0026175951131981578 values:  -46.987736 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0030309574071793635 values:  -47.019127 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002538764173726312 values:  -47.04179 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.002205134214686704 values:  -47.074932 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0022443983003799708 values:  -47.097164 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  71 target diff:  0.002086045901840183 values:  -47.135227 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002178860606399924 values:  -47.1666 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0021932298943238325 values:  -47.20295 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.002130385362128722 values:  -47.229816 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0020874090989780147 values:  -47.247654 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0019681158106530073 values:  -47.273186 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002022374745259231 values:  -47.295094 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0019971873444280886 values:  -47.321896 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.002003610849582763 values:  -47.360054 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0021122622228174647 values:  -47.376167 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0018476638146157178 values:  -47.40569 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.002023255601508604 values:  -47.45669 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002242155519951025 values:  -47.497063 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.002192649711676694 values:  -47.52784 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.002099917413328478 values:  -47.554546 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.002031531921424997 values:  -47.57745 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0021123601973691984 values:  -47.60276 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.002066209121216009 values:  -47.62044 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.001993062322867441 values:  -47.634563 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0018900883983916186 values:  -47.656746 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0019376486265876465 values:  -47.685772 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  92 target diff:  0.0019879126536627655 values:  -47.716423 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.002018211553216655 values:  -47.74881 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0020607206347387393 values:  -47.776646 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0022307246889583985 values:  -47.797367 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0021228834481128206 values:  -47.797302 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0020665424178515556 values:  -47.797665 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.002099918799595066 values:  -47.79997 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.002118262300853397 values:  -47.806057 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.923547328315597 values:  -47.634155 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0036527963751889557 values:  -47.66842 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  2 target diff:  0.002478760581631885 values:  -47.717 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002583785353657945 values:  -47.721504 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002301146504517106 values:  -47.77133 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0027769775632796624 values:  -47.784245 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022069843786232048 values:  -47.815075 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001646041393111655 values:  -47.86854 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001760067761752616 values:  -47.883816 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020822166639897052 values:  -47.930477 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001602208501644435 values:  -47.930325 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016241517476449597 values:  -47.95277 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0016903554206849154 values:  -47.9994 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0014193136609553895 values:  -48.063744 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9238313370400646 values:  -48.400352 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004277681926169698 values:  -48.360188 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0036106700454419764 values:  -48.4269 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0033444865832246485 values:  -48.481445 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028730068901666136 values:  -48.52537 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022783880042900537 values:  -48.525005 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0038876629490665693 values:  -48.543545 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0027772270959998263 values:  -48.597622 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024191655949896114 values:  -48.614967 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001608686328074193 values:  -48.64889 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001937927872477929 values:  -48.69015 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001778390883069576 values:  -48.692024 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  12 target diff:  0.0014695276348766668 values:  -48.692783 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.923706387641148 values:  -46.62338 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027037047420812774 values:  -46.64535 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003116048483202941 values:  -46.632637 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022522310471893904 values:  -46.632687 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019449164046206563 values:  -46.6227 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022644290947556153 values:  -46.630547 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016049849794356325 values:  -46.636543 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015407666580361749 values:  -46.666897 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0014698222867876767 values:  -46.666046 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9237379804978366 values:  -48.739357 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034755677865154545 values:  -48.811832 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00316989090297273 values:  -48.8509 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020471854378412164 values:  -48.847267 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024291017822408853 values:  -48.807705 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025902371602591332 values:  -48.869194 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020028471175558412 values:  -48.85348 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016678111942355564 values:  -48.940624 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0022677594865502157 values:  -48.987175 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002085537341311651 values:  -48.959087 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0011989455621463324 values:  -48.98004 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9239424923489515 values:  -47.099174 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038031561867652485 values:  -47.13458 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0022130374064724782 values:  -47.157047 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001644423902555905 values:  -47.10147 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002355750960196226 values:  -47.122078 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001580294829401211 values:  -47.073574 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016922542592403419 values:  -47.035534 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019683489004885444 values:  -47.02961 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017168970873148472 values:  -47.05198 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018706316904300426 values:  -47.05535 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018798023761700863 values:  -47.001354 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019412431083593855 values:  -47.051975 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0014807421219814841 values:  -47.105915 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9230205924585552 values:  -48.849392 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003617540210433118 values:  -48.88473 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0032157496975390013 values:  -48.920128 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0031015629922382625 values:  -48.97147 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002692854704005838 values:  -48.989815 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  5 target diff:  0.0025988257006275216 values:  -48.974422 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001961411193248971 values:  -49.08891 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0033368591906484456 values:  -49.102932 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  8 target diff:  0.0022768210856112833 values:  -49.13474 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0027866811477459653 values:  -49.12482 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0021659215283516367 values:  -49.11817 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002235398504220786 values:  -49.101162 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0017236581111065277 values:  -49.17971 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002923835163718469 values:  -49.21809 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002572286811884976 values:  -49.272312 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002376110422530864 values:  -49.275974 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018453910214393438 values:  -49.2861 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0028706207173615945 values:  -49.317482 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002507705266964604 values:  -49.333427 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0023032510828177605 values:  -49.365345 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002453497855387446 values:  -49.419163 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0035998861455450977 values:  -49.57434 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.004367969937449213 values:  -49.609413 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002627477124058115 values:  -49.588715 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0024818533156605207 values:  -49.594215 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0025070160075791265 values:  -49.561615 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  26 target diff:  0.002916569732201068 values:  -49.570465 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003186128783056014 values:  -49.55134 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0025076331679120263 values:  -49.539253 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002382990930506841 values:  -49.499718 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0028539247924460917 values:  -49.48643 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.003331653873374002 values:  -49.510227 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003718350785421501 values:  -49.50234 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.00381022989872412 values:  -49.47756 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.003165960318733199 values:  -49.419395 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0036833370814786472 values:  -49.473335 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.004251304617505598 values:  -49.473537 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0037423964899973177 values:  -49.45025 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.003872162151952249 values:  -49.50514 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.00440809919644374 values:  -49.548195 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0041623809836254175 values:  -49.531372 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0037743795970165625 values:  -49.47713 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.00402388179694586 values:  -49.484364 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.003523494025948197 values:  -49.439674 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.00350339969467376 values:  -49.420536 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0026739801497297896 values:  -49.41849 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003020290176322809 values:  -49.360737 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.003869958447875795 values:  -49.363953 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0033226880300299736 values:  -49.329014 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.003424187288303091 values:  -49.34177 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.003585829726897277 values:  -49.335796 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0036547680952432765 values:  -49.326252 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.003460121375559552 values:  -49.327106 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.003631588249915375 values:  -49.338703 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0032814126565167603 values:  -49.30788 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.003168532914243228 values:  -49.3349 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.003021965660084832 values:  -49.309013 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  57 target diff:  0.0029282735233635455 values:  -49.2964 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002730916889588207 values:  -49.303455 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0028785803060143275 values:  -49.35661 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0026010606955863477 values:  -49.35867 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0024965613187635438 values:  -49.405308 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0030509772145046543 values:  -49.43049 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0031607417645675927 values:  -49.469532 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0031295817285635266 values:  -49.510838 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0030921048262711063 values:  -49.491447 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002652902515868088 values:  -49.54021 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0022405572425813125 values:  -49.562138 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.00222941329923543 values:  -49.606083 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.002248110470224495 values:  -49.64121 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002096583267627013 values:  -49.713795 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002077325540606974 values:  -49.779316 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002036730732284051 values:  -49.773403 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0021174424300695813 values:  -49.822044 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0016418117875606764 values:  -49.87722 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0016582625579999767 values:  -49.859516 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0023962689444455886 values:  -49.89285 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0020204358449228753 values:  -49.921665 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0019966812473764246 values:  -49.93537 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.001675215767021552 values:  -49.98594 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.001688985449445132 values:  -50.00754 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0022224560449203776 values:  -50.01048 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0020037920527218992 values:  -50.01703 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0018664625574098146 values:  -50.02528 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0017993638903204046 values:  -50.03996 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0018822862989940055 values:  -50.025887 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0018157519183456036 values:  -50.03219 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0014598815734111574 values:  -50.019436 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold3/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9237217366727224 values:  -49.301258 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.00501214692806182 values:  -49.285732 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002678853827314259 values:  -49.31659 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  3 target diff:  0.0024287073262252963 values:  -49.32482 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017361715425710659 values:  -49.322506 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002022179878267619 values:  -49.37104 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  6 target diff:  0.0018775799485324892 values:  -49.416565 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017379883414959663 values:  -49.41498 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001511367692868838 values:  -49.466404 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019496169771804253 values:  -49.4986 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001764492808202429 values:  -49.446896 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021721167803858757 values:  -49.49282 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002750596547229054 values:  -49.514618 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020293946513864907 values:  -49.508354 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0016674346231200538 values:  -49.563324 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0021468335146567316 values:  -49.610374 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0015674918656153575 values:  -49.59872 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002252614952285614 values:  -49.606712 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002297661933235668 values:  -49.633877 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019038732448152407 values:  -49.687798 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002258600475825368 values:  -49.71775 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  21 target diff:  0.0018776706815648463 values:  -49.77914 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00269771477288496 values:  -49.793274 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.00187000856935541 values:  -49.78261 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0017565006669030025 values:  -49.76001 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0017823816164449476 values:  -49.737724 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018346597902348118 values:  -49.74774 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0015385634578005923 values:  -49.7683 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018643864834244025 values:  -49.77691 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0021206839986066504 values:  -49.793236 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0022270167466458234 values:  -49.753197 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0018620092266379853 values:  -49.762993 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0016427816574628086 values:  -49.792847 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002153872845730143 values:  -49.772797 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0021368002499500658 values:  -49.76632 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002024129866895307 values:  -49.77254 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0021498260320097335 values:  -49.77868 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002525526909473683 values:  -49.796124 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0022687902763366733 values:  -49.80003 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0018105486400592237 values:  -49.765476 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0019206920832815129 values:  -49.755283 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.001843493092180828 values:  -49.72427 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0016834337491353326 values:  -49.711605 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0019580598809490445 values:  -49.64809 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.001658209573066842 values:  -49.644245 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0014471884950278684 values:  -49.63908 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9232515892718027 values:  -48.42586 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030588100123205117 values:  -48.46131 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028913515752660443 values:  -48.475445 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0030296109346432776 values:  -48.518074 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019902648565533984 values:  -48.59137 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022189475205797366 values:  -48.663357 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  6 target diff:  0.002393076502212234 values:  -48.631477 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016174801725529495 values:  -48.703796 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019489985773296658 values:  -48.749912 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017577618539452548 values:  -48.758602 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013772595269539605 values:  -48.835457 ----- \n",
      "\n",
      "-------------------- training agent --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_20000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- training agents --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_5000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_10000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_15000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_30000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.917394923383044 values:  -46.15043 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021313728428981596 values:  -46.206974 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0026272613824906105 values:  -46.256763 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  3 target diff:  0.00346582827872253 values:  -46.248962 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001837461630592575 values:  -46.29627 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018180017343806523 values:  -46.35268 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002665696147416598 values:  -46.39242 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002105880628459179 values:  -46.42873 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002062674460881793 values:  -46.398907 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002664187424153924 values:  -46.456932 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0025822758505472786 values:  -46.501102 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016176650432845176 values:  -46.550182 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0013628930882446505 values:  -46.617645 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9175005607396237 values:  -46.256493 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0015396388486483112 values:  -46.23068 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0014590542053639995 values:  -46.21337 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_30000.ckpt\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9170553448470168 values:  -44.818 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0019798525967308195 values:  -44.770496 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024503403378642284 values:  -44.73556 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002014845629028097 values:  -44.742645 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00255178287935655 values:  -44.692833 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002648202444446042 values:  -44.744648 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0030098423455652214 values:  -44.78466 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022544669104241966 values:  -44.79942 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018361065447856245 values:  -44.81318 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0024915870388881787 values:  -44.78955 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002304007519456523 values:  -44.810204 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019835034526778862 values:  -44.85795 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023730403238665094 values:  -44.846924 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  13 target diff:  0.0019720318741621775 values:  -44.862316 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0023700053233712695 values:  -44.871193 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002418432791032694 values:  -44.89425 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002079541030983829 values:  -44.87752 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019275227427971266 values:  -44.913 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018712294993004142 values:  -44.964737 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0020005766837946416 values:  -44.920464 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002163416016558231 values:  -44.900143 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  21 target diff:  0.001801527751485625 values:  -44.89545 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0023416226575036438 values:  -44.910267 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0020413942181042965 values:  -44.94787 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0017570804722121414 values:  -44.877007 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0026861776634899736 values:  -44.922497 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.00232695266516256 values:  -44.929405 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003094648973544541 values:  -44.943188 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002187472847533938 values:  -44.989437 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0027920362528308803 values:  -45.017067 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002062811564561469 values:  -44.94201 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0034931161225003025 values:  -44.892033 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0019726208359219246 values:  -44.883446 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0019436209514936819 values:  -44.812305 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0034011442552586415 values:  -44.834557 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001767064008367478 values:  -44.857716 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019099941701193604 values:  -44.8654 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0021262820972205772 values:  -44.84494 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0019964735621452543 values:  -44.810226 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0035404293263757674 values:  -44.893047 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0034772459370903948 values:  -44.89472 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0020659583741845272 values:  -44.880177 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0020713429742564233 values:  -44.853424 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0015709446590987447 values:  -44.796368 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0020380705650041657 values:  -44.78835 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002010274361999999 values:  -44.799397 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0018456961546772298 values:  -44.791332 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018322116857534942 values:  -44.782967 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0016495937293670127 values:  -44.755806 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  49 target diff:  0.002168805321033048 values:  -44.71573 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0019570323140184315 values:  -44.724506 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.001672840179765128 values:  -44.623528 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0026639890110277116 values:  -44.636173 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.001728260951910318 values:  -44.58659 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.00185871201801889 values:  -44.53293 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.001752428262938487 values:  -44.521072 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.00337208046537708 values:  -44.507458 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0024097928670256895 values:  -44.539658 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0021010810710770295 values:  -44.433994 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.003774998195834546 values:  -44.479412 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0023157968267120397 values:  -44.308216 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.004168692712837328 values:  -44.285778 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0036254168629106308 values:  -44.29266 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002356743858026693 values:  -44.322258 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0020390221968619514 values:  -44.279118 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0020170857911061407 values:  -44.241104 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.001777692550012063 values:  -44.185444 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0038831845018137672 values:  -44.146923 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0025741656048445913 values:  -44.112587 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.002418306704638963 values:  -44.074547 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002336351145440548 values:  -44.10042 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002875190663564113 values:  -44.04527 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002450279912018623 values:  -44.07299 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0018053375029992392 values:  -43.91622 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  74 target diff:  0.003441994222302948 values:  -43.873734 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0030763541012804995 values:  -43.82134 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0030822251108435414 values:  -43.746765 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0032887786069860773 values:  -43.625675 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.002721168766352008 values:  -43.649326 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.002941376865027072 values:  -43.652042 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0027318067666215126 values:  -43.650333 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0026003339283919387 values:  -43.513866 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0028369900071673446 values:  -43.518753 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0018524619326770106 values:  -43.505478 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0016638338846801525 values:  -43.47981 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0016189466535873108 values:  -43.448254 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.001715934141275884 values:  -43.410976 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0018943514694125176 values:  -43.375126 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0018636737334900562 values:  -43.345062 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  89 target diff:  0.001857544835043415 values:  -43.31733 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0017950385315630652 values:  -43.292995 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0018295958888830868 values:  -43.264896 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0016765760015247974 values:  -43.23384 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0017766743386130838 values:  -43.202824 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0017818202154551523 values:  -43.164932 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0022031127095611894 values:  -43.136368 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0018791695924230331 values:  -43.11255 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  97 target diff:  0.001663070917760823 values:  -43.086525 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.001586595574043096 values:  -43.029503 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0014893562046794867 values:  -42.999504 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9179097683291093 values:  -46.19167 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002370468809527784 values:  -46.164555 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002215472434713093 values:  -46.18462 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002007187389764966 values:  -46.125378 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020024953036124095 values:  -46.152164 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021837050929138387 values:  -46.11143 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001908807558652805 values:  -46.09133 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.00198328205488974 values:  -46.04318 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.00184731808606115 values:  -46.028908 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020269341960705307 values:  -46.074562 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022322208877445927 values:  -46.008953 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019091857909530347 values:  -45.918354 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0015674525954422933 values:  -45.932655 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024820512447070752 values:  -45.889584 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002710798523402078 values:  -45.793423 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018865765246453264 values:  -45.79649 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0024735362526836467 values:  -45.723816 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0021575007856168772 values:  -45.707157 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0017245324437234603 values:  -45.670616 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0016175952688533956 values:  -45.656742 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023150590797496907 values:  -45.660465 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0019463507737005176 values:  -45.62072 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002240085582664467 values:  -45.68501 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002059595939042406 values:  -45.641357 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  24 target diff:  0.0017224999694912077 values:  -45.6662 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  25 target diff:  0.0017577726321684145 values:  -45.700768 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  26 target diff:  0.0018610511465693585 values:  -45.68578 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  27 target diff:  0.0031772452314691407 values:  -45.682938 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002152071878453672 values:  -45.654274 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002443605015520359 values:  -45.63412 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002409791200929896 values:  -45.604816 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  31 target diff:  0.002314160693018399 values:  -45.567493 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.00229972642012544 values:  -45.492973 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002646982970262285 values:  -45.53775 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.001797190272098714 values:  -45.51137 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0020604358850709833 values:  -45.444824 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  36 target diff:  0.0020011428558030144 values:  -45.409718 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9257146813119613 values:  -53.102974 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0017901109603966916 values:  -45.43285 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025406374427803693 values:  -53.1571 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0020088697770133837 values:  -45.478424 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0022218849921558296 values:  -53.163685 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0019640148862315925 values:  -45.399387 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0014046098905513497 values:  -53.15241 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002168113031368512 values:  -45.29647 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0025148296424274187 values:  -45.199245 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002363821907596833 values:  -45.18465 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002495433210751443 values:  -45.124203 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.00237921762701435 values:  -45.077415 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0017985967883514709 values:  -45.038498 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  46 target diff:  0.0015870046232090685 values:  -44.961327 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9258573227472936 values:  -53.08393 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0025354408582321923 values:  -45.0185 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002448558496860219 values:  -53.053516 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0022265590926555463 values:  -45.050922 ----- \n",
      "-----iteration:  2 \n",
      "target diff:  0.002014254388594625 values:  -53.04618 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002193787167799179 values:  -45.060238 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001853265440943353 values:  -53.025284 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.001959940555275313 values:  -45.08997 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0023240528014535065 values:  -45.132008 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020246265167632197 values:  -53.027996 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0023681167575995868 values:  -45.17223 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016919228435035218 values:  -52.99263 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  53 target diff:  0.0024497207055303003 values:  -45.208736 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018667309597867323 values:  -53.001408 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0025439148408957207 values:  -45.17253 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002100789371822267 values:  -45.19413 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016278150441168288 values:  -52.9529 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0021715684732062602 values:  -45.212635 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0025051725012940748 values:  -52.918602 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0022609862402737436 values:  -45.170795 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0013664605175402178 values:  -53.013393 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  58 target diff:  0.0019179406479061325 values:  -45.17354 ----- Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  59 target diff:  0.002156755208124723 values:  -45.1272 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.001865461158882512 values:  -45.02485 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002296283610085705 values:  -45.026665 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002150175268868076 values:  -45.031876 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.002106898243034759 values:  -45.02268 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  64 target diff:  0.002038344832501675 values:  -44.951996 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002209656651585634 values:  -44.9471 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002070098769255071 values:  -44.850395 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.00219647211414407 values:  -44.84031 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0020407372388402435 values:  -44.73871 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.00218689389255475 values:  -44.729427 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.001832474533506755 values:  -44.613094 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  71 target diff:  0.0021949929653190857 values:  -44.602127 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9245584723013041 values:  -53.516853 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0019562853962611848 values:  -44.484455 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001976373627225288 values:  -53.537975 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002089072125407281 values:  -44.47147 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001659976174812639 values:  -53.541958 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0019185022286729117 values:  -44.437283 ----------iteration:   \n",
      "3\n",
      " target diff:  0.0015713707565403808 values:  -53.605804 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  4 target diff:  0.001930351356924589 -----iteration: values:   -53.58702575  -----target diff:  \n",
      "\n",
      " 0.0016772063196961184 values:  -44.42225 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018805455882345624 values:  -53.58672 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0022229595144277114 values:  -44.330353 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016362257073913576 values:  -53.60371 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002132063195760829 values:  -44.31809 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015463413431624738 values:  -53.633812 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0020001525103784507 values:  -44.27499 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017940672720209926 values:  -53.59627 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0016786765632005346 values:  -44.246082 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015599089716232383 values:  -53.599384 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.001869891282738376 values:  -44.19425 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013650304050074123 values:  -53.62068 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0014840864719447653 values:  -44.134132 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  0 target diff:  0.9247195393295156 values:  -52.958492 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002597337747769584 values:  -53.026207 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0023651954623472153 values:  -53.054005 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022786653068174005 values:  -52.987038 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002596206268907809 values:  -53.009594 ----- \n",
      "\n",
      "-----iteration:  5 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target diff: \n",
      " 0.0017851948840686904 values:  -52.990173 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016445135885291488 values:  -53.000217 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9184596868782201 values:  -46.732006 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016502526309489782 values:  -52.98708 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0029345827546175133 values:  -46.73714 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021366685257961887 values:  -53.00987 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022939485552174897 values:  -53.04842 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0029517936147075837 values:  -46.728424 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023776389900495277-----iteration:   values: 10 -46.715096 target diff:   0.0018480946620794334----- values:   -53.017124 ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  11 target diff: -----iteration:   40.002014752373520022  values: target diff:  -53.07837  0.001923375953701584-----  \n",
      "values: \n",
      " -46.73449 ----- \n",
      "\n",
      "-----iteration:  12 target diff: -----iteration:   0.00191678313834528275  values: target diff:   0.0019690700369059924-53.080208  values:  ----- -46.710773 \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001408522723740314 values:  -53.03156 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "-----iteration:  6 target diff:  0.001999570793013765 values:  -46.635677 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  7 target diff: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " 0.00224406583397162\n",
      " values:  -46.57409 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  8 target diff:  0.0019033878800670079 values:  -46.503536 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016605190292358798 values:  -46.4734 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002259310797273965 values:  -46.48418 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  11 target diff:  0.00203649925250723 values:  -46.5373 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022650094751749087 values:  -46.480534 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0026713397963007116 values:  -46.47255 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002070358571377392 values:  -46.418217 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001678678689038414 values:  -46.40593 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.001708969766070372 values:  -46.38934 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  17 target diff:  0.0016579874323295254 values:  -46.358723 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021912595921156144 values:  -46.413223 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9248919494088981 values:  -53.341095 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028015389538347023 values:  -53.341843 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0021657636881087113 values:  -46.33507 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0021694856645326868 values:  -53.342937 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022403479100302696 values:  -46.358013 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020250330379686056 values:  -53.389828 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0021384442831548878 values:  -46.3391 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0020882938721858094 values:  -53.369278 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.001795053907060953 values:  -46.290745 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021835246952866707 values:  -53.369686 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0022598525482601427 values:  -46.260117 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015178779102787878 values:  -53.37144 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0022198166676472377 values:  -46.225567 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019305534167655177 values:  -53.39819 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017213287741961031 values:  -53.468327 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002531241295621382 values:  -46.21607 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023169999090700702 values:  -46.251877 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021740847637115876 values:  -53.523727 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001953432939981887 values:  -46.27515 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020364196450399124 values:  -53.46213 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0017568114504400302 values:  -46.237038 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0016567739534503701 values:  -46.185036 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0029788404253527157 values:  -53.473663 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0015875589050361536 values:  -53.47812 -----iteration:  30----- target diff:   \n",
      "\n",
      "0.0027552531159136195 values:  -46.146774 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001986160524215767 values:  -53.49728 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0017935374737001433 values:  -46.107754 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0014958460796876455 values:  -53.47409 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002374213277402556 values:  -46.108185 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0030532801377311115 values:  -46.07711 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0031645119127896304 values:  -46.055016 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001733741642467565 values:  -46.07012 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  36 target diff:  0.0019838661842064755 values:  -46.074646 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9245767920520759 values:  -54.156162 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003414686844998113 values:  -54.18496 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019756247005027704 values:  -45.99224 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024315962553893254 values:  -54.190487 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002542459212086166 values:  -45.922943 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003137851249401969 values:  -54.138653 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0027259102080113037 values:  -54.113976 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0022501902610328655 values:  -45.823982 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002120940539201761 values:  -54.06637 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002509447665132916 values:  -45.7877 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024155394773635627 values:  -54.118114 ----- \n",
      "-----iteration: \n",
      " 41 target diff:  0.0015939710033779772 values:  -45.743378 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021056448495744436 values:  -54.061775 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0016029495096585094 values:  -45.69242 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0017475761510468758 values:  -45.64695 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0022922981467377356 values:  -54.094765 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0015524054442679295 values:  -45.600636 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020788584327830558 values:  -54.12574 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0015529742630720992 values:  -45.542473 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018127530934177797 values:  -54.084576 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002035037722743731 values:  -54.085766 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0018076791524320782 values:  -45.500877 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001643387155316828 values:  -54.06453 ----- \n",
      "\n",
      "-----iteration:  47 target diff: -----iteration:  0.003373671346074464  13values:   target diff: -45.444584 0.0013678185453514103 -----  values: \n",
      " -54.070538 \n",
      "----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  48 target diff:  0.0023893932665391307 values:  -45.363777 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  49 target diff:  0.0018492430709580467 values:  -45.242096 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002243649563449396 values:  -45.21368 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002120980706782287 values:  -45.06956 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration: --------------------  52fqe on dqn & sale  target diff: -------------------- \n",
      "0.0023532882503721343 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelvalues: \n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-44.984184\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  53 target diff:  0.0024417136685002776 values:  -44.92 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0020474254318941887 values:  -44.885685 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.001419397515182207 values:  -44.84903 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9244356100923505 values:  -52.622173 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.003287773512620011 values:  -52.642 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0031418052776596376 values:  -52.643417 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025668195647787525 values:  -52.665096 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.918230417099413 values:  -45.444477 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002156350610791946 values:  -52.716175 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020603581299161434 values:  -45.483337 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002858781849803102 values:  -52.67442 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019519283346925741 values:  -52.715866 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0021513056451051477 values:  -45.525826 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0013099206710491156 values:  -52.71569 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002718822749861398 values:  -45.46982 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023982390874109365 values:  -45.366093 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  5 target diff:  0.0027086998841456826 values:  -45.372482 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022611645536051756 values:  -45.320824 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  7 target diff:  0.0032110378778605897 values:  -45.259087 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9254535279924694 values:  -53.121395 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0019039779333861618 values:  -45.206173 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025447793393353346 values:  -53.112255 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002658823727801355 values:  -45.203476 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019510383272672805 values:  -53.1122 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001587565957173576 values:  -45.214565 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002319355176016807 values:  -53.105034 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002212813191928446 values:  -53.09538 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016947699763594636 values:  -45.21903 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002422102377801545 values:  -53.10293 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0014740886422726087 values:  -45.223083 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  6 target diff:  0.001424663489539984 values:  -53.091908 ----- \n",
      "\n",
      "-------------------- WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias--------------------\n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.adv learner\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "--------------------WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9257407772944665 values:  -52.304867 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025100887859405676 values:  -52.326275 ----- \n",
      "\n",
      "-----iteration:  --------------------0  ckpt: target diff:   50000.9183239701075014  values: -------------------- \n",
      "-45.354065 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "-----iteration: Refresh buffer every 1000000 sampling! \n",
      "2 target diff:  0.002426581122327118 values:  -52.316624 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  3 target diff:  0.002284389109909496 values:  -52.31625 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0038197078076236766 values:  -45.290653 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002167440950583652 values:  -52.260925 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 2  5target diff:   0.0030828054726365194target diff:   values: 0.0023779919616527534  values: -45.335976 -52.19221 -----  -----\n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  6 target diff:  0.002912834995752644 values:  -52.262173 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025994738407817365 values:  -45.285965 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0026094771751977463 values:  -45.316906 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-----iteration: \n",
      " 7 target diff:  0.0026102156472826202 values:  -52.215843 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019794290043485575 values:  -45.304276 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002059877570960624 values:  -52.247738 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.00279114504892513 values:  -45.325775 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017616694156801966 values:  -52.320866 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022811213151026338 values:  -45.368443 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002435534661208542 values:  -52.292633 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024131712202172272 values:  -45.346645 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00215130260243329 values:  -52.251835 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023078081588367104 values:  -45.341263 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002010671837920934 values:  -45.356293 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019620390777011277 values:  -52.268993 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0014850744753243882 values:  -52.299446 -----iteration: -----  11\n",
      " \n",
      "target diff:  0.0026872989214647325 values:  -45.380962 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  12 target diff:  0.0017814748525997641 values:  -45.406742 ----- \n",
      "\n",
      "-----iteration:  0 target diff: -----iteration:   0.92231464608363513  target diff: values:  0.0018691301039950071 -59.93645  values: -----  \n",
      "\n",
      "-45.402336 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0019230600458742249 values:  -59.9416 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021111074566193505 values:  -45.376545 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001964899850921461 values:  -59.9945 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0016553197387436673 values:  -45.337234 ----- \n",
      "\n",
      "-----iteration:  3 -----iteration: target diff:   160.0015721654045220913  target diff: values:  0.0028393473126306873  values: -60.009056 -45.326054  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  17 target diff:  0.0023392769273448285 values:  -45.373108 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  4 target diff:  0.0018474811448839813 values:  -60.023014 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0016990941818760268 values:  -45.36321 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.926345251360192 values:  -52.348167 ----------iteration:   \n",
      "5\n",
      " target diff:  0.001980334681133004 values:  -60.01065 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0027597603497176515 values:  -45.235786 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003077412501357913 values:  -52.294506 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0030929942490698073 values:  -45.29856 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024231045989982518 values:  -60.05673 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028715649181660615 values:  -52.280933 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018036694549330196 values:  -45.248234 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002993939032117585 values:  -52.275524 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002318132697615133 values: -----iteration:   -45.381184 7----- target diff:  \n",
      "\n",
      " 0.003003753888543348 values:  -59.93939 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002356308408093093 values:  -52.260426 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002690248167561641 values:  -45.34771 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0029743526883728453 values:  -52.281464 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002652054408831406 values:  -59.860573 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016077132673725867 values:  -52.283607 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0020426723710407287 values:  -59.874077 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017325314469092351 values:  -52.28292 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002313852727332776 values:  -45.287537 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014215714045175323 values:  -59.921783 ----- \n",
      "-----iteration: \n",
      " 8 target diff:  0.0022742555908652337 values:  -52.30822 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002489779876095558 values:  -45.295273 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016050868203314687 values:  -52.291943 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022465112719487366 values:  -45.14447 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020521066612655403 values:  -52.308258 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002472968680953923 values:  -45.240616 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002399514413283923 values:  -52.392357 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0029114393742820243 values:  -----iteration: -45.21875 12 target diff:   0.002091407379199677----- values:   -52.3913\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00322642698801713 values:  -45.169857 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019909532841718915 values:  -52.417126 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0027215965093139887 values:  -45.097637 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.001594964379622218 values:  -52.38575 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.00231743621883155 values:  -52.36787 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002153910589585841 values:  -44.937634 ----- \n",
      "\n",
      "-----iteration:  WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "16\n",
      " target diff:  0.0025005176564535927 values:  -52.354927 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003021717113579829 values:  -44.892155 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018035264885057061 values:  -52.397373 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9223137299787817 values:  -59.759632 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018886408300440624 values:  -52.411236 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0021531324765856315 values:  -44.852737 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0018374604486614495 values:  -59.789127 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0020651456576757615 values:  -44.85496 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0021708995170407128 values:  -52.42384 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0017078250124695285 values:  -44.857746 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018618116718765617 values:  -59.623844 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0019816985415453793 values:  -52.44372 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0016029960044913452 values:  -44.82031 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002384122411983509 values:  -----iteration:  21-59.566288  target diff: -----  0.0016713209244074436\n",
      "\n",
      " values:  -52.473858 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0025237382888617503 values: -----iteration:   22-44.714  -----target diff:   \n",
      "\n",
      "0.0021349921104639818 values:  -52.50295 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001435659524431733 values:  -59.575954 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "-----iteration:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias23\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "target diff:  WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "0.0018614122374670007WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias -52.46793\n",
      " -----WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  38 target diff:  0.0022132800497126725 values:  -44.561897 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0020984011244825963 values:  -52.478554 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001670113361299044 values:  -52.468315 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002748640259307267 values:  -44.496803 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002135896823904001 values:  -44.47828 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018851876533910253 values:  -52.459225 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002205426336933991 values:  -52.458096 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  41 target diff:  0.0018775348539201884 values:  -44.417675 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0017308139181739916 values:  -52.517906 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018779293367118506 values:  -52.49572 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0019864432887443883 values:  -44.36732 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021228601091238756 values:  -52.42854 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0023336164350169766 values:  -44.287464 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0024159982606204405 values:  -52.392876 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002614009493026064 values:  -44.20803 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0019406727659612073 values:  -52.356308 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.001794023853461287 values:  -44.099712 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0016862596693494793 values:  -52.315773 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  34 target diff:  0.0017808682282469724 values:  -52.308323 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0024355444934458558 values:  -44.084538 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.001523861759191948 values:  -52.32938 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9194952371190022 values:  -54.704838 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0018950317801888043 values:  -52.334827 ----------iteration:  \n",
      "\n",
      " 47 target diff:  0.0026538496338796716 values:  -44.00494 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021437653496671296 values:  -54.715584 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019449739386678288 values:  -52.337368 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0020565853283043087 values:  -43.910652 ----- \n",
      "\n",
      "-----iteration: -----iteration:   382  target diff: target diff:   0.00223211440020138670.0020030264893259675  values: values:  -52.343224  ------54.741158  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  -----iteration: 3  49target diff:   target diff: 0.0011597797011623232  0.0030022381257805136values:   -54.6656values:   -43.83865-----  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  39 target diff:  0.001977846259196368 values:  -52.370697 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0020841336180115718 values:  -43.769375 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0018915845823554065 -----iteration: values:   -52.35598851  target diff: -----  0.002324710838929616\n",
      " \n",
      "values:  -43.683018 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0018622809631838229 values:  -52.37087 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0022220077276965 values: -----iteration:   -52.3766252  -----target diff:   \n",
      "0.002857129166528719\n",
      " values:  -43.61499 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0020067623554853135 values:  -52.369015 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0016246321567075254 values:  -52.3651 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0021147259355370355 values:  -43.485588 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  45 target diff:  0.001945835179005753 values:  -52.338387 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002047371396553237 values:  -43.419052 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.001808855387843788 values:  -52.265057 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9200151070447575 -----iteration: values:  -53.90726 55 target diff:   0.0017869316751894287 values:  ------43.34968 -----  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  47 target diff:  0.0020692090846977248 values:  -52.28896 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0019641261634418573 values:  -----iteration:  -43.30263 1-----  target diff: \n",
      "\n",
      " 0.0028131041731825636 values:  -53.827328 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0018535257718596784 values:  -52.267006 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0017998478883864686 values:  -52.254128 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002048931046959167 values:  -43.27575 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002127657417729043 values:  -53.66622 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0016309122849523022 values:  -52.25326 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  51 target diff:  0.0017793792372765753 values:  -52.228592 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018217281977235564 values:  -53.602543 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0030949654756318857 values:  -43.207573 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0016286574865891688 values:  -52.21482 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0016467288933145125 values:  -53.517925 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0018189548309347086 values:  -52.19039 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0021056560105209825 values:  -43.107323 ----- \n",
      "\n",
      "-----iteration: -----iteration:  5  54 target diff: target diff:   0.0020700759221086420.0015170456259882724 values:   -53.516895values:  -----  \n",
      "\n",
      "-52.157127 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0014128531453319168 values:  -52.128094 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "60 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biastarget diff: \n",
      " WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0026512752629965775 \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelvalues:  -43.04375\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias ----- \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "6WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel \n",
      "0.001153035794056116WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernelvalues:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-53.396175WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias -----\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "\n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!Refresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "\n",
      "Refresh buffer every 1000000 sampling!WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.biasRefresh buffer every 1000000 sampling!\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.biasLoaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  61 target diff:  0.0026499539530243517 values:  -42.99644 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0020973174788999007 values:  -42.91884 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0020450392899614323 values:  -42.82189 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.002360762544266528 values:  -42.760956 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  65 target diff:  0.002397746556121511 values:  -42.697124 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002573081674610209 values:  -42.62771 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "-----iteration:  67 target diff:  0.0024119027523962057 values:  -42.607014 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0018719430401124347 values:  -42.50266 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.002473805148878645 values:  -42.503765 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.001818315888155321 values:  -42.476753 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  71 target diff:  0.0022451451813498076 values:  -42.40196 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002563922429961509 values:  -42.396126 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9258918831558637 values:  -52.33776 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002138744316140199 values:  -52.285038 ----------iteration:   0\n",
      "\n",
      " target diff:  0.9200487198614993 values:  -56.86951 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002492866976663849 values:  -42.385807 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027428909287447786 values:  -52.267426 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028046952818430834 values:  -57.000214 ----- \n",
      "\n",
      "-----iteration:  74 target diff: -----iteration:   0.0023383508769977393 values:   target diff: -42.271046 0.002647192884212046  values: ----- \n",
      " -52.28016 -----\n",
      " \n",
      "\n",
      "-----iteration:  4 target diff:  0.001546939818243477 values:  -52.24832 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0025101860651352225 values:  -42.27985 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024158967500054807 values:  -57.063404 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020514808565652827 values:  -52.303566 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002244593578727886 values:  -42.192307 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002112697450273318 values:  -52.31388 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018196616203746455 values:  -57.124256 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0031374966529548205 values:  -42.209724 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015155522591928853 values:  -52.344837 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017341344908551385 values:  -57.174564 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0018121763755922764 values:  -42.188103 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002168204245841257 values:  -52.33029 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 5  target diff: 79 target diff:   0.00147964746822569320.002556411757370572  values: values:   -57.22105-42.172844  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  9 target diff:  0.0018798354415312131 values:  -52.30541 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020513574693300177 values:  -57.18052 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020446791430758443 values:  -52.303223 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022294117709821004 values:  -57.213287 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0014527294930939375 values:  -52.272316 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017625596878629087 values:  -57.252823 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015492610351766506 values:  -57.318695 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013410597106241612 values:  -57.36926 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9168598798324931 values:  -45.05014 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0023547204264609397 values:  -45.075787 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 target diff:  -----iteration: 0.0021834855282521957  0values:   -45.112553target diff:   ----- 0.9247932698452411\n",
      " \n",
      "values:  -52.910824 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0022594605014135414 values:  -52.821423 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  3 target diff:  0.0024505628457869274 values:  -45.14595 ----- \n",
      "\n",
      "-----iteration:  4 -----iteration: target diff:   0.00190498969118860432  target diff: values:   0.003288101140597-45.095024  values: ----- \n",
      " \n",
      "-52.8214 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.920837036896135 values:  -59.473087 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017678043896021231 values:  -52.743656 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021041150750211153 values:  -45.14791 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002543226166761217 values:  -52.69761 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026599125558132283 values:  -45.183437 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0026075555603028984 values:  -59.514828 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022500055390359017 values:  -45.219395 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0028632602916006593 values:  -52.7604 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  2 target diff:  0.001959334371935769 values:  -59.519188 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022194732741695348 values:  -52.711212 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0022038774100864213 values:  -45.255768 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016818382476709302 values:  -59.61687 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00188409293353275 values:  -45.307156 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017934822616839134 values:  -52.729313 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022562283273244994 values:  -59.63262 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0021618743324221864 values:  -45.332844 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017635895758782137 values:  -52.67576 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0031702319666116877 values:  -45.37136 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016482082270125266 values:  -59.691875 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002161405303487929 values:  -52.605923 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001648045988527462 -----iteration: values:   12 target diff: -59.54787  0.0024090088641453545----- values:   \n",
      "\n",
      "-45.4092 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0021755173220494705 values:  -52.616 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002248810260506989 values:  -59.585888 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002268123314552567 values:  -45.389854 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015087369589659627 values:  -52.63051 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0020985763351589037 values:  -45.40247 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002943007840993579 values:  -45.366077 ----- \n",
      "\n",
      "-----iteration:  12-----iteration:   8target diff:   target diff: 0.0013576026449023605  0.0019583914992344236values:   -52.5721values:   ------59.486298  \n",
      "\n",
      "----- -------------------- \n",
      "ckpt: \n",
      " 35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "-----iteration:  Refresh buffer every 1000000 sampling!\n",
      "16 target diff:  0.0031569685479298066 values:  -45.435253 -----WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 9 target diff:  0.001609943112144413 values:  -59.47709 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration: -----iteration:   1710  target diff: target diff:   0.00149234868479525620.0019826887931664984  values: values:   -59.57355-45.425865  ----- -----\n",
      " \n",
      "\n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  18 target diff:  0.002491347416636916 values:  -45.489735 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  19 target diff:  0.002470641489339993 values:  -45.573574 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0031335460192316476 values:  -45.562794 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002020537583495817 values:  -45.605408 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0015542591693191844 values:  -45.596928 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0022783056347172436 values:  -45.66977 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  24 target diff:  0.0023522777278648078 values:  -45.545353 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002706114534379946 values:  -45.530983 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  26 target diff:  0.0020575155847291503 values:  -45.53782 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001777112034015875 values:  -45.531548 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9259069128097855 values:  -52.539333 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  28 target diff:  0.0031265241951863036 values:  -----iteration: -45.549866  ----- \n",
      "\n",
      "1 target diff:  0.0020323542441749902 values:  -52.539806 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0016907610875068954 values:  -52.532635 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0019599335317161937 values:  -45.555546 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9200784731322449 values:  -57.5089 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022435852638354155 values:  -52.523685 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0024552044958016726 values:  -45.596725 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002152995743219848 values:  -57.50475 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001858650406147816 values:  -52.570065 ----- \n",
      "\n",
      "-----iteration: -----iteration:   52  target diff: target diff:   0.00180112289682596120.0030611246942420295  values: values:   -52.58254-57.49056  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  31 target diff: -----iteration:   0.0016426331636872633 values:  target diff:   0.0024762829478542315-45.564484  values:  ----- -57.549755\n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0014526537896595868 values:  -52.561497 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018481636075917721 values:  -57.477528 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002166169545512442 values:  -57.488705 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003107885129827587 values:  -45.543827 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001712328689579113 values:  -57.486256 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0033336083392101275 values:  -45.525326 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016359146997336307 values:  -57.38967 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 8  34target diff:   target diff: 0.002425260078682683  0.0019245094170915094values:   -57.359474values:   -45.535328-----  ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  9 target diff:  0.002441943127571847 values:  -57.35975 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019692869868445143 values:  -45.47353 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019763600372440645 values:  -57.353428 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0018891440308939013 values:  -45.492043 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  11 target diff:  0.0018229098373094147 values:  -57.357014 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0021127111607416533 values:  -45.439583 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9254324053830442 values:  -52.702583 ----- \n",
      "\n",
      "-----iteration:  38 -----iteration: target diff:   120.002656322960749106  values: target diff:   0.0016245941889343847-45.39635  values:  ----- -57.366257 \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0018865686906413205 values:  -52.675938 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002057826869872416 values:  -45.354897 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018352099875083847 values:  -52.672768 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0021388954488369637 values:  -57.43476 ----- -----iteration: \n",
      " \n",
      "40 target diff:  0.0024216263059209137 values:  -45.34519 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0011345485765105186 values:  -52.665123 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "-----iteration: Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl! \n",
      "Refresh buffer every 1000000 sampling!14\n",
      " target diff:  0.002229642017228575 values:  -57.484344 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----\n",
      " \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  41Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent2/trajs2.pkl!\n",
      " Refresh buffer every 1000000 sampling!target diff: \n",
      " 0.0021019615877881956 values:  -45.342785 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  -----iteration: 15  target diff: 42  0.0026424520176834467target diff:  values:   0.0029647615656237065-57.52921 values:   ------45.330185  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  43 target diff:  0.0018528231828975259 values:  -45.32946 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0019469760362109828 values:  -45.3712 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018174515222929971 values:  -57.434143 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002073467139000342 values:  -45.40945 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  17 target diff:  0.002186365272741031 values:  -57.436543 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0024685413883630846 values:  -45.370163 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0018167187393758988 values:  -45.355507 -----iteration:  ----- \n",
      "\n",
      "18 target diff:  0.0022029222762655586 values:  -57.35731 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002692851766330925 values:  -45.2665 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0030129452134626373 values:  -45.225945 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0025388887452221097 values:  -57.08369 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  50 target diff:  0.002574616692461198 values:  -45.162357 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003462111353599469 values:  -56.984646 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0025025773834356463 values:  -45.12356 ----- \n",
      "-----iteration: \n",
      " 21 target diff:  0.002299187985604828 values:  -56.778465 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0024268070642629314 values:  -45.109337 ----- \n",
      "\n",
      "-----iteration: WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "22 target diff:  0.0028995060886422347 values:  -56.608513 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0016993481713678611 values:  -45.114212 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0025377858614879225 values:  -56.369884 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9248936315856763 values:  -52.423916 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.001992251053305589 values:  -45.06711 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0036761573663146936 values:  -56.14134 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002347782487661742 values:  -52.430046 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0021349354923863003 values:  -45.040646 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018767914380059044 values:  -52.46893 ----- \n",
      "\n",
      "-----iteration:  25 target diff: -----iteration:   560.00302306679067514  target diff:  values:  0.002688365086302296 -55.99493 ----- values: \n",
      " -44.99693\n",
      " ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025575471823836484 values:  -52.46021 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0030990111554270853 values:  -55.75787 ----- \n",
      "-----iteration:  \n",
      "57 target diff:  0.002016239626795774 values:  -44.95861 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002288791452074735 values:  -52.44637 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0026868596057212156 values:  -----iteration:  -52.420174 ----- \n",
      "\n",
      "58 target diff:  0.0021938428813588116 values: -----iteration:  27 -44.906357  target diff:  -----0.0029814084487907715  \n",
      "values:  -55.53303\n",
      " ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0029029894492784824 values:  -55.283333 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0021837881796101756 values:  -44.84331 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0027463228452559423 values:  -52.441277 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0027959817390455226 values:  -44.837772 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016623142971986613 -----iteration: values:  29  -52.420094target diff:   0.0023218298117998024-----  values: \n",
      "\n",
      " -55.190666 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0021218406611582348 values:  -44.80005 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001548319086142711 values:  -52.46628 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0024601801397228546 values:  -54.98766 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002394175177948088 values:  -52.502842 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0016871647745007026 values:  -44.7535 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002326633269777893 values:  -54.77715 ----- -----iteration: \n",
      " \n",
      "10 target diff:  0.0021424998310772265 values:  -52.490288 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  32 target diff:  0.0024875818068662236 values:  -54.64051-----iteration:   -----63  \n",
      "target diff: \n",
      " 0.0025692413066357995 values:  -44.701813 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016560020808931227 values:  -52.51886 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0024583974840637307 values:  -44.732567 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002017765133364524 values:  -54.521828 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  -----iteration: 0.0015034566627586117  values: 65  -52.547302target diff:   -----0.0018184116468285545  values: \n",
      " \n",
      "-44.690887 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0027651057617941025 values:  -54.291786 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0021394379479047934 values:  -44.649845 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001742413542410043 values:  -52.552216 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002633391735854903 values:  -54.13086 ----- \n",
      "\n",
      "-----iteration: -----iteration:   67 36 target diff:  0.0016624678880656208 values:  -44.582607 ----- target diff: \n",
      " \n",
      "0.002475963551980607 values:  -53.897957 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0010265654446627017 values:  -52.54512 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002796021367942411 values:  -44.528214 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002133764320303317 values:  -53.774586 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0024617752691303927 values:  -44.469418 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017663536025241168 values:  -53.558273 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0021739658551314513 values:  -53.46443 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0019165644373380884 values:  -44.45077 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0016221168100411867 values:  -53.29088 ----------iteration:   \n",
      "71\n",
      " target diff:  0.0020714644992167316 values:  -44.37662 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0022036970096270753 values:  -44.31363 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0019430247014457275 values:  -53.09376 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0024294299921944367 values:  -44.275845 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002378031481189057 values:  -52.96826 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0022820684179769954 values:  -44.2375 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  43 target diff:  0.0020155305264192777 values:  -52.870667 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0018470059642638672 values:  -44.19341 ----- \n",
      "\n",
      "-----iteration: -----iteration:  44  0target diff:   0.001530196700166456target diff:  values:  -52.842014  -----0.9239357520886572  values: \n",
      "\n",
      " -53.695744 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  45 target diff:  0.0017588614460064054 values:  -52.725346 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 1  76target diff:   target diff: 0.0014240256767851618  0.0022081763162675842values:   -53.69156 values: -----  \n",
      "-44.173717\n",
      "-------------------- -----  ckpt:  \n",
      "\n",
      "45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/209652396/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.-----iteration:  0 target diff:  0.9224488024011892 values:  -59.47186 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001848180932875817 values:  -46.71458 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016295612059544495 values:  -46.733803 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0029017966924139247 values:  -59.49905 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001954062536113511 values:  -46.791847 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021527359132823966 values:  -46.830505 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002997894385726719 values:  -59.49558 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0017290613792157936 values:  -46.81287 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024577188288276053 values:  -59.4359 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0020769300469233886 values:  -46.83138 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002814661545510274 values:  -59.28293 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.003501017834124141 values:  -59.286922 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0019741809777678978 values:  -46.842155 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0027757529843210065 values:  -59.354607 ----- \n",
      "\n",
      "-----iteration: -----iteration:  7  22target diff:   0.003321082859168848 target diff:  0.001981920867458661 values:  values:  -46.852062 ----- -59.340424\n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  8 target diff:  -----iteration: 0.0028097145845644585  23values:   target diff: -59.41238  0.001880471441724249-----  values: \n",
      " \n",
      "-46.843906 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002563521226410197 values:  -----iteration: -59.4713  -----24 target diff:  0.0026150820842739506 values:  -46.86196 -----  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  10 target diff:  0.0024202497948031046 values:  -59.435883 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0026812571764316213 values:  -46.928356 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021814806943192527 values:  -59.39989 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002499707321109818 values:  -59.3602 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0019425623877103026 values:  -59.31328 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022229938733898807 values:  -46.96378 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0017977903549960788 values:  -59.234802 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018634376808195183 values:  -59.253803 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002188604812635283 values:  -46.977085 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017035974635280185 values:  -59.07441 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0027288707124756228 values:  -47.081245 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0030214801000282765 values:  -59.096066 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0019431269811410828 values:  -59.134457 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0033465005246423245 values:  -47.12612 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0022372830772749257 values:  -58.98821 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002470971689061963 values:  -47.1531 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023986174919057093 values:  -58.988842 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.001955966882576674 values:  -47.147076 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002491021170672428 values:  -59.058613 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0025054335174216017 values:  -59.04044 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0024504496678803586 values:  -47.127018 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0021145930572125955 values:  -59.12467 ----- \n",
      "\n",
      "-----iteration:  24 target diff: -----iteration:   330.002630054502385306 values:  target diff:  -58.989117  -----0.002897626503841425  \n",
      "values: \n",
      " -47.05704 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.00213614349211461 values:  -58.922764 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0027491077386699973 values:  -46.993927 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.001839557371445119 values:  -58.825504 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0023876290256667665 values:  -46.94621 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0023041478153446784 values:  -58.79812 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.002262783985189127 values:  -46.925346 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018196423507530178 values:  -58.615612 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002567005319562088 values:  -46.88991 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0021465979281139933 values:  -58.599552 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0030446828286932186 values:  -46.896152 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002098422892280574 values:  -58.235725 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0031794419171674456 values:  -46.914806 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.003046922090319895 values:  -58.268856 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020282494444505113 values:  -46.90208 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0023322814499066426 values:  -58.019154 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.00195892129783102 values:  -46.87461 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0025155034621985512 values:  -57.86067 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0028025386023511865 values:  -46.843063 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0018221786490608084 values:  -57.624844 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0021255385312374236 values:  -46.800213 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0020995433353182993 values:  -57.439564 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002537032290327766 values:  -46.806797 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0028256412301318813 values:  -46.860294 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0026332104346616166 values:  -57.202694 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0020926669035954168 values:  -46.76878 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0020748679728766167 values:  -57.004765 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002206048871068786 values:  -46.78027 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0023406171249638545 values:  -56.698864 ----- \n",
      "\n",
      "-----iteration: -----iteration:  39  target diff:  0.002825686940050074748  target diff: values:  0.002408886781260846  -56.428665values:   -46.69824-----  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  40 target diff:  0.0026796375912077537 values:  -56.343376 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.003313280390704508 values:  -46.58993 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0020333970678637786 values:  -56.079975 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002420691670695456 values:  -46.52135 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0022634511181934395 values:  -46.546757 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0021514387209571736 values:  -55.831684 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0023496800616430906 values:  -46.461475 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0020350521419005498 values:  -55.70537 ----- \n",
      "-----iteration:  \n",
      "53 target diff:  0.0025255152750628678 values:  -46.506012 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002172475806704749-----iteration:  values:  44  -46.517582target diff:   -----0.001718054900210774  values: \n",
      " \n",
      "-55.540142 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0017080639321001962 values:  -55.379612 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0032336569758783513 values:  -46.46734 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 46  56target diff:   target diff: 0.0016727014569296143  0.0028330181427865366values:   values: -55.22835 -46.48809  ----------  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  47 target diff:  0.0017183963500530027 values:  -55.122528 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0019167680849909163 values:  -46.439583 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002248058118021603 values:  -46.46132 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.001867499962073288 values:  -54.90991 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  49 target diff:  0.0016564591126260522 values:  -54.810585 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002180028576082285 values:  -46.41653 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_25000.ckpt\n",
      "-----iteration:  50 target diff:  0.001621165154937374 values:  -54.64737 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0025139223615811067 values:  -46.39489 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0015096633452673846 values:  -54.42733 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0029463449468110896 values:  -46.38104 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0016599520739700659 values:  -54.209084 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002012643384199716 values:  -46.30177 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0015034379291113309 values:  -53.997185 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0017393586325727605 values:  -46.271046 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.001688573495719746 values:  -53.825222 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0019935653765504515 values:  -46.234013 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0014693133105727338 values:  -53.596535 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner -----iteration:  --------------------\n",
      "65 target diff:  0.0016656999362650031 values:  -46.204533 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.001602015657829337 values:  -46.17489 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0015619750712607885 values:  -46.167133 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0015887651257728154 values:  -46.159115 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  69 target diff:  0.0015339196713187004 values:  -46.151623 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0015584992047731458 values:  -46.14207 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.001588244902387478 values:  -46.053463 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002374222374162358 values:  -46.047897 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0015596211332539424 values:  -46.04 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  74 target diff:  0.0018718737233719153 values:  -45.940857 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  75 target diff:  0.0025437585399552386 values:  -45.863556 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9203888000369862 values:  -55.98095 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0024866288245111415 values:  -45.80162 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025502594149901477 values:  -55.93856 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0026826107413183793 values:  -45.846863 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0015406497231334518 values:  -55.887238 ----- \n",
      "\n",
      "-----iteration:  78 target diff: -----iteration:   30.0035448474429421047  values: target diff:   0.0015289692786193384-45.75726 -----  \n",
      "\n",
      "values:  -55.862064 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0021117071953422515 values:  -55.93294 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0026797353089426474 values:  -45.69106 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0027326437703348106 values:  -55.8826 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002090961677071076 values:  -55.89172 -----iteration: ----- 80 \n",
      " \n",
      "target diff:  0.002724226927581548 values:  -45.726788 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017209111406966077 values:  -55.8677 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0028539908566248633 values:  -45.66944 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001957512730639251 values:  -55.826305 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0025016913591878447 values:  -45.678593 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002155617346170385 values:  -45.68398 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0015357044031341202 values:  -45.682644 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015344407687951005 values:  -55.972607 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.001352405178491231 values:  -45.677654 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  10 target diff:  0.003070037688673209 values:  -55.942947 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0024326593580863494 values:  -55.966934 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  -------------------- 0.0020555183533988693fqe on dqn & sale  values: --------------------\n",
      " -56.001434WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  13 target diff:  0.0021395359540420386 values:  -56.137985 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.003298827347920687 values:  -56.16715 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0019329431496400177 values:  -56.199024 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016440636451683442 values:  -56.10199 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0020408190959157312 values:  -56.018417 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0020718507639399322 values:  -55.88069 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9185595370995241 values:  -45.030445 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002030222876918374 values:  -55.909363 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034254266835971633 values:  -45.00081 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024732011251420863 values:  -44.99368 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002551378176545754 values:  -45.014694 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0026134753399246844 values:  -55.7495 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0024967047108774803 values:  -45.041016 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0024663749472295677 values:  -55.621017 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0025034514669310714 values:  -45.030876 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018927851974586739 values:  -45.038742 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002036698670755568 values:  -55.432755 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002609479499295113 values:  -45.007 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0030104511122340505 values:  -45.02646 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019244478758153759 values:  -55.378498 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0028032922763762736 values:  -45.09467 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0027569428464116323 values:  -55.296177 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002145047145002149 values:  -45.13485 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.00195822293932639 values:  -45.241024 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0020936201689710668 values:  -55.13671 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021909041562018098 values:  -45.15243 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0022034666175002947 values:  -54.84974 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.004277940713972804 values:  -45.172527 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0030396938625029775 values:  -54.691135 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002290958085469004 values:  -54.567432 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0021233435263640385 values:  -45.237057 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001977279480808564 values:  -45.316757 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002160833211517156 values:  -54.3451 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0023777735898266555 values:  -54.206352 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0021112473437848323 values:  -45.221607 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0017210800175148655 values:  -54.052486 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0029348624158110036 values:  -45.226074 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0026478207275763958 values:  -53.895535 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0027462434130397203 values:  -45.28945 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002490069375328647 values:  -53.82988 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.00246984242370814 values:  -45.298862 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 20  target diff: 34  0.0024757513022743514target diff:   values: 0.0023177066417349474  -45.328796values:   ------53.728832 \n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002278058839182319 values:  -----iteration:  -53.64784 21----- target diff:  0.0020493107774391364  \n",
      "values: \n",
      " -45.394684 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019500417351875907 values:  -53.522675 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0023556907920592044 values:  -45.333717 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002101211017023425 values:  -53.441986 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0025467173876270177 values:  -45.24178 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002082853637613286 values:  -53.313766 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.003290765463814985 values:  -45.334538 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0027687666877888053 values:  -53.06546 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  4025 target diff:   target diff:  0.00258365165540947640.002920637030485682 values:  values:   -45.282623-52.869545  ----- -----\n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  41 target diff:  0.0018484412506906672 values:  -52.7627 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.003211131025506424 values:  -45.247772 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002116507869295145 values:  -52.50822 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0032591380031168024 values:  -45.139404 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0027029309678043975 values:  -52.429935 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.00328980515860767 values:  -45.111065 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0017741415987524338 values:  -52.35686 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002781461976197576 values:  -45.04707 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.001565251324373495 values:  -52.30667 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0017299675394799744 values:  -52.202778 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002278367589920043 values:  -52.130627 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0022993045340536423 values:  -45.032993 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0017722844453845153 values:  -52.05183 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0020715613958282504 values:  -51.927162 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0025069121913095494 values:  -44.90519 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002067215746014619-----iteration:   values: 32  target diff: -51.833767  ----- 0.0030492834033447112\n",
      " values:  -44.99762 \n",
      "----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0023677591054262646 values:  -45.056526 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.002004545764439541 values:  -51.723507 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.001385175460320834 values:  -51.60614 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0024049488702031652 values:  -44.92828 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0029395912267998927 values:  -44.9301 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0025093135017273463 values:  -44.852108 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002840578133502889 values:  -44.765472 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002199175399195598 values:  -44.75973 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0035105863788741287 values:  -44.780895 ----- \n",
      "\n",
      "-----iteration:  40WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "target diff:  0.0022168916862181794 values:  -44.801167 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0025897585771468786 values:  -44.79127 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0022462127831260246 values:  -44.760365 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9202088058337267 values:  -57.932465 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_30000.ckpt\n",
      "-----iteration:  1 target diff:  0.0036890287643037228 values:  -58.043133 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002314919144305027 values:  -44.678185 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002155902238995283 values:  -58.027702 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0027569456777484123 values:  -44.560455 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0018616023368247477 values:  -57.90029 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.003235059449482167 values:  -44.446976 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0035739711626985447 values:  -57.989132 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019800416472372266 values:  -58.01532 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.002804087223870445 values:  -44.37772 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002333923144445295 values:  -57.98156 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0029038349504530727 values:  -44.272198 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016660897050465428 values:  -57.901222 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017722375446285567 values:  -57.784584 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0021395213144242415 values:  -44.170975 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018710155806995145 values:  -57.798103 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.003058843305219724 values:  -44.16157 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002285697579219078 values:  -57.71295 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002052785606065807 values:  -44.085846 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016602746906630376 values:  -57.695393 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0034289062670841185 values:  -44.01145 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0015433846663274833 values:  -57.63493 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0026093907364416005 values:  -43.94033 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002266885566531218 values:  -43.892597 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016114035863734996 values:  -57.625404 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0022270886757424836 values:  -43.82555 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-----iteration:  55 target diff:  0.0016586347218380652 values:  -43.785595 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0016038591482088129 values:  -57.693546 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0018375247529872853 values:  -43.72379 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0021584315678251456 values:  -57.72037 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002149198281639987 values:  -43.658634 ----- \n",
      "\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "16Refresh buffer every 1000000 sampling! \n",
      "target diff:  0.001949049272767331 values:  -57.627693 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  58 target diff:  0.002162475895006484 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "values:  -43.553955 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  17 target diff:  0.0025478454292885734 values:  -57.54044 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002544665779738626 values:  -43.50662 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.003030017374624931 values:  -57.51404 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0019064738846833822 values:  -43.428177 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.001987919630349148 values:  -57.325798 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0022653596732918812 values:  -43.448643 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022745596084144137 values:  -57.26956 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  62 target diff:  0.002239882409796454 values:  -43.324524 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002636230548524879 values:  -57.141056 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0024043608325756494 values:  -43.35533 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002114141625546107 values:  -57.102974 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0020391380207441957 values:  -43.346153 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0028061609851626934 values:  -56.916515 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0020404810059917746 values:  -43.34556 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0020706153702010153 values:  -56.901066 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002119701335588718 values:  -43.318462 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0027056841430480242 values:  -56.74179 ----- -----iteration: \n",
      " 67\n",
      " target diff:  0.0024871467418926727 values:  -43.31062 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0018241099716970845 values:  -43.293755 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0021439748308984866 values:  -56.66059 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0018066941722128652 values:  -43.3017 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018460730626619073 values:  -56.495888 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  70 target diff:  0.0025831726430610847 values:  -43.289036 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0022991118989753832 values:  -56.409904 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9172108240953554 values:  -51.429985 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0018671673771783121 values:  -43.300137 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.001975209345207957 values:  -56.165276 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0023297581117515767 values:  -51.433887 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0025635509622530047 values:  -43.294678 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0018682267209663823 values:  -56.077282 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018430984025864612 values:  -51.38701 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0020759312401679646 values:  -43.273926 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0019542076409005214 values:  -55.883797 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002181341498443 values:  -51.445072 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0021816749676354654 values:  -43.271366 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.001691435328112403 values:  -55.731415 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0013055593766171003 values:  -51.55792 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002071985552795428 values:  -43.25969 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002142490169193329 values:  -55.548546 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0019934343897257682 values:  -43.26828 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0017837548066482775 values:  -55.46109 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0022969914488558123 values:  -43.331078 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0017325993043208635 values:  -55.34149 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.003370407019777761 values:  -43.363472 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019448611535236055 values:  -55.27724 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.00241423933357342 values:  -43.373936 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019494136695955816 values:  -55.22047 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0022807596193776055 values:  -43.38115 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0019946336433150566 values:  -55.020912 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0018056564127159095 values:  -43.392365 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0015161987184280914 values:  -54.918053 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0022243618122046623 values:  -43.42741 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  40 target diff:  0.0018510095054778593 values:  -54.733074 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002148642621065809 values:  -43.44638 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 41  84target diff:   0.0017305828183033021target diff:   values: 0.002133211954449312  -54.566723 values: ----- -43.458202 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  0 target diff:  0.918800468318426 values:  -52.093864 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.002204774577766775 values:  -43.502586 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.001445579745999592 values:  -54.426487 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  86 target diff:  0.001940041112719126 values:  -43.52707 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  1 target diff:  0.003461432557766625 values:  -52.147064 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  87 target diff:  0.0018810913524684003 values:  -43.530136 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002391598714454993 values:  -52.09039 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0021379803455226177 values:  -43.55674 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025779652461447424 values:  -52.033943 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0020129514414874827 values:  -43.564198 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0021826723825916178--------------------  values: fqe on dqn & sale  -43.592148 --------------------\n",
      "-----WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  4 target diff:  0.002274006963815122 values:  -51.88461 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0017376770888490047 values:  -43.526646 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002295724133760509 values:  -51.751705 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.002086438950877213 values:  -43.5197 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002234497546956481 values:  -51.67388 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015194927490766819 values:  -51.671333 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0023416374932050737 values:  -43.501736 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001906720497306991 values:  -51.6375 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0018726565840468353 values:  -43.488834 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0021101179633052345 values:  -43.48994 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019617139128773977 values:  -51.54889 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0019261295881512397 values:  -43.474083 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0020251497189011916 values:  -51.80863 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0016226800806477073 values:  -43.39086 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 98  11 target diff: target diff:   0.0030435487461670544 0.0032771008868386436values:   values: -43.3569  -51.66286-----  \n",
      "-----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  12 target diff:  -----iteration: 0.002071641551447174  99values:   target diff: -51.70009 0.0019916996136600516  -----values:   \n",
      "-43.397022 \n",
      "----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9229267432680651 values:  -58.89991 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0024898964672954082 values:  -58.920067 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018889913072547347 values:  -51.764587 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019252652364401888 values:  -58.851486 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002201111269431273 values:  -58.71552 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0029336189425796474 values:  -51.747326 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022440270654664426 values:  -58.64755 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0026049368589401377 values:  -51.774105 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  5 target diff:  0.0019554242107601718 values:  -58.652054 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0018960540619239882 values:  -51.891933 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022013832315482275 values:  -58.631023 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9191400386870254 values:  -46.51202 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.00198976752004947 values:  -51.988697 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001826564526324366 values:  -58.601852 ----- \n",
      "\n",
      "-----iteration:  1 -----iteration: target diff:   18 0.00211180083678224target diff:  values:  0.0025582568965373215 -46.519283 values:   ------52.12869 -----  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  8 target diff:  0.002724279150439719 values:  -58.594162 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018991847387087033 values:  -46.57877 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002788181944167393 values:  -52.043777 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0024635124212942904 values:  -46.581833 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021906889111851812 values:  -58.48712 ----- \n",
      "\n",
      "-----iteration:  10 -----iteration: target diff:  4  0.0020362420725307737target diff:   values: 0.002354633824889903  -58.423443values:   ------46.575138 \n",
      " ----- \n",
      "\n",
      "\n",
      "-----iteration:  20 target diff:  0.001891537288277339 values:  -52.03565 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0020548367788369858 values:  -----iteration: -58.36684  5-----  \n",
      "target diff: \n",
      " 0.0019287374078348015 values:  -46.60166 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0016730014958007684 values:  -51.956184 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018956761071686487 values:  -46.62163 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021578035195542163 values:  -58.54349 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019680395130153004 values:  -51.985786 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0025240212330777593 values:  -58.552784 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022329487068345096 values:  -46.626144 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0021738115813336686 values:  -51.97916 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0017558033418158226 values:  -46.671173 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.00247407900094817 values:  -58.566216 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0021252548787043736 values:  -51.93477 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00203506045968883 values:  -46.701992 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0018304953727424046 values:  -51.907097 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002611804392717391 values:  -----iteration: -46.74487 15  target diff:  0.0024782396083786267----- values:  -58.608067  ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  26 target diff:  0.0014818989363825689 values:  -51.857716 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "-----iteration:  11 target diff:  0.0018104057775887629 values:  -46.80316Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl! \n",
      "-----Refresh buffer every 1000000 sampling! \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!-----iteration:  \n",
      "16 Refresh buffer every 1000000 sampling!target diff:  \n",
      "0.0019884231610335814 values:  -58.61786 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  17 target diff:  0.002149516835378504WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      " \n",
      "values:  -58.617386 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  12 target diff:  0.001997930022104611 values:  -46.830807 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002271521062923579 values:  -58.689526 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024202616521615543 values:  -46.889263 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.001743873807370719 values:  -58.66067 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002584755566300886 values:  -46.87688 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0025199927644171108 values:  -46.8338 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002077350179784662 values:  -58.67508 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019879746566276346 values:  -46.8898 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  17 target diff:  0.0018162024972889568 values:  -46.882458 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0019230819626121747 values:  -58.558937 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002056077800111475 values:  -46.87128 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0025047025505073577 values:  -58.445286 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0018731380650064942 values:  -46.903866 ----------iteration:   \n",
      "23\n",
      " target diff:  0.0024910486482950505 values:  -58.47457 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  24 target diff:  0.0025407486937984716 values:  -58.412098 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.003914056334574394 values:  -46.8601 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0019978624357882735 values:  -58.42227 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  21 target diff:  0.0027591577987740993 values:  -46.818153 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0034810080829361946 values:  -58.323315 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0020523261230320556 values:  -58.31486 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9171663540750893 values:  -51.610756 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002509270179122302 values:  -58.30897 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00235079140502534 values:  -46.822735 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002056177536878234 values:  -51.552975 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.002076856396100632 values:  -58.260124 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0023056741319245565 values:  -46.84125-----iteration:   -----2  \n",
      "target diff: \n",
      " 0.0017143825800020006 values:  -51.56073 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002193608685746017 values:  -58.216553 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.00182746077112486 values:  -51.639214 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002121588556491402 values:  -46.87634 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0024172625836101384 values:  -58.060795 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018791960553570066 values:  -51.653152 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002233089600041826 values:  -46.786648 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002011199807196731 values:  -51.68021 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0021969219637751024 values:  -57.852467 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002546992160156728 values:  -46.814526 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002438563626001945 values:  -57.76332 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0013992218749068403 values:  -51.732956 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_35000.ckpt\n",
      "-----iteration:  27 target diff:  0.002569295652480994 values:  -46.798195 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002139291562635782 values:  -57.482643 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0021013488926061325 values:  -46.90057 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0025462947216223736 values:  -57.28719 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0029365962601557785 values:  -46.92504 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019280763812639403 values:  -57.10659 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019714533500538004 values:  -56.95017 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0021581322717369473 values:  -46.83252 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.00194117008580834 values:  -56.824833 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0018255497003394606 values:  -56.66627 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002919880184424269 values:  -46.75736 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020538710653911535 values:  -56.633457 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002167710105247045 values:  -46.769424 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  41 target diff:  0.0019922475601582353 values:  -56.447174 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002461618761284643 values:  -46.696236 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9179358782979321 values:  -51.81571 ----- -----iteration: \n",
      " 42\n",
      " target diff:  0.0017607719349253767 values:  -56.373295 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0023282944042786785 values:  -46.566044 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0024105859187144485 values:  -56.2102 ----- \n",
      "-----iteration: \n",
      " 1 target diff:  0.003633147591277545 values:  -51.736355 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003016695467143047 values:  -46.579754 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.001844346694219357 values:  -56.097 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0027072279913368962 values:  -51.747177 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0017744761916109522 values:  -56.01582 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0020225181539189323 values:  -46.490757 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022301253332698188 values:  -51.7096 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0017949759154463796 values:  -55.920895 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002338707340409823 values:  -51.61055 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.002122747954891107 values:  -46.440517 ----- \n",
      "\n",
      "-----iteration: -----iteration:   47 5 target diff: target diff:  0.0017974476628299684  0.002306644034835028values:  values:  -55.69138 ----- -51.672073  \n",
      "-----\n",
      " \n",
      "\n",
      "-----iteration:  38 target diff:  0.0019246955672812625 values:  -46.4229 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001980651647627392 values:  -51.622658 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002542707303605884 values:  -55.46166 ----- \n",
      "\n",
      "-----iteration:  7-----iteration:   target diff: 39  0.0020121016690955755 target diff: values:   0.0020196932947547292-51.676315  -----values:   -46.357018 ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  8 target diff:  0.0018910645374770926 values:  -51.63381 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0023620869210062238 values:  -46.337585 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002325979934914424 values:  -55.110188 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002222233717301408 values:  -51.652985 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017336065824758312 values:  -51.597042 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017414551526520638 values:  -46.272552 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.002688632256934645 values:  -54.949974 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023935186863097576 values:  -51.57622 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0022920105471054895 values:  -46.246017 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0024147662763491606 values:  -51.56903 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0022517532956870673 values:  -54.675472 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.00157615910596714-----iteration:   13values:   target diff: -46.23279  0.002578308113294999-----  values:  \n",
      "\n",
      "-51.353672 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002506965655427559 values:  -54.56622 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018685425617755516 values:  -51.336338 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002853489666935243 values:  -46.180233 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.00196615403039069 values:  -54.44174 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0026167988322043146 values:  -51.33793 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002126455090996695 values:  -51.398003 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0024930615444203647 values:  -46.203255 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0025895481251526223 values:  -54.136436 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0019052041425644578 values:  -51.39927 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.003400921003995365 values:  -46.08483 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0029530967774166698 values:  -54.00611 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002062508540626456 values:  -51.35706 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.002551390134671298 values:  -46.067303 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0019118389433462983 values:  -53.74013 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002242895484046874 values:  -51.372257 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0024598524454151017 values:  -46.01487 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0021088194109262558 values:  -53.587868 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0017871746009738413 values:  -51.43097 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0024910130489421436 values:  -45.918907 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.001729672447493807 values:  -53.32612 ----- \n",
      "\n",
      "-----iteration:  50 -----iteration: target diff:   0.002357129172431943659  values: target diff:  -45.92721 0.0020602760854297438  -----values:  \n",
      "\n",
      " -53.126926 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0023572008676705845 values:  -51.43456 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0018302249391193293 values:  -52.963505 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.003503835631271712 values:  -45.846783 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.003294423793135446 values:  -51.431896 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.00203854547747609 values:  -52.738995 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002370327075193424 values:  -51.326363 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0019163373152594656 values:  -45.778694 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0019225177103863195 values:  -52.413227 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.00213964735947585 values:  -51.3305 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0023207098881859248 values:  -52.29018 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0020246985780136935 values:  -45.709003 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0020646396869427614 values:  -52.136417 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002220949873446521 values:  -45.64361 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002467540111094297 values:  -51.991398 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002157039405785016 values:  -51.439373 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0021936772929576163 values:  -51.870308-----iteration:  -----  26\n",
      " \n",
      "target diff:  0.0020779579414883544 values:  -51.563667 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.001966032018593489 values:  -45.56914 ----- \n",
      "\n",
      "-----iteration:  27-----iteration:  target diff:  67 0.0019190779930962991 target diff:   values: 0.0021846261256024692  values: -51.57818  ------51.691273  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0021929855375860353 values:  -45.508877 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0016706604837179119 values:  -51.60116 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0018135117849471943 values:  -51.570717 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0015724488776613756 values: -----iteration:  -51.633522 57  -----target diff:   0.001849263727937392\n",
      " \n",
      "values:  -45.5086 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0020575904952295893 values:  -51.40788 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.001874984368471949 values:  -51.690357 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0017178623132077357 values:  -51.28865 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0017497498411839796 values:  -45.444088 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002041683505317273 values:  -51.19845 ----- \n",
      "\n",
      "-----iteration: -----iteration:   3159  target diff: target diff:  0.0015139792934569752 0.002470915032179564 values:  -45.439156 ----- \n",
      "\n",
      " values:  -51.579823 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002124664517857439 values:  -51.058407 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0017679075994908701 values:  -45.430077 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002274115605909775 values:  -51.474697 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0017712494706459817 values:  -50.932255 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0020085473721976957 values:  -51.479748 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0017009361457053327 values:  -45.420822 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0020431554673845777 values:  -50.801594 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0015111036220792104 values:  -51.539883 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0022242974095013014 values:  -45.441814 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.001685800701801853 values:  -50.688225 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0015833817057031906 values:  -51.615715 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0018530423684656326 values:  -45.42468 ----- -----iteration: \n",
      " \n",
      "76 target diff:  0.0020039436386574483 values:  -50.561203 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0015236951672819435 values:  -51.657337 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 64  target diff: 77  0.0012997487094650853target diff:  0.0016245262764732656 values:   -50.43022 values: -----  -45.42348 ----- \n",
      "\n",
      "-------------------- ckpt:  \n",
      "40000\n",
      " --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!37\n",
      " target diff:  Refresh buffer every 1000000 sampling!0.0015592306600285687\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernelvalues: \n",
      " -51.64969WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel-----\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  78 target diff:  0.0016319300532850912 values:  -50.326416 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  79 target diff:  0.0017465364902715383 values:  -50.23964 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0017182606365911052 values:  -51.584465 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0017238613988264312 values:  -50.154243 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0017163809083313776 values:  -50.07942 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.002446330658936298 values:  -51.584805 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0017908737986365537 values:  -50.00103 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.002126368363256997 values:  -51.628014 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  83 target diff:  0.0017801318510009766 values:  -49.911053 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0018683913498623755 values:  -51.53911 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0017234312823756332 values:  -49.83141 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018851669582729655 values:  -51.59806 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0016716088875871479 values:  -49.753204 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0024704792716949355 values:  -51.42208 -----iteration: -----  86\n",
      " target diff: \n",
      " 0.0016284388146925643 values:  -49.63057 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.001898780103208499 values:  -49.549164 ----------iteration:   \n",
      "44\n",
      " target diff:  0.003077718941740071 values:  -51.343994 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0015714390739161974 values:  -49.47926 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0012820498181228138 values:  -51.360226 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  89 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!target diff: \n",
      " 0.0016545134361013688Refresh buffer every 1000000 sampling! values:  \n",
      "-49.43813 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  90 target diff:  0.0016383596563251483 values:  -49.37286 ----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  91 target diff:  0.0016149651476965478 values:  -49.318775 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9190662510360237 values:  -45.249485 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0015492433274466898 values:  -49.281094 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0033098600580392214 values:  -45.267162 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0015429816965380387 values:  -49.25025 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0038093415433015474 values:  -45.284786 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0015354777286722128 values:  -49.197678 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003289952450746778 values:  -45.24021 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0015068074152036312 values:  -49.16423 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002794710983857897 values:  -45.276546 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  96 target diff:  0.001447160463410607 values:  -49.14655 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002210190620503983 values:  -45.243603 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002785945684662484 values:  -45.26294 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002683720434306409 values:  -45.289707 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002578429080549415 values:  -45.28485 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002036893169661948 values:  -45.31817 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0025596196513112865 values:  -45.33366 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0027483577990615655 values:  -45.392002 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "-----iteration:  12 target diff:  0.0021399151233446167 values:  -45.373726 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9219255588302888 values:  -58.381386 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9185918959172983 values:  -51.733418 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0022431020572188246 values:  -45.411293 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  1 14 target diff:  target diff:  0.00256483231753631140.0024731855564765664  values: values:  -51.861496 -45.46689 ----- ----- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  1 target diff:  0.00320530901795452 values:  -58.386555 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.003547328998606296 values: -----iteration:  2  target diff:  -45.500687 0.0022660185110175445-----  values: \n",
      "\n",
      " -51.847927 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00186685045732314 values:  -58.406498 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017924869372406534 values:  -51.81396 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019103614528111724 values:  -45.520393 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002146274497081012 values:  -51.72678 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001697126114804544 values:  -58.43112 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017541138533976053 values:  -51.738182 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0016346118514415746 values:  -58.391556 ----- \n",
      "\n",
      "-----iteration:  17 target diff: -----iteration:   0.002434634937847116  values: target diff:  0.001988898453170156 -45.471455  -----values:   \n",
      "-51.74656\n",
      " ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016826420956198645 values:  -58.397926 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0020467474805584565 values:  -51.694492 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.002992735088974793 values:  -45.405544 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020292637234652217 values:  -58.438663 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0033036613147778373 values: -----iteration:   -45.4162868  -----target diff:  \n",
      " 0.001821110827595769\n",
      " values:  -51.62773 ----- \n",
      "\n",
      "-----iteration:  -----iteration:  97  target diff: target diff:  0.001531705642629138  values: 0.0020100795158406455  values:  -51.616592 -58.356167----- \n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0021903634246674803 values:  -45.39748 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002618996470863089 values:  -51.49265 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0026074887714459204 values:  -58.46243 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0026853748878459763 values:  -45.41639 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0021971912471247376 values:  -51.56551 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022680309434471627 values:  -58.539772 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.003578135256571046 values:  -45.505558 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0021900064383113147 values:  -51.495487 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001535044342625311 values:  -58.54192 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0029882516183672146 values:  -45.62741 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016686757953480252 values:  -51.551655 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  -----iteration:  0.003162517946608974 11 values: target diff:   -45.685295 -----0.0016892973510970086  values: \n",
      " \n",
      "-58.49517 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.003266787463520313 values:  -51.47455 ----- \n",
      "\n",
      "-----iteration:  25-----iteration:   12target diff:   target diff: 0.0026387868343191877  0.00235770856913272values:   values: -45.75439  -58.531803 ---------- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  26 -----iteration: target diff:   13 target diff: 0.002426951723657999  0.0024050848151708827values:   -45.664234 values: -----  \n",
      "-58.467415\n",
      " ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002207891736278726 values:  -51.372658 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0022855355060665667-----iteration:   values: 27 -58.459217 target diff:   -----0.004177221206377609  \n",
      "values:  \n",
      "-45.604164 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002119839383700108 values:  -51.14465 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.00224160738422924 values:  -58.640102 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0029811839505774866 values:  -45.580807 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0025714536229990235 values:  -51.15342 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0026598118077901865 values:  -58.56046 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0028765372941572474 values:  -45.540176 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0019965816973915433 values:  -51.063293 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.003175437897471532 values:  -58.633633 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002965613654259049 values:  -45.483208 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0030287056967767986 values:  -45.533737 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0022876096912391036 values:  -50.915077 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0027432297696175023 values:  -58.588318 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002966014926485593 values:  -45.39871 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0021177673820034853 values:  -58.62329 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0022901154141464985 values:  -50.852264 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0032253437475091764 values:  -45.491917 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0032630256533638475 values:  -58.574165 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.003144063763153981 values:  -45.484653 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.001904452326138121 values:  -58.606335 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.002478692533622018 values:  -45.33999 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002111451015394405 values:  -50.76242 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0031245812611627012 values:  -45.290047 ----- \n",
      "\n",
      "-----iteration:  22 -----iteration: target diff:  37  0.0020466807055927344target diff:   values:  0.00208360447962888-58.556263  values: -----  \n",
      "-45.31592\n",
      " ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0016361318635897374 values:  -50.64766 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.001672822939198056 values:  -58.5348 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0035841764845102137 values:  -58.530785 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001769873237374753 values:  -45.285183 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0016487095316382316 values:  -50.656116 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0014023185230081908 values:  -50.605545 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0021170481810570837 values:  -58.43094 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0019712383212601987 values:  -58.312336 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0028264858955320046 values:  -45.225864 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0019957726746413474 values:  -58.41617 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0031712945944691266 values:  -45.218903 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0022585931986046676 values:  -58.232784 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0019823452258215485 values:  -45.12124 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0019420999548961705 values:  -58.09605 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0037975730728380145 values:  -45.094303 ----- \n",
      "-----iteration: \n",
      " 30 target diff:  0.0021526162077488997 values:  -57.94927 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  43 target diff:  0.0028027880790739306 values:  -45.0358 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0033583755343832224 values:  -57.864735 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003138548021351209 values:  -44.965405 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0018881406273307526 values:  -57.69176 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9171895730269758 values:  -52.315548 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.001964949267090135 values:  -57.556828 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.0033193162349702725 values:  -----iteration: -44.903603  1 -----target diff:   \n",
      "0.003795118475020086\n",
      " values:  -52.31502 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0017531078792753646 values:  -57.334896 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003908614822246424 values:  -52.244476 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0029450254280768834 values:  -44.817135 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_40000.ckpt\n",
      "-----iteration:  3 target diff:  0.002112237053430293 values:  -52.120655 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019369229002497647 values:  -57.14764 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00240271064519508 values: -----iteration:   -52.197304 47-----  \n",
      "target diff: \n",
      " 0.0032163855183673807 values:  -44.75782 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0020353537133896357 values:  -56.997063 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  5 target diff:  0.0029450091619811223 values:  -52.06516 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.003099064185603054 values:  -56.88429 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.002351088447873077 values:  -44.709522 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0023818101382981054 values:  -52.0929 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001939471144541395 values:  -56.711098 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002460696726793837 values:  -51.974022 ----- \n",
      "\n",
      "-----iteration: -----iteration:   839  target diff: target diff:  0.0018104176136435216  0.002015376968256543values:   values: -56.570168 -51.941986  ----- \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0026753113218111186 values:  -44.703175 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0023915496014080898 values:  -52.033115 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0018822973990679061 values:  -56.344025 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0029335790159727678 values:  -44.671986 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0017274325930514616 values:  -56.229385 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001626102489404605 values:  -52.09197 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023778835751057624 values:  -52.113773 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.002182927407069695 values:  -56.018612 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0025358526025907077 values:  -44.605778 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0020557418959389275 values:  -52.092873 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0017375376848194949 values:  -55.83593 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001468508949179531 values:  -52.194195 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!52 \n",
      "target diff: Refresh buffer every 1000000 sampling! \n",
      "0.0024052652093396304 values:  -44.58648 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  44 target diff:  0.0016985759009406135 values:  -55.662167 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.0031973608744076823 values:  -44.551643 ----- \n",
      "\n",
      "-----iteration:  45-----iteration:   target diff: 54  0.0018750243252312001 target diff:  values: 0.0026933604333147696  values: -55.47396  -44.52172-----  \n",
      "----- \n",
      "\n",
      "\n",
      "-----iteration:  55 target diff:  0.0023471624474605594 values:  -44.486607 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.002329743953482616 values:  -44.44367 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0017213343472565405 values:  -55.22755 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002639497297651059 values:  -44.46254 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0024056240810724646 values:  -54.89994 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  58 target diff:  0.003208033353674821 values:  -44.44993 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0020223849541462706 values:  -54.766 ----- \n",
      "\n",
      "-----iteration: -----iteration:   4959  target diff: target diff:   0.00170513386063095920.002273984265911787  values: values:   -44.471127 -54.54484----- -----  \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  50 target diff:  0.0016223351093257522 values:  -54.418327 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0033256036141617665 values:  -44.45122 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0017231736363321783 values:  -54.26543 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002938633203385137 values:  -44.39162 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0014498413786124273 values:  -54.091522 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  62 target diff: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel 0.0033210462144738174\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias values:  -44.38537\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias \n",
      "----- WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/798842024/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  63 target diff:  0.002083376252424826 values:  -44.346073 WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-----\n",
      " \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  64 target diff:  0.003959761719230747 values:  -44.265053 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9190196851490231 values:  -49.343315 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002142871319086922 values:  -49.373653 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002454880554383044 values:  -44.22969 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  2 target diff:  0.0021435860663514238 values:  -49.375656 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  66 target diff:  0.002022704766920023 values:  -44.217144 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0015976122747050376 values:  -49.33048 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002058698704456755 values:  -49.212166 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.001906258819036888 values:  -44.147163 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001630529035401858 values:  -49.20521 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0020857444420391584 values:  -44.095894 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015902866145144834 values:  -49.20135 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.002386268525486823 values:  -44.041424 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002003583547905877 values:  -49.26669 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.002091597119935888 values:  -44.01102 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0019258599028863872 values:  -43.993294 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0023028209136760594 values:  -49.393726 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.0019125488601373184 values:  -49.365883 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0018310694923435093 values:  -43.9504 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014913233102803937 values:  -49.424213 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.921561419046948 values:  -59.46117 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0022761645830382143 values:  -43.908897 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.001948874165607785 values:  -43.871155 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021026586234081683 values:  -59.528194 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0025028384772940735 values:  -43.790657 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002233020296057329 values:  -59.51212 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.002706666466092379 values:  -43.756428 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002161708266541122 values:  -59.51608 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0018207050748902805 values:  -43.739174 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0014857558266110126 values:  -59.47565 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.002338573691686677 values:  -43.73871 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.001908716934498685 values:  -43.683434 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  80 target diff:  0.001621355693818922 values:  -43.618046 ----- \n",
      "\n",
      "-----iteration:  0-----iteration:   target diff: 81  0.9182402509741648target diff:   values: 0.001971751355559781  values: -53.040977 ----- -43.635  \n",
      "\n",
      "----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028417890053032005 values:  -53.01018 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.002078002349554177 values:  -43.547123 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0023808419962817818 values:  -53.02075 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.001705242144821684 values:  -43.57028 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023898333955957285 values:  -53.053802 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0022485246916189167 values:  -43.51754 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0017033274593586272 values:  -----iteration: -43.534966 4  -----target diff:   \n",
      "0.00249301556256857 \n",
      "values:  -53.10664 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  86 target diff:  0.0021175057805814792 -----iteration: values:   -43.479175  -----target diff:   0.0019014820207121075\n",
      " \n",
      "values:  -53.12806 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.001662400907664909 values:  -43.49406 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001559123607005068 values:  -53.139122 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9196550841005444 values:  -57.686546 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0020778330356744867 values:  -43.438313 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0014539075343273852 values:  -53.142323 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!-----iteration: \n",
      " 89 target diff:  0.0016489902926231838 values:  -43.453033 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  90 target diff:  0.002048658707121078 values:  -43.45202 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002844088589229121 values:  -57.702274 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0018365381350498736 values:  -43.444504 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0022615898588825025 values:  -57.669495 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0018243822746482007 values:  -43.349983 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0020552516941973217 values:  -57.601837 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0017337959524940931 values:  -43.293648 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017967328222813618 values:  -57.582256 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0025777137436097932 values:  -43.28353 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  95 target diff:  0.0018594809846448515 values:  -43.27731 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0019177459709480084 values:  -57.613705 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0019877207377088355 values:  -43.243217 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018859146330210696 values:  -57.492588 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0017061547511403566 values:  -43.235226 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002536861401156834 values:  -57.46233 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0019481748378788757 values:  -43.200108 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002257921889099864 values:  -57.38461 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0017555519233523782 values:  -43.19279 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015118241741012904 values:  -57.368958 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002191621841953196 values:  -57.32568 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  11 target diff:  0.0017818631110762219 values:  -57.2925 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9177801700248094 values:  -50.224167 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002397460608467706 values:  -57.280624 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003628978254931277 values:  -50.19809 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001655757218390611 values:  -57.324356 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0024978248641584814 values:  -50.120117 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019972907089357977 values:  -57.372154 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0022496413156282047 values:  -50.09353 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0016986841841463173 values:  -57.315536 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  16 target diff:  0.002184112269747142 values:  -57.261757 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002036515108721048 values:  -50.086254 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9186241907663347 values:  -44.436222 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0032810596498628873 values:  -50.003803 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002418016875760621 values:  -57.27076 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0016013948689242766 values:  -44.472763 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002156521804359257 values:  -49.94037 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0020571746467120534 values:  -44.474987 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0027525731877423233-----iteration:   values: 7  -44.504433target diff:   -----0.0021924133703213507 \n",
      " -----iteration: \n",
      " values: 18 -49.906246 target diff:   0.0025374522616691364-----  \n",
      "values: \n",
      " -57.23751 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022527546029586197 values:  -44.547684 ----- \n",
      "\n",
      "-----iteration:  8-----iteration:   target diff: 19 target diff:   0.00182898701444221980.0018744244732154544  values: values:  -49.895588  ------57.219242 ----- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  5 target diff:  0.002195307153833348 values:  -44.57766 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0022424286743727303 values:  -49.84931 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0023012201388123805 values:  -57.19499 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0015832946035892748 values:  -44.582176 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017748781074620455 values:  -57.136227 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017888847821395308 values:  -49.804173 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022727948910543183 values:  -44.608437 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018173568276232833 values:  -49.828407 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002148808790637488 values:  -57.017166 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018841384599665187 values:  -44.613747 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002188949031939499 values:  -56.873688 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002743226931197675 values:  -44.649746 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002300812014930222 values:  -49.858025 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018863552337067462 values:  -56.749817 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002465223230117305 values:  -44.647 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 11  target diff: 13  target diff: 0.0019830703487755054  values: 0.002162468961861604 -44.67996 values:   -49.926086-----  ----- \n",
      "\n",
      "\n",
      "\n",
      "-----iteration:  25 target diff:  0.00221302745519596 values:  -56.597244 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018815637667625833 values:  -49.952564 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002111123104753974 values:  -44.703266 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002788785617219236 values:  -56.351864 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002146608223813063 values:  -49.922672 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0024303415301994654 values:  -44.698616 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.003812811582306916 values:  -56.13219 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019150733849125218 values:  -49.894093 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0019455098045106517 values:  -44.662727 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.001986338504777832 values:  -55.97518 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0020246048730231457 values:  -44.70177 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002096605355947894 values:  -49.797455 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00231750890634077 values:  -55.818516 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0017274587352171201 values:  -44.67887 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018864757066477944 values:  -49.663513 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019615727917249837 values:  -49.629578 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 17  target diff:  300.002856674235879809  target diff: values:  0.0019141293883690985 -44.720345  values:  ----- -55.5972\n",
      " \n",
      "----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.00183077328609687 values:  -44.714703 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002329028809652259 values:  -55.39458 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0016878308713179498 values:  -49.565777 ----- \n",
      "\n",
      "-----iteration: -----iteration:  19  32target diff:   target diff: 0.002104755126377313 values:   -44.720890.0019640959354395165 values:  ----- \n",
      " -55.11913 ----- \n",
      "\n",
      "\n",
      "-----iteration:  33 target diff:  0.0023089228386210738 values:  -55.058937 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0025072438594621414 values:  -44.702538 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002167687898969624 values:  -49.481945 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002338473907421288 values:  -54.924446 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0020833532633371373 values:  -44.730053 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019197244121047154 values:  -49.44228 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003175324320643684 values:  -54.676792 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0016560278267025103 values:  -44.760887 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018531616758630618 values:  -49.337025 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0030001585493869775 values:  -54.40774 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.001983436254590792 values:  -44.767277 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0017685768805275877 values:  -44.78242 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.001954425081138893 values:  -49.26672 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0023686262501529773 values:  -54.19629 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.0030265391240863687 values:  -54.00793 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001781524916482411 values:  -44.803017 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0020193464931790414 values:  -53.863224 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0021043840629255683-----iteration:   values:  40-44.845367  target diff: -----  0.002121164123860394\n",
      " values: \n",
      " -----iteration: -53.74519  25-----  target diff:  \n",
      "\n",
      "0.0022730801863200985 values:  -49.080185 ----- \n",
      "\n",
      "-----iteration:  41 target diff:  0.0024734880954241827 values:  -53.551014 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002013954629174972 values:  -44.84877 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018857372206295944 values:  -49.070484 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0018264373939067516 values:  -44.85835 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0018574144107652243 values:  -49.104733 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0023844242113216204 values:  -53.31356 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0029515425697271627 values:  -53.161205 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.00197626045615963 values:  -44.89798 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.001922487389084002 values:  -49.043076 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.002198539880295686 values:  -53.0242 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.002713637939824174 values:  -44.8846 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0026952571336902984 values:  -48.9671 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002838330293191967 values:  -52.88151 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.002796737219366833 values:  -44.898808 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0016869225293392014 values:  -48.974182 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0026883665921090577 values:  -52.72951 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0020859483321841 values: -----iteration:   -48.9439532  target diff: -----  0.0017648857363610302\n",
      " \n",
      "values:  -44.92754 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0023195303930751226 values:  -52.565647 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002080110078564094 values:  -----iteration:  33-48.81602  -----target diff:   \n",
      "0.0018623411132585456 values:  -44.94739\n",
      "-----iteration:  48  ----- \n",
      "\n",
      "target diff:  0.0019941892967252415 values:  -52.50689 ----- \n",
      "\n",
      "-----iteration:  -----iteration: 49  34target diff:  -----iteration:  target diff:  0.0018518987223429307 33 0.0018566431023622173 values:  target diff:   values:  0.001922363085079629-52.35638-44.947887 -----  \n",
      " \n",
      "----- values:  \n",
      "-48.742058\n",
      " ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.001899889601858082 values:  -52.32679 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0019387240155388965 values:  -44.93573 -----iteration:  34-----  \n",
      "target diff: \n",
      " 0.0014455921815021895 values:  -48.680504 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0017791171682837003 values:  -44.892677 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0019866463639182973 values:  -52.22601 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.003143371875146391 values:  -44.967613 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002198534242698644 values:  -52.088634 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.002008896424627642 values:  -51.92036 ----- \n",
      "\n",
      "-----iteration:  54 -----iteration: target diff:   380.0019664394127197585  target diff: values:   -51.853490.00273319271637649  values:  ----- -44.905254\n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0024798381261614756 values:  -44.920773 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002619698120394056 values:  -51.69415 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0020967021134418117 values:  -51.598026 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0018414788287232132 values:  -51.519127 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.0020880567961193406 values:  -44.86138 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  41 target diff:  0.002498087359952075 values:  -44.87737 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.002467376475131347 values:  -51.364525 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0018434436048358537 values:  -44.850754 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9188570846892269 values:  -52.617123 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.002112885514498608 values:  -51.253185 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_45000.ckpt\n",
      "-----iteration:  1 target diff:  0.005007250645303162 values:  -52.531647 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0017675275749320526 values:  -51.11665 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002408786975620001 values:  -44.780678 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  -----iteration: 0.002100711785459714  2values:   -51.003365target diff:   -----0.0035827101283103326  values:  \n",
      "-52.444393 \n",
      "----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0024058696754171087 values:  -44.72488 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0025697939445540933 values:  -52.666393 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0027733463521472388 values:  -50.94813 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002636072160179401 values:  -44.685307 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.003002666724729626 values:  -50.81259 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0021237172552828905 values:  -44.642452 -----iteration:  -----4  \n",
      "target diff:  \n",
      "0.003896126479924552 values:  -52.511707 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0022733804658218826 values:  -50.6173 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0022138037223743646 values:  -44.629604-----iteration:   5-----  target diff:  0.0022658010577587023\n",
      " values: \n",
      " -52.400127 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0031634849898038195 values:  -50.56359 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0015044209362036335 values:  -44.633186 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002336467935343397 values:  -52.176056 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0031767662403382945 values:  -----iteration:  -50.4836249 target diff:   0.0019162734572139386 values:  -44.591858----- ----- \n",
      " \n",
      "\n",
      "\n",
      "-----iteration:  7 target diff:  0.0029010235546681755 values:  -52.143246 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  50 target diff:  0.0018331479169187864 values:  -44.556965 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0028526170721423698 values:  -50.330578 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016620685481206733 values:  -52.242725 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0017008605624674006 values:  -44.50848 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0017318073908011858 values:  -50.20559 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017763120120234284 values:  -52.154236 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.0016147836275051002 values:  -44.55293 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0016874676550377341 values:  -50.152103 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0014702890484494886 values:  -52.071995 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel-----iteration: \n",
      " 70 WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.biastarget diff:  \n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.0.0027003443458409886 values: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      " -49.948795 ----- \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  53 target diff:  0.0022668468993125718 values:  -44.52925Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl! \n",
      "Refresh buffer every 1000000 sampling!\n",
      "----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  71 target diff:  0.002745027138883447 values:  -49.75006 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.0017955079399518742 values:  -44.50483 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0029703007238522346 values:  -49.58232 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.0019920389388839144 values:  -44.4617 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002168297169366218 values:  -49.40049 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.0020620845296962917 values:  -44.419144 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0024080806221530504 values:  -49.19856 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0019311153789790861 values:  -44.34779 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0020933031851982013 values:  -49.119087 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  58 target diff:  0.0022123339669772573 values:  -44.296364 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0026737647529722227 values:  -48.945927 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.0017520456519212824 values:  -44.21104 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.0027890369235948637 values:  -48.780117 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.00201234513785041 values:  -44.132435 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0021984056444037054 values:  -48.575085 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002283666958602851 values:  -44.122242 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0025184227378143623 values:  -48.474846 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0018945596413221062 values:  -44.09153 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0024219654848119947 values:  -48.30023 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0018111741937142424 values:  -44.044144 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.003072085704283371 values:  -48.122646 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  64 target diff:  0.0026048491965056197 values:  -43.984196 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0019124797309594285 values:  -47.915184 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.002488437442115598 values:  -43.931698 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.002210547862319068 values:  -47.79292 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9180258669823989 values:  -49.91246 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0021715480407471423 values:  -47.56424 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0025459989611931115 values:  -43.86908 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004339552728182023 values:  -49.941082 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0023201311907193145 values:  -47.458748 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0017438460522976363 values:  -43.920807 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0023393400077252264 values:  -47.321667 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002590828311569488 values:  -43.86174 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002925519790252176 values:  -49.88663 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0023352735339010533 values:  -47.199947-----iteration:   69-----  \n",
      "target diff:  \n",
      "0.0019135843902520508 values:  -43.77946 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0030152329824833066 values:  -49.77045 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.0015806718325495949 values:  -47.077892 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.00237347719778645 values:  -43.767868 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002401517836284948 values:  -49.6797 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.002039824490207674 values:  -46.942333 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0017089916934671877 values:  -43.81811 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0020671855725813877 values:  -46.835827 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.002172810674384195 values:  -43.863983 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0030070233225230844 values:  -49.664467 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.002104781625317373 values:  -43.90353 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.002011050554736035 values:  -46.755974 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.0021902045270537646 values:  -46.72686 ----- -----iteration: \n",
      " 74\n",
      " target diff:  0.0019289045336084096 values:  -43.966217 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019160025091512186 values:  -49.966526 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0021738712460880605 values:  -44.003212 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.001457637862583429 values:  -46.74134 ----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  7 target diff:  0.004410527651562253 values:  -49.913986 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.001855493826221748 values:  -44.065002 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021889620320380944 values:  -49.818665 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.00232423787574336 values:  -44.113995 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002196604116538656 values:  -49.786514 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0020283677318091247 values:  -44.149647 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0023564184802504135 values:  -49.668663 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0018830823629123214 values:  -44.18242 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0017857137104762817 values:  -44.174538 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001777879339696153 values:  -49.707676 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0021152878030845927 values:  -44.17975 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0019034816349002696 values:  -44.23815 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001855662096893596 values:  -49.54776 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0019940312478170076 values:  -44.27231 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0017117704102182346 values:  -44.270382 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0027322081591295787 values:  -49.4653 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0020266871221825415 values:  -44.263966 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002498711193529705 values:  -49.48092 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0014763523493102086 values:  -44.328613 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  15 target diff:  0.0024016898815051686 values:  -49.326637 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002890842222320644 values:  -49.33921 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0018360631813133543 values:  -49.385624 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0018631630141778817 values:  -49.51945 ----- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  19 target diff:  0.0022236913062542154 values:  -49.5431 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0021564956131825785 values:  -49.553585 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.001848428049953568 values:  -49.575745 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.002138046887912863 values:  -49.624447 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.001808645901254801 values:  -49.572227 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0015842431156242842 values:  -49.5284 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  25 target diff:  0.001704935286738249 values:  -49.45278 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9184355689431493 values:  -44.512894 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0021215592472303394 values:  -49.37463 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003263632176696443 values:  -44.568012 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0014921865127532868 values:  -49.369736 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002909452664882758 values:  -44.561054 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.00274070641370705 values:  -44.497334 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002472702952074574 values:  -44.483364 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002900643013337475 values:  -44.48768 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0026342248846039575 values:  -44.53256 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002530647198569198 values:  -44.44565 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002654900749467099 values:  -44.488934 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  9 target diff:  0.0023518790324241036 values:  -44.498722 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0021666976086543266 values:  -44.452187 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0034260158948283682 values:  -44.484783 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9183528010004651 values:  -50.840164 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.00253337983814678 values:  -44.39329 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030625136796995265 values:  -50.77643 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.003246072207507939 values:  -44.370747 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018448823632680128 values:  -50.7312 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.003213072007621004 values:  -44.32747 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023594963675516076 values:  -50.679848 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018104255718192027 values:  -44.329597 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0016721985944591405 values:  -50.752033 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0029057929276668517 values:  -44.3762 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017566151067562007 values:  -50.73462 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016949135533291435 values:  -50.79116 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002109236299764616 values:  -44.376 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  -----iteration: 0.002011543263067985  7values:   target diff: -44.410446  -----0.0016702824531547352  values: \n",
      " \n",
      "-50.88283 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0035929862929759073 values:  -44.347023 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0018372696574161782 values:  -50.922447 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0020363360138410287 values:  -44.383076 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017072693434749286 values:  -50.90551 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0031498388177997974 values:  -44.36721 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0021522242024965645 values:  -44.223408 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0017152224947407089 values:  -50.988045 ----- \n",
      "\n",
      "-----iteration:  23-----iteration:  target diff:   110.0025849424665380914  target diff: values:   -44.214730.002133507327810124  -----values:   -51.000053\n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002275536651028955 values:  -44.21111 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0022794675342827486 values:  -51.009308 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0025865463774406463 values:  -44.14812 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002030346956033439 values:  -44.120506 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0020496511326500264 values:  -50.991085 ----- \n",
      "-----iteration: \n",
      " 27 target diff:  0.001999050175559112 values:  -44.040436 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.003167457007307631 values:  -44.024364 ----- \n",
      "\n",
      "-----iteration: -----iteration:   2914  target diff:  target diff:  0.00203925218056675430.0029926881627085626  values: values:   -43.98027-50.945885  ---------- \n",
      "\n",
      " \n",
      "\n",
      "-----iteration:  30 target diff:  0.003212028159182489 values:  -43.993374 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0028997295400228487 values:  -50.884647 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002295595738716976 values:  -50.88764 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0018034030625406637 values:  -43.935497 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002228466851686768 values:  -50.96554 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.003591190010300681 values:  -43.91011 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0019268836564408235 values:  -50.84176 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.002478063860563148 values:  -43.949196 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0018899837007954274 values:  -50.914955 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0019414071287028837 values:  -50.90343 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0024697215412355414 values:  -43.884167 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0017191867623775688 values:  -50.856915 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0023141796231714988 values:  -43.89767 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0019310744048414976 values:  -43.86687 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.001821219640933606 values:  -50.789223 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0016871716522617226 values:  -50.786026 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0019226364384701093 values:  -43.77938 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0016354489252424478 values:  -50.73412 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.00226583820932429 values:  -43.646732 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0020447279134846873 values:  -50.71297 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0014682015706727603 values:  -50.72292 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  39 target diff:  0.0035490755496437303 values:  WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "-43.674076 \n",
      "----- \n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/ckpt/offline_rem_50000.ckpt\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  40 target diff:  0.002571998131863198 values:  -43.631927 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  41 target diff:  0.002486169841856057 values:  -43.575405 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.00245381251920962 values:  -43.479736 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.002845409587084977 values:  -43.421963 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.0021254024574301595 values:  -43.373432 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  45 target diff:  0.0022408212354798978 values:  -43.31021 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9185786202862152 values:  -50.71208 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004125305244194595 values:  -50.76609 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0029178632111006935 -----iteration: values:   2-43.18474  ----- target diff: \n",
      " \n",
      "0.003026266281502046 values:  -50.77306 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002101316123102971 values:  -50.868362 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.003083618863087513 values:  -43.10795 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002240780397482813 values:  -51.053825 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0023486504699343517 values:  -43.016876 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002622545733326696 values:  -50.984993 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.002163863193634847 values:  -43.069336 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017171664000143361 values:  -50.963253 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0028170906062195953 values:  -42.992672 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0023932893212882927 values:  -43.04471 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019077882670249268 values:  -50.96339 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002034554850504456 values:  -51.043007 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002745644869637005 values:  -42.96268 ----- \n",
      "\n",
      "-----iteration: -----iteration:   539  target diff: target diff:   0.00201353168091734530.0024511454654125133  values: values:  -50.9357 -42.88605 ----- \n",
      "\n",
      " ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002248963839989547 values:  -50.983635 ----- \n",
      "\n",
      "-----iteration:  54 target diff:  0.002321640221382163 values:  -42.823967 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001800843291469074 values:  -51.09989 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0019830278779983256 values:  -51.180798 ----- \n",
      "\n",
      "-----iteration:  55 target diff:  0.002237113211455852 values:  -42.766705 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0018673853925745402 values:  -51.13993 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.002392627639970117 values:  -42.69931 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.002075502592607533 values:  -42.73365 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0022604538116712115 values:  -51.13583 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0022879726948426245 values:  -42.68185 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0017271100044825415 values:  -51.13523 ----- \n",
      "\n",
      "-----iteration:  59 target diff:  0.00186861263250651 values:  -42.646576 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.0024197355410064732 -----iteration: values:  16  -42.582157 target diff:  ----- 0.0015358133795742275\n",
      " \n",
      "values:  -50.99925 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.002285382021550251 values:  -42.543194 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002291766181581846 values:  -50.9495 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.002672845668602536 values:  -42.48813 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0025530641934708937 values:  -50.84326 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0020868274763674033 values:  -42.464348 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0019863132312500655 values:  -42.50258 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002578474476424282 values:  -50.798275 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.0020178863551515752 values:  -42.438175 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002835659868541532 values:  -50.780575 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.0018959922951472983 values:  -42.450855 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0024360952492888982 values:  -50.726322 ----- \n",
      "\n",
      "-----iteration:  67 target diff:  0.0020742863721287495 values:  -42.49512 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.0021319178475009567 values:  -42.438644 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0016524244243870643 values:  -50.82173 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0019107841598030705 values:  -42.46892 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0023696385481958124 values:  -50.853302 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.001967363548788208 values:  -42.39546 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0016211512470606592 values:  -50.861443 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.0019928618089132735 values:  -42.417786 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.001788173134930307 values:  -50.874306 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0021676431228209773 values: -----iteration:   -42.430077 26 -----target diff:   \n",
      "0.0017566902566162532\n",
      " values:  -50.896584 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0021390041342427995 values:  -42.438614 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001803666314452372 values:  -50.878326 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0021360604281146596 values:  -42.455624 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002254358752466653 values:  -50.83621 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.0020957583284908284 values:  -42.4618 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0015627812963515126 values:  -50.83284 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0019766418274526965 values:  -42.41541 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0017190145672115965 values:  -50.754986 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002064233985975659 values:  -42.44809 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0014682720721749811 values:  -50.75553 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0021071163563957506 values:  -42.458168 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.001978285453895792 values:  -42.408203 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0025758891929072913 values:  -42.37582 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.0018098484581301204 values:  -42.345085 ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.0025465945345943563 values:  -42.33944 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0017903554689474787 values:  -42.370342 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  84 target diff:  0.0022407655771956854 values:  -42.338306 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9169246451919694 values:  -49.751385 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0019521155803491935 values:  -42.308098 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0021806553022023375 values:  -49.721603 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0022016513019023857 values:  -42.27477 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019932011077724 values:  -49.78238 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0017650163306672131 values:  -42.266357 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016359356755358601 values:  -49.793858 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.002246623955040305 values:  -42.230896 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002235097932120133 values:  -49.90623 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0018975602018970466 values:  -42.223602 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.001673055891221823 values:  -42.250813 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022306861619784883 values:  -49.827805 ----- \n",
      "\n",
      "-----iteration:  6 target diff: -----iteration:   0.00171674562321289391  target diff: values:  -49.821045  -----0.00225015514683997 \n",
      " \n",
      "values:  -42.228355 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.002238302370891417 values:  -42.241745 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0019495945761816489 values:  -49.772842 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0020386540632554725-----iteration:   values: 8  target diff: -42.24024  0.0016901993290755351 -----values:   \n",
      "\n",
      "-49.782394 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0020846915303357476 values:  -42.235035 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001626978958816698 values:  -49.770966 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.002072654592779773 values:  -42.227165 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015611781343699471 values:  -49.65851 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.00203775630571083 values:  -42.21866 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0019958375382381492 values:  -42.20222 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0019525341987859613 values:  -42.17211 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0019246548940362943 values:  -42.15542 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018282280727846538 values:  -49.54729 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023770745491220277 values:  -49.538883 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002090080800363309 values:  -49.42865 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0026338727155226466 values:  -49.480824 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "0.0020123050242050887\n",
      " values:  -49.432556 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019259610492668464 values:  -49.44352 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9173412485202622 values:  -45.698376 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001909627250230266 values:  -49.464874 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002463913861565861 values:  -45.657257 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0017914489935672941 values:  -49.314896 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0019560185347514123 values:  -49.26665-----iteration:  ----- \n",
      " \n",
      "2 target diff:  0.0017112052566861898 values:  -45.599285 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0019905506977193144 values:  -49.294624 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0028007977309948183 values:  -45.6112 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0026763691126661135 values:  -49.347904 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0028055215549838124 values:  -45.595398 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  5 target diff:  0.0016068678036788302 values:  -45.575348 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0022294439582513405 values:  -45.558777 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022716741999471816 values:  -45.538467 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0019821805171741503 values:  -49.285095 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0016425034754760579 values:  -45.54338 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0019725038058305915 values:  -49.38971 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016679047537835525 values:  -45.53196 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0025764228531588223 values:  -49.437645 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018595128158043447 values:  -45.500946 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019177584776418415 values:  -45.494133 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0020396631701221765 values:  -49.370777 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_5000.ckpt\n",
      "-----iteration:  12 target diff:  0.00205301144570936 values:  -45.448803 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0017682325374249108 values:  -49.307228 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0026157254903643973 values:  -45.337486 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0016128344915408226 values:  -49.285667 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0018031276633948031 values:  -45.35606 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0013538272775980118 values:  -49.253063 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "-----iteration:  15 target diff:  0.0018664999739345422 Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!values: \n",
      " Refresh buffer every 1000000 sampling!-45.3382 \n",
      "----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  16 target diff:  0.0017825082384202277 values:  -45.333702 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001737026007053692 values:  -45.3386 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  18 target diff:  0.0025421721370583418 values:  -45.34018 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.00190703395175897 values:  -45.315826 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0016450032176855633 values:  -45.265404 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0018218760415123208 values:  -45.164116 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0025024481538643163 values:  -45.2178 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0018472461460244671 values:  -45.230576 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0019409238484594433 values:  -45.26812 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  25 target diff:  0.001821567659366877 values:  -45.267616 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9188281798454466 values:  -50.811657 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0018531824145188078 values:  -45.266655 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0040666170613404 values:  -50.775394 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0025245230205161364 values:  -50.860844 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0017572348298564185 values:  -45.269726 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002970588990873433 values:  -50.892532 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019416320868544505 values:  -50.86019 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0022497599513428288 values:  -50.873844 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0025691794519885395 values:  -45.274025 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002095301797092471 values:  -50.860493 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0036811776396121804 values:  -45.216625 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0021479651692689786 values:  -50.929066 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001641338270265321 values:  -50.947834 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0017449996338751057 values:  -45.1746 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0021640651431143855 values:  -45.053738 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.001838682900219894 values:  -50.743397 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0021758559505293115 values:  -45.00363 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002232532180591621 values:  -50.78412 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.001626736590998213 values:  -50.745518 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0018258659425509649 values:  -44.957306 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.002371198229936561 values:  -44.91797 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0014893870301927504 values:  -50.628452 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0016701406103108976 values:  -44.904797 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0036332112826600142 values:  -44.87789 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.0012553034605180182 values:  -44.865505 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/932136058/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9179369526124148 values:  -50.441113 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0028704644929541134 values:  -50.404167 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019891471312051164 values:  -50.36422 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016618245742693058 values:  -50.38051 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001807907911276976 values:  -50.304638 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0017863335370204955 values:  -50.212452 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  6 target diff:  0.0016977436503464887 values:  -50.205048 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0016905817858952823 values:  -50.20685 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9179632558653577 values:  -45.566387 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020553319907927765 values:  -50.19497 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002649557694956537 values:  -45.557316 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0015389483410366996 values:  -50.14417 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0022954133100559085 values:  -50.08369 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0028366732534206617 values:  -45.500835 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0015383796337502943 values:  -49.9933 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002702701536346085 values:  -45.508102 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0013912069859312141 values:  -49.995018 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel-----iteration: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias 4\n",
      " WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kerneltarget diff: \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias 0.0028294679093185783\n",
      " values: WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel \n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "-45.45526 -----WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details. \n",
      "\n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  5 target diff:  0.0026109429897401577 values:  -45.44623 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0024847330408160327 values:  -45.428177 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002108503278604446 values:  -45.45329 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  8 target diff:  0.0023037032306972164 values:  -45.35414 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002962677970035422 values:  -45.344864 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001828368269546323 values:  -45.354836 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0017774769370464058 values:  -45.38966 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0018351885182485538 values:  -45.42233 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002039113014409081 values:  -45.454914 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  14 target diff:  0.0021089955792034493 values:  -45.394882 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9180646610333141 values:  -52.76894 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0019473672367833139 values:  -45.38489 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.004144751236992166 values:  -52.991436 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0019684696616373387 values:  -45.36198 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0033682228599759977 values:  -52.95423 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.003353483251281425 values:  -52.783092 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002431428594125095 values:  -45.376377 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002703141860631038 values:  -52.71696 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  5 target diff:  0.0018414387147277428 values:  -52.65041 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0023520837900828 values:  -45.365047 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020255429089471857 values:  -52.51513 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002049720625714031 values:  -52.451725 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002284060942953498 values:  -52.422375 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0023125549259693837 values:  -45.355865 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0019655651022309475 values:  -52.445637 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.002558472720403982 values:  -52.300453 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002248076526810339 values:  -45.37102 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0016706688124125155 values:  -52.277714 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001673456595323093 values:  -52.365658 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002407078821087666 values:  -45.324173 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001882686315432732 values:  -52.34611 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0015764968153861012 values:  -52.354767 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0027461432684405683 values:  -45.246105 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.001968878016345723 values:  -52.30053 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016699777907231337 values:  -52.28942 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0024702804014077795 values:  -45.24364 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.001624494980435742 values:  -52.3612 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002185820191533691 values:  -45.236546 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0020659760460130213 values:  -52.35647 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0023281339885891676 values:  -45.1463 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0018106117748566202 values:  -52.451363 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002904257167918353 values:  -45.118534 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.002130913581597427 values:  -45.08311 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.0018722358175931805 values:  -52.421043 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002578120259705114 values:  -45.079018 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.002425840786817546 values:  -52.482964 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0018033063804440822 values:  -45.063675 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0024290484539429627 values:  -52.538597 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0027410158609425567 values:  -45.00347 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_10000.ckpt\n",
      "-----iteration:  23 target diff:  0.002937471862869108 values:  -52.486664 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.00214308271213892 values:  -45.15942 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002849721375198842 values:  -52.525616 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.002854579959777202 values:  -52.349415 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.005018747095488262 values:  -45.15022 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0023472402342521507 values:  -52.258553 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0022811204699405147 values:  -45.10641 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.0028008985324765464 values:  -52.20202 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0028171011925756015 values:  -44.934864 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.001858737689821379 values:  -52.101418 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0020800137525588992 values:  -52.135635 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.003072376850163288 values:  -44.812992 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0018739691203848564 values:  -52.242424 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0020151134973610783 values:  -52.20923 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0024246592474068225 values:  -44.705647 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.0016652519533959624 values:  -52.176765 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.00262732240785665 values:  -44.675976 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0019184496138103613 values:  -52.07242 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.002297938311652528 values:  -44.617992 ----- \n",
      "\n",
      "-----iteration:  34 target diff:  0.0020560249377640305 values:  -51.98674 ----- \n",
      "\n",
      "-----iteration:  35 target diff:  0.0022391881934196857 values:  -51.85118 ----- \n",
      "\n",
      "-----iteration:  36 target diff:  0.0026542183029846416 values:  -51.777943 ----- \n",
      "\n",
      "-----iteration:  39 target diff:  0.0020636997477550714 values:  -44.440685 ----- \n",
      "\n",
      "-----iteration:  37 target diff:  0.001851534352819773 values:  -51.72515 ----- \n",
      "\n",
      "-----iteration:  40 target diff:  0.003708332728967067 values:  -44.429695 ----- \n",
      "\n",
      "-----iteration:  38 target diff:  0.001660883851829357 values:  -51.72974 ----- \n",
      "\n",
      "-----iteration:  39 -----iteration: target diff:   410.0017939871627685572  values: target diff:   -51.6146430.002403155916566965 -----  values:  \n",
      "\n",
      "-44.315475 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.00304986509139525 -----iteration: values:   40-44.339252  target diff: ----- \n",
      "\n",
      " 0.0017680852425415695 values:  -51.47083 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0026033740087808427 values:  -44.37392 ----- \n",
      "-----iteration: \n",
      " 41 target diff:  0.002153911481301751 values:  -51.480907 ----- \n",
      "\n",
      "-----iteration:  42 target diff:  0.0019148064586314683 values:  -51.423504 ----- \n",
      "\n",
      "-----iteration:  44 target diff:  0.003105305418983762 values:  -44.392452 ----- \n",
      "\n",
      "-----iteration:  43 target diff:  0.0013575594668485528 values:  -51.310863 ----- \n",
      "\n",
      "-----iteration:  45 target diff:  0.002923278668702188 values:  -44.39683 ----- \n",
      "\n",
      "-----iteration:  46 target diff:  0.0023249939050460954 values:  -44.389496 ----- \n",
      "\n",
      "-----iteration:  47 target diff:  0.0019898978871907727 values:  -44.402397 ----- \n",
      "\n",
      "-----iteration:  48 target diff:  0.0023340945906215405 values:  -44.328064 ----- \n",
      "\n",
      "-----iteration:  49 target diff:  0.0020111492694822974 values:  -44.253044 ----- \n",
      "\n",
      "-----iteration:  50 target diff:  0.0017825068469503648 values:  -44.191235 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9180988694140544 values:  -51.46669 ----- \n",
      "\n",
      "-----iteration:  51 target diff:  0.0026115242259618174 values:  -44.113503 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002540740519036411 values:  -51.489456 ----- \n",
      "\n",
      "-----iteration:  52 target diff:  0.002239517229450639 values:  -44.04284 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.00188587031836184 values:  -51.403088 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021974135840052023 values:  -51.43219 ----- \n",
      "\n",
      "-----iteration:  53 target diff:  0.001684855651621156 values:  -43.96347 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002417711685820276 values:  -51.312553 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0013938165687596695 values:  -51.304626 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  54 target diff:  0.002757730401088915 values:  -43.865456 ----- \n",
      "\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/218175338/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- adv learner --------------------\n",
      "-----iteration:  55 target diff:  0.002807473533316449 values:  -43.83603 ----- \n",
      "\n",
      "-----iteration:  56 target diff:  0.002480857928452095 values:  -43.818398 ----- \n",
      "\n",
      "-----iteration:  57 target diff:  0.0024435148521229438 values:  -43.796364 ----- \n",
      "\n",
      "-----iteration:  58 target diff:  0.0024797165405292415 values:  -43.7745 ----- \n",
      "\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  59 target diff:  0.0024977810550872856 values:  -43.752872 ----- \n",
      "\n",
      "-----iteration:  60 target diff:  0.002548860205246454 values:  -43.706924 ----- \n",
      "\n",
      "-----iteration:  61 target diff:  0.0024298532881604578 values:  -43.652153 ----- \n",
      "\n",
      "-----iteration:  62 target diff:  0.0023765563328416706 values:  -43.536194 ----- \n",
      "\n",
      "-----iteration:  63 target diff:  0.0019364499530144744 values:  -43.44413 ----- \n",
      "\n",
      "-----iteration:  64 target diff:  0.0017164710609022047 values:  -43.366364 ----- \n",
      "\n",
      "-----iteration:  65 target diff:  0.001853105762692365 values:  -43.287605 ----- \n",
      "\n",
      "-----iteration:  66 target diff:  0.002012496682910072 values:  -43.221752 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  67 target diff:  0.0019028063372089799 values:  -43.227375 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9175292395000951 values:  -49.8874 ----- \n",
      "\n",
      "-----iteration:  68 target diff:  0.002770232207197898 values:  -43.154354 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003387206040669428 values:  -49.909676 ----- \n",
      "\n",
      "-----iteration:  69 target diff:  0.0019496456037916483 values:  -43.100857 ----- \n",
      "\n",
      "-----iteration:  70 target diff:  0.0023011821956546346 values:  -43.034603 ----- \n",
      "\n",
      "-----iteration:  71 target diff:  0.002159134366605149 values:  -42.984013 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.003469248097730261 values:  -49.881367 ----- \n",
      "\n",
      "-----iteration:  72 target diff:  0.0025974486725796222 values:  -43.003967 ----- \n",
      "\n",
      "-----iteration:  73 target diff:  0.0032392625904810964 values:  -42.952103 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0021803419899864176 values:  -49.784306 ----- \n",
      "\n",
      "-----iteration:  74 target diff:  0.0019850659969325936 values:  -42.9272 ----- \n",
      "\n",
      "-----iteration:  75 target diff:  0.002046988704795338 values:  -42.9527 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0019780090870547737 values:  -49.69181 ----- \n",
      "\n",
      "-----iteration:  76 target diff:  0.0024790154308233416 values:  -42.93015 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018043252824463418 values:  -49.776974 ----- \n",
      "\n",
      "-----iteration:  77 target diff:  0.002207152367850683 values:  -42.920483 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0018290104518305528 values:  -49.80831 ----- \n",
      "\n",
      "-----iteration:  78 target diff:  0.0017505679828936345 values:  -42.90758 ----- \n",
      "\n",
      "-----iteration:  79 target diff:  0.0020090014192876544 values:  -42.94881 ----- \n",
      "\n",
      "-----iteration:  80 target diff:  0.0025144614131179777 values:  -42.92303 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002126919658806242 values:  -49.787174 ----- \n",
      "\n",
      "-----iteration:  81 target diff:  0.002028349280122022 -----iteration:  8 values: target diff:  -42.907307  ----- \n",
      "0.0016811602290443056 values:  -49.69679\n",
      " ----- \n",
      "\n",
      "-----iteration:  82 target diff:  0.001933474780306046 values:  -42.952118 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.00196468505300142 values:  -49.59926 ----- \n",
      "\n",
      "-----iteration:  83 target diff:  0.0025610864535476584 values:  -42.904243 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001971967627198111 values:  -49.62652 ----- \n",
      "\n",
      "-----iteration:  84 target diff:  0.0019152683823502785 values:  -42.903923 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0019262605469146596 values:  -49.77906 ----- \n",
      "\n",
      "-----iteration:  85 target diff:  0.0017882664797610939 values:  -42.862682 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0037500505428391105 values:  -49.781647 ----- \n",
      "\n",
      "-----iteration:  86 target diff:  0.0016527735582281945 values:  -42.883953 ----- \n",
      "\n",
      "-----iteration:  87 target diff:  0.0016010284362233376 values:  -42.965446 ----- \n",
      "\n",
      "-----iteration:  88 target diff:  0.002598274701826796 values:  -42.943783 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.0016857342658050888 values:  -49.559494 ----- \n",
      "\n",
      "-----iteration:  89 target diff:  0.0018123444927465747 values:  -42.968937 ----- \n",
      "\n",
      "-----iteration:  90 target diff:  0.0016264131347495535 values:  -42.961025 ----- \n",
      "\n",
      "-----iteration:  91 target diff:  0.0016733380833424943 values:  -42.99418 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0030873548533125964 values:  -49.582214 ----- \n",
      "\n",
      "-----iteration:  92 target diff:  0.00178338984031574 values:  -42.99839 ----- \n",
      "\n",
      "-----iteration:  93 target diff:  0.0017752235077517808 values:  -42.971725 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002649996542991976 values:  -49.399723 ----- \n",
      "\n",
      "-----iteration:  94 target diff:  0.0018293917739133797 values:  -43.02312 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.002852322626576794 values:  -49.35048 ----- \n",
      "\n",
      "-----iteration:  95 target diff:  0.0017794047893679053 values:  -43.032288 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0023824045137264293 values:  -49.35452 ----- \n",
      "\n",
      "-----iteration:  96 target diff:  0.0017998811827781758 values:  -43.001583 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0022900762505706643 values:  -49.32512 ----- \n",
      "\n",
      "-----iteration:  97 target diff:  0.0018735958344293711 values:  -42.96299 ----- \n",
      "\n",
      "-----iteration:  98 target diff:  0.0017995719562325537 values:  -42.92757 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.0016026166616047628 values:  -49.195045 ----- \n",
      "\n",
      "-----iteration:  99 target diff:  0.0018173414710609419 values:  -42.882668 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002761760923869971 values:  -49.16956 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0016205054118439567 values:  -49.124477 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.0016018434834650253 values:  -49.06005 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.0015773427523051741 values:  -49.01606 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.001309386920645618 values:  -48.967155 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9187879009089703 values:  -46.924923 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0030724334269133214 values:  -46.974537 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  2 target diff:  0.001923584370026058 values:  -47.000244 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002065543411391374 values:  -47.05654 ----- \n",
      "\n",
      "-----iteration:  0 target diff:  0.9168094746981822 values:  -50.496437 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002217313866672738 values:  -47.009174 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0023176516778875772 values:  -50.37056 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0029199925217449746 values:  -47.059998 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002315199539288218 values:  -50.231953 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0021209634449123695 values:  -47.09861 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0026428935053958674 values:  -50.192535 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018207629390681345 values: -----iteration:   -50.178566 7 target diff:  -----0.0020481565123704414 values:   \n",
      "\n",
      "-47.107956 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  -----iteration: 0.0016470589925081701  8values:   -50.192173target diff:   ----- \n",
      "0.0028215446498241433 values: \n",
      " -47.10933 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017198242216436889 values:  -50.193546 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.002114636356413302 values:  -47.116734 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017726385851067291 values:  -50.26481 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0015364775037269066 values:  -47.160374 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.001844879293698033 values:  -50.297806 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.002631319190056692 values:  -47.188446 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0016595754321087597 values:  -50.3575 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0018643915211190149 values:  -50.40023 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0029372956472900036 values:  -47.23589 ----- \n",
      "\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_15000.ckpt\n",
      "-----iteration:  11 target diff:  0.0023610249447533938 values:  -50.41027 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.001807604575771622 values:  -50.425724 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.001476231074224454 values:  -50.42747 ----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "-----iteration:  13 target diff:  0.0023235933744464514 values:  -47.289932 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0029844621518543397 values:  -47.32381 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.002521070436711556 values:  -47.318954 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0029249783845947852 values:  -47.29666 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0023766475367620627 values:  -47.35736 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.0021492805662813104 values:  -47.380745 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.002188828293933308 values:  -47.405457 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002474904671695395 values:  -47.404552 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0021954961884904775 values:  -47.56372 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.005627835365137272 values:  -47.557186 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.002532847479649878 values:  -47.611492 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.002553707517186009 values:  -47.666965 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0024890610539490894 values:  -47.58866 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.0028925390730692724 values:  -47.584007 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001981952281768193 values:  -47.633663 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.002332799528560634 values:  -47.570286 ----- \n",
      "\n",
      "-----iteration:  29 target diff:  0.0019631400222712594 values:  -47.630295 ----- \n",
      "\n",
      "-----iteration:  30 target diff:  0.0023155491157831917 values:  -47.600048 ----- \n",
      "\n",
      "-----iteration:  31 target diff:  0.0019660966033854857 values:  -47.65854 ----- \n",
      "\n",
      "-----iteration:  32 target diff:  0.002362535895552806 values:  -47.649586 ----- \n",
      "\n",
      "-----iteration:  33 target diff:  0.0014225270178227505 values:  -47.68546 ----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_20000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_25000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_30000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_35000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_40000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_45000.ckpt\n",
      "saving model weights at /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/ckpt/offline_rem_50000.ckpt\n",
      "-------------------- behavior cloning --------------------\n",
      "-------------------- ckpt:  5000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9190505416495066 values:  -57.05799 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0015850566099525451 values:  -57.0047 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0010677743676839903 values:  -56.968636 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9196553606354723 values:  -56.86764 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0014121548562766272 values:  -56.949753 ----- \n",
      "\n",
      "-------------------- ckpt:  10000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.91910896694736 values:  -58.736443 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0025770388667984683 values:  -58.70233 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0011739658729294732 values:  -58.721004 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9195531741022008 values:  -57.334023 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0027369223047348026 values:  -57.28928 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0013652248868085204 values:  -57.265778 ----- \n",
      "\n",
      "-------------------- ckpt:  15000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9193106617572596 values:  -58.27144 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.002888591059169062 values:  -58.282715 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018582072049485832 values:  -58.42883 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.002405382991651946 values:  -58.408527 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.00207826874066633 values:  -58.385582 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001225477766890077 values:  -58.392925 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.918848236530385 values:  -57.137794 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0016234476831787326 values:  -57.107964 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018009723992599958 values:  -57.138783 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017579354730443838 values:  -57.19764 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0014215681050802104 values:  -57.163097 ----- \n",
      "\n",
      "-------------------- ckpt:  20000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9199999293419409 values:  -58.00414 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0035020753140127285 values:  -58.050793 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0021734060428332115 values:  -58.055275 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017693747309145407 values:  -58.05235 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.001922980763858541 values:  -58.08325 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016417131027098237 values:  -58.026737 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0020234872574745326 values:  -58.03203 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022941360147637328 values:  -57.975494 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002337492684563241 values:  -57.998566 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0024777032654173152 values:  -57.86912 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0025622137069537657 values:  -57.856228 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018032548410917913 values:  -57.790527 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.002100182307932308 values:  -57.746033 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002170508296975215 values:  -57.780632 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.0022128239453020984 values:  -57.88617 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  15 target diff:  0.002482471598384945 values:  -57.799534 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0020318823619156928 values:  -57.815666 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.0014993053262180353 values:  -57.748936 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9195496440323171 values:  -58.04486 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0032323900947556572 values:  -57.986176 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0017171736329555855 values:  -57.967453 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016914692691634638 values:  -57.939297 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0023026936257365886 values:  -57.953533 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.002084118731212956 values:  -57.920475 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0017470896962850303 values:  -57.97429 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0022268819485743887 values:  -57.913055 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0021109645728372897 values:  -57.871197 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0026824217846223753 values:  -57.87894 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019423041314258732 values:  -57.72554 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0023133042120431243 values:  -57.573467 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0023548394902350167 values:  -57.596844 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002194834614071615 values:  -57.42893 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.002299955189161246 values:  -57.362434 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0018150227170430696 values:  -57.316563 ----- \n",
      "\n",
      "-----iteration:  16 target diff:  0.0016220840013859894 values:  -57.28751 ----- \n",
      "\n",
      "-----iteration:  17 target diff:  0.002065626750526796 values:  -57.274197 ----- \n",
      "\n",
      "-----iteration:  18 target diff:  0.001967192672779521 values:  -57.24287 ----- \n",
      "\n",
      "-----iteration:  19 target diff:  0.001593789759025581 values:  -57.338135 ----- \n",
      "\n",
      "-----iteration:  20 target diff:  0.002541059182821938 values:  -57.285645 ----- \n",
      "\n",
      "-----iteration:  21 target diff:  0.0016681452024405645 values:  -57.315502 ----- \n",
      "\n",
      "-----iteration:  22 target diff:  0.00224325011866085 values:  -57.346684 ----- \n",
      "\n",
      "-----iteration:  23 target diff:  0.001584593524148198 values:  -57.22439 ----- \n",
      "\n",
      "-----iteration:  24 target diff:  0.0018043674242454101 values:  -57.08373 ----- \n",
      "\n",
      "-----iteration:  25 target diff:  0.0017698974823606274 values:  -56.85934 ----- \n",
      "\n",
      "-----iteration:  26 target diff:  0.002217088905847443 values:  -56.79127 ----- \n",
      "\n",
      "-----iteration:  27 target diff:  0.001614108008272382 values:  -56.69064 ----- \n",
      "\n",
      "-----iteration:  28 target diff:  0.0013807204846238636 values:  -56.500294 ----- \n",
      "\n",
      "-------------------- ckpt:  25000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9195636972946442 values:  -57.994408 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003128822167465292 values:  -57.884056 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018299454666655351 values:  -57.795143 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017606188785072483 values:  -57.679817 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018880087330530584 values:  -57.59654 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0023566830060359114 values:  -57.565277 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002508191272294954 values:  -57.549538 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.001998545348905551 values:  -57.54409 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.002099717696530227 values:  -57.47632 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0025531591860779614 values:  -57.383762 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0019309506243989406 values:  -57.36189 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0018706746519443142 values:  -57.47483 ----- \n",
      "\n",
      "-----iteration:  12 target diff:  0.0031899263866373914 values:  -57.47208 ----- \n",
      "\n",
      "-----iteration:  13 target diff:  0.002566349800443113 values:  -57.44561 ----- \n",
      "\n",
      "-----iteration:  14 target diff:  0.00234926517585019 values:  -57.43709 ----- \n",
      "\n",
      "-----iteration:  15 target diff:  0.0014928105876033466 values:  -57.288692 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----iteration:  0 target diff:  0.9196856783823851 values:  -57.92263 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0020236496047556117 values:  -57.921356 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0021210289614338584 values:  -57.86317 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001660571166152779 values:  -57.895428 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002221436751904834 values:  -57.871372 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0010958983995156741 values:  -57.945156 ----- \n",
      "\n",
      "-------------------- ckpt:  30000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9193366450148055 values:  -57.02175 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0039006492463582354 values:  -56.94369 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0022936453595173434 values:  -56.879482 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001984984927430256 values:  -56.86075 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.002182849835765843 values:  -56.790283 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.001992932628142433 values:  -56.803783 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0019932808488071106 values:  -56.727245 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.002107427514795277 values:  -56.729164 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020422797170066985 values:  -56.67267 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0021148823353418747 values:  -56.716553 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013785228212643337 values:  -56.662136 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9202710556267586 values:  -56.952557 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0018687658314654465 values:  -56.959072 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0019313426082946585 values:  -56.973297 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0013734819139437447 values:  -56.959908 ----- \n",
      "\n",
      "-------------------- ckpt:  35000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9198017291113545 values:  -57.66378 ----- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----iteration:  1 target diff:  0.0025501036534178964 values:  -57.66332 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018831396603604016 values:  -57.65239 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.001682912753513148 values:  -57.67416 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0022668398145761688 values:  -57.708843 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0021345518500047065 values:  -57.664574 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.0016894599587736821 values:  -57.671043 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0017416339519316067 values:  -57.748318 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0024643165447361475 values:  -57.774826 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0018990551717713172 values:  -57.708 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.001639268971391225 values:  -57.73864 ----- \n",
      "\n",
      "-----iteration:  11 target diff:  0.0013949363925541058 values:  -57.722897 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9196324849116817 values:  -57.825005 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0019529443937758369 values:  -57.798046 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0014645127416348309 values:  -57.792126 ----- \n",
      "\n",
      "-------------------- ckpt:  40000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.919555714554086 values:  -58.33419 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.003653632254773446 values:  -58.348263 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001823425461209183 values:  -58.39653 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0016345500668616484 values:  -58.362877 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0016796818017578642 values:  -58.31987 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0018211689459084253 values:  -58.309944 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002104536477559824 values:  -58.272205 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0014159949118798848 values:  -58.33185 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9194018222100635 values:  -57.69094 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0024579301190556626 values:  -57.71001 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.001993916170433569 values:  -57.54863 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017509994903760087 values:  -57.65468 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0018794691551881812 values:  -57.58071 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0012533983666695577 values:  -57.50878 ----- \n",
      "\n",
      "-------------------- ckpt:  45000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9185546271277591 values:  -57.30308 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0032673995682701495 values:  -57.263077 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.002402238392551516 values:  -57.274136 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0017338449493529337 values:  -57.235252 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017427303728142353 values:  -57.20309 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0020569673183454926 values:  -57.087097 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.002029467761946228 values:  -57.115597 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0015693553059838343 values:  -56.954952 ----- \n",
      "\n",
      "-----iteration:  8 target diff:  0.0020686445798347853 values:  -56.874954 ----- \n",
      "\n",
      "-----iteration:  9 target diff:  0.0017045516351958281 values:  -56.867138 ----- \n",
      "\n",
      "-----iteration:  10 target diff:  0.0013868649480419128 values:  -56.853992 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.919541087729158 values:  -58.112637 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0034809911895553164 values:  -58.07153 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0018706907296911141 values:  -57.961082 ----- \n",
      "\n",
      "-----iteration:  3 target diff:  0.0023376788344768563 values:  -57.944088 ----- \n",
      "\n",
      "-----iteration:  4 target diff:  0.0017147882662457163 values:  -57.937183 ----- \n",
      "\n",
      "-----iteration:  5 target diff:  0.0016253829598604972 values:  -57.91621 ----- \n",
      "\n",
      "-----iteration:  6 target diff:  0.001556380988700217 values:  -57.944668 ----- \n",
      "\n",
      "-----iteration:  7 target diff:  0.0012411747580715392 values:  -57.859825 ----- \n",
      "\n",
      "-------------------- ckpt:  50000 --------------------\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent/trajs.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent0/trajs0.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent1/trajs1.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent2/trajs2.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent3/trajs3.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "Loaded trajectories from load path: /home/jupyt/leyuan/SUPRL/data/mh/rem/tmp/717354021/fold4/train/agent4/trajs4.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-------------------- adv learner --------------------\n",
      "-------------------- fqe on dqn & sale --------------------\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Layer multi_head_dqn_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9192249674066463 values:  -57.703705 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.001876495715749949 values:  -57.701164 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0013070474550382432 values:  -57.67871 ----- \n",
      "\n",
      "WARNING:tensorflow:Layer mlp_network is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "-----iteration:  0 target diff:  0.9195213097254819 values:  -55.795376 ----- \n",
      "\n",
      "-----iteration:  1 target diff:  0.0022849760215415244 values:  -55.808815 ----- \n",
      "\n",
      "-----iteration:  2 target diff:  0.0014198060932650632 values:  -55.80019 ----- \n",
      "\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).dense_layers.2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "save_path = './data/mh/rem/'\n",
    "pool = mp.Pool(5)\n",
    "rets = pool.map(one_step, range(5))\n",
    "pool.close()\n",
    "\n",
    "with open(save_path + 'rets_rem_mh.pkl', 'wb') as f:\n",
    "    pickle.dump(rets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
