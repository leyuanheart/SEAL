{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('.')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peal.utils.epsilon_decay import linearly_decaying_epsilon\n",
    "from peal.agents.default_config import DEFAULT_CONFIG as config\n",
    "from peal.agents.dqn import DQNAgent\n",
    "from peal.agents.qr_dqn import QuantileAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online QR-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/Prophet/sluo/software/anaconda3/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save buffer every 500 episodes!\n",
      "------------------------------------------------\n",
      "episodes 15\n",
      "timestep 1000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000500\n",
      "mean reward (100 episodes) -587.876869\n",
      "max reward (100 episodes) -369.109733\n",
      "mean step (100 episodes) 68.600000\n",
      "max step (100 episodes) 88.000000\n",
      "------------------------------------------------\n",
      "episodes 26\n",
      "timestep 2000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -328.748344\n",
      "max reward (100 episodes) -44.757731\n",
      "mean step (100 episodes) 534.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 32\n",
      "timestep 3000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -313.422510\n",
      "max reward (100 episodes) -44.757731\n",
      "mean step (100 episodes) 513.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 35\n",
      "timestep 4000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -328.856543\n",
      "max reward (100 episodes) -44.757731\n",
      "mean step (100 episodes) 497.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 37\n",
      "timestep 5000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -286.212096\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 531.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 39\n",
      "timestep 6000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -261.827855\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 577.433333\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 41\n",
      "timestep 7000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -239.061193\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 620.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 43\n",
      "timestep 8000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -235.187888\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 668.025000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 45\n",
      "timestep 9000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -226.493603\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 704.911111\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_10000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 47\n",
      "timestep 10000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -219.062011\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 734.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 49\n",
      "timestep 11000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -210.081718\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 758.563636\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 51\n",
      "timestep 12000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -205.700274\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 776.483333\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 53\n",
      "timestep 13000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -200.813245\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 793.676923\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 55\n",
      "timestep 14000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -196.836492\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 808.414286\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 57\n",
      "timestep 15000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -192.780612\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 821.186667\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 59\n",
      "timestep 16000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -189.233753\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 829.687500\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 61\n",
      "timestep 17000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -185.415083\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 812.211765\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 63\n",
      "timestep 18000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -183.242065\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 810.144444\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 65\n",
      "timestep 19000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -180.571720\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 811.042105\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_20000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 67\n",
      "timestep 20000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -177.014451\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 795.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 70\n",
      "timestep 21000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -154.591817\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 825.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 72\n",
      "timestep 22000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -158.492825\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 825.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 74\n",
      "timestep 23000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -150.346317\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 835.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 76\n",
      "timestep 24000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -137.037310\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 842.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 78\n",
      "timestep 25000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -139.355853\n",
      "max reward (100 episodes) 6.684170\n",
      "mean step (100 episodes) 842.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 80\n",
      "timestep 26000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -137.546406\n",
      "max reward (100 episodes) 6.684170\n",
      "mean step (100 episodes) 844.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 82\n",
      "timestep 27000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -137.634092\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 833.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 84\n",
      "timestep 28000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -135.631748\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 810.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 86\n",
      "timestep 29000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -135.792263\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 800.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_30000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 90\n",
      "timestep 30000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -133.925416\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 786.750000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 94\n",
      "timestep 31000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -132.354838\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 769.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 96\n",
      "timestep 32000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -131.906091\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 754.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 98\n",
      "timestep 33000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -129.996149\n",
      "max reward (100 episodes) 2.896017\n",
      "mean step (100 episodes) 737.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 100\n",
      "timestep 34000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -125.288462\n",
      "max reward (100 episodes) 18.943683\n",
      "mean step (100 episodes) 721.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 102\n",
      "timestep 35000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) -122.796973\n",
      "max reward (100 episodes) 18.943683\n",
      "mean step (100 episodes) 696.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 104\n",
      "timestep 36000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) -120.369955\n",
      "max reward (100 episodes) 18.943683\n",
      "mean step (100 episodes) 677.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 106\n",
      "timestep 37000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) -116.998844\n",
      "max reward (100 episodes) 51.979232\n",
      "mean step (100 episodes) 677.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 108\n",
      "timestep 38000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) -115.483656\n",
      "max reward (100 episodes) 51.979232\n",
      "mean step (100 episodes) 672.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 110\n",
      "timestep 39000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) -111.362030\n",
      "max reward (100 episodes) 112.397920\n",
      "mean step (100 episodes) 657.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_40000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 112\n",
      "timestep 40000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) -106.433824\n",
      "max reward (100 episodes) 121.149601\n",
      "mean step (100 episodes) 680.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 115\n",
      "timestep 41000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) -98.638682\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 679.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 117\n",
      "timestep 42000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) -91.887868\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 674.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 119\n",
      "timestep 43000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) -88.189020\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 690.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 121\n",
      "timestep 44000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) -83.318725\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 711.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 123\n",
      "timestep 45000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -77.495717\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 726.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 125\n",
      "timestep 46000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -72.492011\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 733.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 127\n",
      "timestep 47000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -66.936663\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 745.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 129\n",
      "timestep 48000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000477\n",
      "mean reward (100 episodes) -57.865505\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 761.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 131\n",
      "timestep 49000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000477\n",
      "mean reward (100 episodes) -46.719496\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 765.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_50000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 133\n",
      "timestep 50000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000476\n",
      "mean reward (100 episodes) -39.049606\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 778.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 135\n",
      "timestep 51000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000476\n",
      "mean reward (100 episodes) -36.681471\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 777.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 137\n",
      "timestep 52000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000475\n",
      "mean reward (100 episodes) -22.402497\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 787.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 139\n",
      "timestep 53000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000475\n",
      "mean reward (100 episodes) -17.359236\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 802.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 141\n",
      "timestep 54000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000474\n",
      "mean reward (100 episodes) -13.071738\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 814.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 143\n",
      "timestep 55000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000474\n",
      "mean reward (100 episodes) -5.209027\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 833.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 145\n",
      "timestep 56000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) -2.530268\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 852.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 147\n",
      "timestep 57000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 4.207638\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 875.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 149\n",
      "timestep 58000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 12.477651\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 890.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 151\n",
      "timestep 59000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000472\n",
      "mean reward (100 episodes) 15.328460\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 913.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_60000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 153\n",
      "timestep 60000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000472\n",
      "mean reward (100 episodes) 15.410119\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 904.200000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 155\n",
      "timestep 61000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000471\n",
      "mean reward (100 episodes) 14.632190\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 912.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 157\n",
      "timestep 62000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000471\n",
      "mean reward (100 episodes) 20.729057\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 900.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 159\n",
      "timestep 63000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000470\n",
      "mean reward (100 episodes) 26.803850\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 885.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 161\n",
      "timestep 64000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000470\n",
      "mean reward (100 episodes) 32.527403\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 869.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 163\n",
      "timestep 65000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 40.769032\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 852.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 165\n",
      "timestep 66000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 42.315782\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 853.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 167\n",
      "timestep 67000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 43.709057\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 841.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 169\n",
      "timestep 68000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000468\n",
      "mean reward (100 episodes) 43.261158\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 840.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 171\n",
      "timestep 69000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000468\n",
      "mean reward (100 episodes) 42.223109\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 828.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_70000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 174\n",
      "timestep 70000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000467\n",
      "mean reward (100 episodes) 41.069205\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 810.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 177\n",
      "timestep 71000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000467\n",
      "mean reward (100 episodes) 46.047784\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 814.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 180\n",
      "timestep 72000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 42.800813\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 806.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 182\n",
      "timestep 73000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 45.128558\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 787.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 184\n",
      "timestep 74000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 50.015438\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 789.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 186\n",
      "timestep 75000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000465\n",
      "mean reward (100 episodes) 50.656252\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 787.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 188\n",
      "timestep 76000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000465\n",
      "mean reward (100 episodes) 56.195127\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 789.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 190\n",
      "timestep 77000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000464\n",
      "mean reward (100 episodes) 54.673935\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 783.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 192\n",
      "timestep 78000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000464\n",
      "mean reward (100 episodes) 54.800793\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 778.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 194\n",
      "timestep 79000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 61.113351\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 775.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_80000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 196\n",
      "timestep 80000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 64.836352\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 775.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 198\n",
      "timestep 81000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 73.486802\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 762.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 200\n",
      "timestep 82000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000462\n",
      "mean reward (100 episodes) 68.036536\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 772.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 202\n",
      "timestep 83000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000462\n",
      "mean reward (100 episodes) 67.823139\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 776.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 204\n",
      "timestep 84000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000461\n",
      "mean reward (100 episodes) 69.165532\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 770.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 206\n",
      "timestep 85000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000461\n",
      "mean reward (100 episodes) 69.242826\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 780.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 208\n",
      "timestep 86000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 71.898921\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 774.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 210\n",
      "timestep 87000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 73.191344\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 776.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 213\n",
      "timestep 88000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 81.922368\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 762.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 215\n",
      "timestep 89000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000459\n",
      "mean reward (100 episodes) 91.429161\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 754.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_90000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 217\n",
      "timestep 90000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000459\n",
      "mean reward (100 episodes) 97.502919\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 760.050000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 219\n",
      "timestep 91000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000458\n",
      "mean reward (100 episodes) 97.957679\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 757.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 221\n",
      "timestep 92000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000458\n",
      "mean reward (100 episodes) 105.714990\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 745.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 223\n",
      "timestep 93000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 114.552431\n",
      "max reward (100 episodes) 279.586751\n",
      "mean step (100 episodes) 749.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 225\n",
      "timestep 94000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 110.365960\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 733.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 227\n",
      "timestep 95000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 111.769504\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 732.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 229\n",
      "timestep 96000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000456\n",
      "mean reward (100 episodes) 112.977610\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 709.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 231\n",
      "timestep 97000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000456\n",
      "mean reward (100 episodes) 115.322560\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 701.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 233\n",
      "timestep 98000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 116.253996\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 687.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 235\n",
      "timestep 99000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 117.031373\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 672.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_100000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 238\n",
      "timestep 100000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 120.059268\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 657.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 240\n",
      "timestep 101000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000454\n",
      "mean reward (100 episodes) 119.992704\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 649.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 243\n",
      "timestep 102000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000454\n",
      "mean reward (100 episodes) 122.710811\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 628.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 245\n",
      "timestep 103000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000453\n",
      "mean reward (100 episodes) 128.919685\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 620.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 248\n",
      "timestep 104000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000453\n",
      "mean reward (100 episodes) 130.978355\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 624.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 250\n",
      "timestep 105000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 135.182903\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 602.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 252\n",
      "timestep 106000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 139.186265\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 580.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 254\n",
      "timestep 107000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 143.194287\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 558.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 256\n",
      "timestep 108000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000451\n",
      "mean reward (100 episodes) 145.349221\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 559.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 258\n",
      "timestep 109000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000451\n",
      "mean reward (100 episodes) 140.282708\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 555.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_110000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 260\n",
      "timestep 110000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 140.971739\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 536.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 263\n",
      "timestep 111000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 146.512880\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 530.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 266\n",
      "timestep 112000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 148.065916\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 527.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 268\n",
      "timestep 113000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000449\n",
      "mean reward (100 episodes) 139.255914\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 514.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 272\n",
      "timestep 114000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000449\n",
      "mean reward (100 episodes) 147.297761\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 502.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 275\n",
      "timestep 115000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 145.695873\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 486.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 277\n",
      "timestep 116000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 141.538321\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 483.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 279\n",
      "timestep 117000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 146.243606\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 481.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 281\n",
      "timestep 118000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000447\n",
      "mean reward (100 episodes) 151.468795\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 478.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 284\n",
      "timestep 119000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000447\n",
      "mean reward (100 episodes) 154.372689\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 465.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_120000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 287\n",
      "timestep 120000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 157.138784\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 458.590000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 289\n",
      "timestep 121000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 159.992361\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 457.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 291\n",
      "timestep 122000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 161.833820\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 457.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 293\n",
      "timestep 123000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000445\n",
      "mean reward (100 episodes) 163.950892\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 445.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 295\n",
      "timestep 124000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000445\n",
      "mean reward (100 episodes) 166.252770\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 434.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 298\n",
      "timestep 125000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 160.937837\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 439.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 301\n",
      "timestep 126000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 160.075072\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 434.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 304\n",
      "timestep 127000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 162.013913\n",
      "max reward (100 episodes) 291.077152\n",
      "mean step (100 episodes) 442.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 308\n",
      "timestep 128000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000443\n",
      "mean reward (100 episodes) 160.376530\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 434.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 310\n",
      "timestep 129000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000443\n",
      "mean reward (100 episodes) 157.533149\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 442.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_130000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 313\n",
      "timestep 130000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 156.789574\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 454.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 315\n",
      "timestep 131000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 156.847921\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 469.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 319\n",
      "timestep 132000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 155.201762\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 465.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 322\n",
      "timestep 133000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 160.759826\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 467.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 325\n",
      "timestep 134000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 160.602027\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 479.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 327\n",
      "timestep 135000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 166.346860\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 488.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 330\n",
      "timestep 136000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000440\n",
      "mean reward (100 episodes) 172.289571\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 488.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 333\n",
      "timestep 137000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000440\n",
      "mean reward (100 episodes) 167.427797\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 499.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 335\n",
      "timestep 138000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 171.310441\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 487.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 338\n",
      "timestep 139000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 172.146388\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 495.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_140000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 340\n",
      "timestep 140000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 172.605435\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 510.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 342\n",
      "timestep 141000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000438\n",
      "mean reward (100 episodes) 168.214818\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 511.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 345\n",
      "timestep 142000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000438\n",
      "mean reward (100 episodes) 165.220698\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 511.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 348\n",
      "timestep 143000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 161.006368\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 519.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 351\n",
      "timestep 144000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 161.659333\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 517.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 353\n",
      "timestep 145000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 166.149178\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 509.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 356\n",
      "timestep 146000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 171.307157\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 510.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 358\n",
      "timestep 147000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 170.398421\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 510.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 360\n",
      "timestep 148000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 170.081162\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 510.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 362\n",
      "timestep 149000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000435\n",
      "mean reward (100 episodes) 172.216910\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 508.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_150000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 364\n",
      "timestep 150000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000435\n",
      "mean reward (100 episodes) 168.610325\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 514.980000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 367\n",
      "timestep 151000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 172.198318\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 492.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 369\n",
      "timestep 152000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 173.448447\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 490.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 372\n",
      "timestep 153000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 172.342166\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 486.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 374\n",
      "timestep 154000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 168.244334\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 474.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 378\n",
      "timestep 155000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 170.058836\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 463.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 380\n",
      "timestep 156000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 171.600331\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 459.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 382\n",
      "timestep 157000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000432\n",
      "mean reward (100 episodes) 177.031656\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 432.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 385\n",
      "timestep 158000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000432\n",
      "mean reward (100 episodes) 174.531530\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 433.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 387\n",
      "timestep 159000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 170.587264\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 429.000000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_160000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 389\n",
      "timestep 160000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 170.501597\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 433.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 393\n",
      "timestep 161000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 169.528132\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 446.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 396\n",
      "timestep 162000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 176.647528\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 440.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 398\n",
      "timestep 163000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 176.804393\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 430.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 400\n",
      "timestep 164000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 176.346022\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 424.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 404\n",
      "timestep 165000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000429\n",
      "mean reward (100 episodes) 174.764310\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 424.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 407\n",
      "timestep 166000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000429\n",
      "mean reward (100 episodes) 170.450521\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 431.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 409\n",
      "timestep 167000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 170.258779\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 450.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 411\n",
      "timestep 168000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 169.047301\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 457.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 414\n",
      "timestep 169000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 172.213553\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 453.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_170000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 416\n",
      "timestep 170000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 178.769996\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 441.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 419\n",
      "timestep 171000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 172.449130\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 457.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 421\n",
      "timestep 172000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 170.715964\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 464.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 423\n",
      "timestep 173000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 175.005381\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 472.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 425\n",
      "timestep 174000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 169.568128\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 477.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 427\n",
      "timestep 175000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 165.863340\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 477.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 429\n",
      "timestep 176000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000425\n",
      "mean reward (100 episodes) 166.933241\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 480.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 431\n",
      "timestep 177000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000425\n",
      "mean reward (100 episodes) 165.470127\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 493.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 433\n",
      "timestep 178000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 163.091514\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 505.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 435\n",
      "timestep 179000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 159.877801\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 525.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_180000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 437\n",
      "timestep 180000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 159.707553\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 521.300000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 439\n",
      "timestep 181000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 162.197021\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 525.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 441\n",
      "timestep 182000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 159.831970\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 546.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 443\n",
      "timestep 183000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 155.257068\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 561.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 445\n",
      "timestep 184000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 154.604197\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 578.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 447\n",
      "timestep 185000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 145.664876\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 604.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 449\n",
      "timestep 186000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 144.649994\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 615.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 451\n",
      "timestep 187000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 142.659787\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 607.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 453\n",
      "timestep 188000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 145.828043\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 609.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 455\n",
      "timestep 189000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 147.991664\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 605.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_190000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 457\n",
      "timestep 190000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 150.196855\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 610.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 459\n",
      "timestep 191000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 149.523237\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 612.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 461\n",
      "timestep 192000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 149.664631\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 615.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 465\n",
      "timestep 193000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 151.511910\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 604.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 467\n",
      "timestep 194000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 160.128660\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 607.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 469\n",
      "timestep 195000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 164.463925\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 603.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 471\n",
      "timestep 196000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 162.545953\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 617.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 474\n",
      "timestep 197000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 166.036027\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 603.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 476\n",
      "timestep 198000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 170.044526\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 596.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 478\n",
      "timestep 199000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 175.954810\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 582.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_200000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 480\n",
      "timestep 200000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 178.799871\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 564.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 482\n",
      "timestep 201000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 182.880233\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 545.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 484\n",
      "timestep 202000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 187.468067\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 538.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 486\n",
      "timestep 203000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 195.502016\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 528.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 488\n",
      "timestep 204000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 193.666689\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 533.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 490\n",
      "timestep 205000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 205.323855\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 514.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 492\n",
      "timestep 206000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 209.575224\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 498.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 494\n",
      "timestep 207000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 211.309590\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 510.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 498\n",
      "timestep 208000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 211.885659\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 506.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 500\n",
      "timestep 209000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 213.172162\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 502.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_210000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 502\n",
      "timestep 210000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 212.123765\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 496.720000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 505\n",
      "timestep 211000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 218.604245\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 474.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 507\n",
      "timestep 212000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 219.166343\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 468.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 509\n",
      "timestep 213000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 216.907492\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 474.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 511\n",
      "timestep 214000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 217.365747\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 483.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 513\n",
      "timestep 215000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 218.218444\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 485.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 515\n",
      "timestep 216000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 220.172951\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 475.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 518\n",
      "timestep 217000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 216.513956\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 495.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 520\n",
      "timestep 218000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 214.290979\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 505.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 523\n",
      "timestep 219000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 213.679094\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 503.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_220000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 525\n",
      "timestep 220000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 212.924635\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 516.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 527\n",
      "timestep 221000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 212.655638\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 519.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 529\n",
      "timestep 222000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 213.757777\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 510.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 531\n",
      "timestep 223000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 212.253079\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 513.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 534\n",
      "timestep 224000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 214.510619\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 501.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 537\n",
      "timestep 225000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 216.117315\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 498.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 539\n",
      "timestep 226000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 215.593353\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 504.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 542\n",
      "timestep 227000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 219.524374\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 480.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 545\n",
      "timestep 228000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 219.525660\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 481.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 547\n",
      "timestep 229000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 216.748545\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 495.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_230000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 549\n",
      "timestep 230000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 217.574367\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 489.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 551\n",
      "timestep 231000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 213.568056\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 522.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 554\n",
      "timestep 232000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 212.108584\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 542.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 556\n",
      "timestep 233000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 214.167235\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 537.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 560\n",
      "timestep 234000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 213.703160\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 539.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 562\n",
      "timestep 235000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 209.998461\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 555.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 564\n",
      "timestep 236000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 211.901616\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 550.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 566\n",
      "timestep 237000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 215.614060\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 534.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 568\n",
      "timestep 238000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 219.748122\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 519.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 571\n",
      "timestep 239000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 222.925079\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 507.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_240000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 574\n",
      "timestep 240000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 223.652048\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 499.490000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 576\n",
      "timestep 241000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 218.800040\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 530.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 578\n",
      "timestep 242000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 216.280471\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 547.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 581\n",
      "timestep 243000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 217.817502\n",
      "max reward (100 episodes) 311.234522\n",
      "mean step (100 episodes) 551.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 585\n",
      "timestep 244000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 219.375073\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 547.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 587\n",
      "timestep 245000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 221.223799\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 540.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 590\n",
      "timestep 246000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 224.516463\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 526.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 593\n",
      "timestep 247000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 226.614746\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 515.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/trajs_0.pkl!\n",
      "------------------------------------------------\n",
      "episodes 597\n",
      "timestep 248000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 225.957237\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 520.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 599\n",
      "timestep 249000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 227.472694\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 521.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_250000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 601\n",
      "timestep 250000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 228.397259\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 531.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 603\n",
      "timestep 251000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 230.266822\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 503.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 606\n",
      "timestep 252000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 232.710201\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 484.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 608\n",
      "timestep 253000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 229.697394\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 491.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 610\n",
      "timestep 254000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 227.498140\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 472.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 614\n",
      "timestep 255000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 230.986639\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 447.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 617\n",
      "timestep 256000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 231.182168\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 448.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 620\n",
      "timestep 257000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 230.643270\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 441.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 625\n",
      "timestep 258000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 225.800982\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 437.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 628\n",
      "timestep 259000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 220.230367\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 430.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_260000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 634\n",
      "timestep 260000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 216.756434\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 425.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 639\n",
      "timestep 261000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 212.818185\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 391.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 644\n",
      "timestep 262000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 217.025477\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 366.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 647\n",
      "timestep 263000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 213.689115\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 358.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 649\n",
      "timestep 264000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 214.364832\n",
      "max reward (100 episodes) 307.764627\n",
      "mean step (100 episodes) 354.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 652\n",
      "timestep 265000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 209.782940\n",
      "max reward (100 episodes) 306.228669\n",
      "mean step (100 episodes) 351.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 656\n",
      "timestep 266000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 203.166157\n",
      "max reward (100 episodes) 306.228669\n",
      "mean step (100 episodes) 356.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 658\n",
      "timestep 267000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 200.945237\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 365.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 663\n",
      "timestep 268000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 198.699968\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 356.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 665\n",
      "timestep 269000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 200.538393\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 344.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_270000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 669\n",
      "timestep 270000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 196.107384\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 366.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 673\n",
      "timestep 271000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 198.152536\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 372.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 675\n",
      "timestep 272000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 200.116273\n",
      "max reward (100 episodes) 305.297701\n",
      "mean step (100 episodes) 366.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 677\n",
      "timestep 273000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 202.925249\n",
      "max reward (100 episodes) 308.101673\n",
      "mean step (100 episodes) 363.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 679\n",
      "timestep 274000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 204.776428\n",
      "max reward (100 episodes) 308.101673\n",
      "mean step (100 episodes) 359.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 681\n",
      "timestep 275000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 202.589818\n",
      "max reward (100 episodes) 308.101673\n",
      "mean step (100 episodes) 376.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 684\n",
      "timestep 276000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 202.942153\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 368.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 687\n",
      "timestep 277000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 205.130607\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 373.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 689\n",
      "timestep 278000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 209.657749\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 380.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 691\n",
      "timestep 279000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 214.975130\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 392.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_280000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 693\n",
      "timestep 280000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 215.863899\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 410.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 697\n",
      "timestep 281000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 225.611731\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 406.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 699\n",
      "timestep 282000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 225.613634\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 405.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 701\n",
      "timestep 283000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 230.818792\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 396.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 703\n",
      "timestep 284000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 231.165695\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 392.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 706\n",
      "timestep 285000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 236.052289\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 391.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 708\n",
      "timestep 286000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 240.203988\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 402.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 711\n",
      "timestep 287000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 240.568688\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 412.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 713\n",
      "timestep 288000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 244.934383\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 406.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 715\n",
      "timestep 289000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 245.476419\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 398.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_290000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 717\n",
      "timestep 290000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 246.505737\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 366.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 719\n",
      "timestep 291000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 244.761472\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 372.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 721\n",
      "timestep 292000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 241.661718\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 381.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 723\n",
      "timestep 293000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 242.373398\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 371.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 725\n",
      "timestep 294000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 243.554926\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 384.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 728\n",
      "timestep 295000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 244.726250\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 374.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 730\n",
      "timestep 296000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 240.868815\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 409.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 732\n",
      "timestep 297000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 230.742663\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 412.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 735\n",
      "timestep 298000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 225.490136\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 415.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 737\n",
      "timestep 299000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 222.660162\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 439.980000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_300000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 740\n",
      "timestep 300000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 224.956154\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 444.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 744\n",
      "timestep 301000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 224.802196\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 446.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 748\n",
      "timestep 302000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 224.307446\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 455.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 751\n",
      "timestep 303000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 224.438574\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 461.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 753\n",
      "timestep 304000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 220.355636\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 460.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 756\n",
      "timestep 305000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 218.879721\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 465.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 759\n",
      "timestep 306000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 221.499187\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 471.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 762\n",
      "timestep 307000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 223.052540\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 452.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 764\n",
      "timestep 308000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 223.768967\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 453.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 768\n",
      "timestep 309000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 217.159627\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 492.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_310000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 772\n",
      "timestep 310000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 220.953039\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 485.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 775\n",
      "timestep 311000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 223.342660\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 475.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 777\n",
      "timestep 312000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 224.661321\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 473.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 780\n",
      "timestep 313000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 221.698988\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 498.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 784\n",
      "timestep 314000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 224.681563\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 482.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 787\n",
      "timestep 315000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 227.341491\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 474.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 791\n",
      "timestep 316000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 230.603039\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 452.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 793\n",
      "timestep 317000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 237.133629\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 463.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 795\n",
      "timestep 318000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 241.424177\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 475.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 798\n",
      "timestep 319000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 246.196965\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 443.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_320000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 801\n",
      "timestep 320000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 241.090460\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 455.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 805\n",
      "timestep 321000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 240.304434\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 464.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 809\n",
      "timestep 322000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 239.671083\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 459.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 811\n",
      "timestep 323000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 238.063246\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 469.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 813\n",
      "timestep 324000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 241.931979\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 473.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 816\n",
      "timestep 325000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 243.755947\n",
      "max reward (100 episodes) 304.869117\n",
      "mean step (100 episodes) 468.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 819\n",
      "timestep 326000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 243.162765\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 452.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 821\n",
      "timestep 327000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 242.447661\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 467.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 826\n",
      "timestep 328000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 242.883779\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 464.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 831\n",
      "timestep 329000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 249.389415\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 422.870000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_330000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 834\n",
      "timestep 330000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 248.014801\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 432.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 837\n",
      "timestep 331000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 248.901147\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 419.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 842\n",
      "timestep 332000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 250.273531\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 409.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 845\n",
      "timestep 333000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 248.009825\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 422.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 849\n",
      "timestep 334000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 248.831136\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 422.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 853\n",
      "timestep 335000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 246.024480\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 431.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 856\n",
      "timestep 336000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 248.328884\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 415.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 860\n",
      "timestep 337000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 251.989542\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 390.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 865\n",
      "timestep 338000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 251.573229\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 376.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 869\n",
      "timestep 339000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 250.383340\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 382.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_340000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 873\n",
      "timestep 340000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 257.563762\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 341.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 876\n",
      "timestep 341000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 258.275844\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 329.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 880\n",
      "timestep 342000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 260.235077\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 324.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 883\n",
      "timestep 343000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 259.401234\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 314.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 886\n",
      "timestep 344000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 257.974832\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 329.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 889\n",
      "timestep 345000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 254.680212\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 336.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 891\n",
      "timestep 346000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 252.201247\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 354.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 895\n",
      "timestep 347000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 253.352236\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 338.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 899\n",
      "timestep 348000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 253.228499\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 338.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 903\n",
      "timestep 349000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 252.859249\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 348.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_350000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 907\n",
      "timestep 350000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 252.982623\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 346.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 911\n",
      "timestep 351000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 252.266990\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 352.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 914\n",
      "timestep 352000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 252.476196\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 353.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 918\n",
      "timestep 353000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 257.883550\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 312.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 922\n",
      "timestep 354000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 247.174777\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 334.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 926\n",
      "timestep 355000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 248.740396\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 325.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 929\n",
      "timestep 356000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 247.302827\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 333.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 932\n",
      "timestep 357000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 240.620018\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 350.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 935\n",
      "timestep 358000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 242.516751\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 350.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 939\n",
      "timestep 359000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 243.378623\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 342.330000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_360000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 943\n",
      "timestep 360000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 243.440536\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 344.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 945\n",
      "timestep 361000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 240.587580\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 344.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 949\n",
      "timestep 362000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 237.977625\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 350.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 951\n",
      "timestep 363000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 235.855371\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 342.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 954\n",
      "timestep 364000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 237.747154\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 327.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 956\n",
      "timestep 365000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 235.582697\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 329.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 959\n",
      "timestep 366000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 238.269727\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 305.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 963\n",
      "timestep 367000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 237.857988\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 305.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 968\n",
      "timestep 368000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 235.984041\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 314.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 972\n",
      "timestep 369000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 236.027358\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 313.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_370000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 975\n",
      "timestep 370000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 237.397144\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 306.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 979\n",
      "timestep 371000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 236.209079\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 316.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 983\n",
      "timestep 372000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 232.897871\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 315.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 987\n",
      "timestep 373000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 232.160108\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 327.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 989\n",
      "timestep 374000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 242.911047\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 305.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 992\n",
      "timestep 375000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 243.403229\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 305.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 996\n",
      "timestep 376000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 244.131437\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 296.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1000\n",
      "timestep 377000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 250.413740\n",
      "max reward (100 episodes) 313.394286\n",
      "mean step (100 episodes) 282.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1002\n",
      "timestep 378000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 246.947381\n",
      "max reward (100 episodes) 313.394286\n",
      "mean step (100 episodes) 308.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1006\n",
      "timestep 379000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 246.504590\n",
      "max reward (100 episodes) 313.394286\n",
      "mean step (100 episodes) 309.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_380000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1009\n",
      "timestep 380000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 243.204891\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 331.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1011\n",
      "timestep 381000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 246.268165\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 329.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1014\n",
      "timestep 382000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 247.277859\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 322.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1018\n",
      "timestep 383000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 251.613098\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 333.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1023\n",
      "timestep 384000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 251.155995\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 337.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1025\n",
      "timestep 385000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 255.871786\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 329.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1029\n",
      "timestep 386000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 251.060885\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 327.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1032\n",
      "timestep 387000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 244.891140\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 336.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1035\n",
      "timestep 388000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 245.695463\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 334.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1040\n",
      "timestep 389000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 247.115632\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 327.400000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_390000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1043\n",
      "timestep 390000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 245.406131\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 343.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1047\n",
      "timestep 391000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 245.042337\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 338.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1049\n",
      "timestep 392000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 245.428983\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 346.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1052\n",
      "timestep 393000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 247.073194\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 339.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1055\n",
      "timestep 394000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 237.346070\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 337.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1057\n",
      "timestep 395000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 236.754865\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 347.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1059\n",
      "timestep 396000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 237.297751\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 347.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1063\n",
      "timestep 397000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 237.190378\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 346.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1065\n",
      "timestep 398000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 236.601188\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 324.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1068\n",
      "timestep 399000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 235.818560\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 333.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_400000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1072\n",
      "timestep 400000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 236.617862\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 329.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1074\n",
      "timestep 401000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 235.614075\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 341.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1078\n",
      "timestep 402000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 233.445613\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 360.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1080\n",
      "timestep 403000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 233.822910\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 351.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1084\n",
      "timestep 404000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 233.679652\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 348.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1088\n",
      "timestep 405000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 227.172309\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 363.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1090\n",
      "timestep 406000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 231.248996\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 373.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1093\n",
      "timestep 407000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 235.910322\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 378.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1096\n",
      "timestep 408000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 236.976214\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 374.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1099\n",
      "timestep 409000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 234.837141\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 380.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_410000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1102\n",
      "timestep 410000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 237.234527\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 363.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1106\n",
      "timestep 411000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 237.184358\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 368.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1108\n",
      "timestep 412000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 238.297782\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 369.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1111\n",
      "timestep 413000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 233.553812\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 390.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/trajs_1.pkl!\n",
      "------------------------------------------------\n",
      "episodes 1114\n",
      "timestep 414000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 241.309231\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 417.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1116\n",
      "timestep 415000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 239.762829\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 407.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1119\n",
      "timestep 416000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 237.226615\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 422.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1122\n",
      "timestep 417000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 236.389870\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 428.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1125\n",
      "timestep 418000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 239.129945\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 426.600000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1128\n",
      "timestep 419000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 241.191690\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 417.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_420000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1131\n",
      "timestep 420000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 243.300383\n",
      "max reward (100 episodes) 306.870274\n",
      "mean step (100 episodes) 400.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1135\n",
      "timestep 421000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 244.635252\n",
      "max reward (100 episodes) 306.870274\n",
      "mean step (100 episodes) 390.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1140\n",
      "timestep 422000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 248.042128\n",
      "max reward (100 episodes) 308.819457\n",
      "mean step (100 episodes) 371.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1142\n",
      "timestep 423000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 248.897241\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 371.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1147\n",
      "timestep 424000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 247.796791\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 373.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1153\n",
      "timestep 425000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 251.346428\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 374.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1156\n",
      "timestep 426000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 250.181820\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 374.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1159\n",
      "timestep 427000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.868455\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 365.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1164\n",
      "timestep 428000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.185886\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 371.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1169\n",
      "timestep 429000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.110094\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 371.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_430000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1172\n",
      "timestep 430000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.093715\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 374.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1176\n",
      "timestep 431000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 252.834701\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 357.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1179\n",
      "timestep 432000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 254.191744\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 351.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1182\n",
      "timestep 433000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 258.524221\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 326.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1187\n",
      "timestep 434000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 260.383443\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 299.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1193\n",
      "timestep 435000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 260.069143\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 324.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1196\n",
      "timestep 436000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 263.485643\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 309.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1200\n",
      "timestep 437000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 265.163993\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 301.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1204\n",
      "timestep 438000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 264.985155\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 303.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1207\n",
      "timestep 439000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.716262\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 307.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_440000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1211\n",
      "timestep 440000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.686819\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 306.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1215\n",
      "timestep 441000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.829368\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 306.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1218\n",
      "timestep 442000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.855243\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 310.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1221\n",
      "timestep 443000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 260.012168\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 317.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1225\n",
      "timestep 444000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 248.589836\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 322.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1231\n",
      "timestep 445000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 247.088174\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 314.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1235\n",
      "timestep 446000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 248.107802\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 312.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1241\n",
      "timestep 447000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 248.555211\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 313.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1246\n",
      "timestep 448000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 246.921751\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 321.240000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1253\n",
      "timestep 449000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 244.941200\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 320.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_450000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1259\n",
      "timestep 450000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 241.951374\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 317.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1264\n",
      "timestep 451000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 240.884958\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 325.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1268\n",
      "timestep 452000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 240.920384\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 322.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1273\n",
      "timestep 453000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 238.378004\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 321.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1277\n",
      "timestep 454000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 235.269649\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 328.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1282\n",
      "timestep 455000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 238.015540\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 302.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1287\n",
      "timestep 456000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 235.524196\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 309.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1291\n",
      "timestep 457000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 235.664354\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 308.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1295\n",
      "timestep 458000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 236.635268\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 304.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1300\n",
      "timestep 459000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 236.561866\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 315.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_460000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1305\n",
      "timestep 460000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 236.737814\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 313.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1308\n",
      "timestep 461000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 236.703154\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 311.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1312\n",
      "timestep 462000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 236.129589\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 306.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1317\n",
      "timestep 463000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 231.838524\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 323.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1322\n",
      "timestep 464000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 245.545517\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 309.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1327\n",
      "timestep 465000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 250.225242\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 300.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1331\n",
      "timestep 466000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 251.842330\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 292.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1335\n",
      "timestep 467000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 253.502798\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 283.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1339\n",
      "timestep 468000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 254.626120\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 275.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1345\n",
      "timestep 469000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 257.032273\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 276.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_470000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1349\n",
      "timestep 470000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 256.937239\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 277.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1352\n",
      "timestep 471000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 258.139857\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 268.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1356\n",
      "timestep 472000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 258.163838\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 268.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1358\n",
      "timestep 473000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 258.583596\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 290.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1362\n",
      "timestep 474000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 261.071700\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 281.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1368\n",
      "timestep 475000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 259.206226\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 292.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1371\n",
      "timestep 476000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 259.752408\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 297.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1374\n",
      "timestep 477000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 259.005222\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 297.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1379\n",
      "timestep 478000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 258.726469\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 289.580000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1381\n",
      "timestep 479000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 263.200648\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 272.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_480000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1384\n",
      "timestep 480000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 263.575104\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 274.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1388\n",
      "timestep 481000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 264.343794\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 275.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1392\n",
      "timestep 482000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 261.680640\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 291.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1397\n",
      "timestep 483000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 264.300131\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 275.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1401\n",
      "timestep 484000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 261.653808\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 285.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1405\n",
      "timestep 485000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 261.437440\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 285.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1411\n",
      "timestep 486000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 260.044046\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 295.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1416\n",
      "timestep 487000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 258.732097\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 296.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1421\n",
      "timestep 488000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 260.214053\n",
      "max reward (100 episodes) 315.280556\n",
      "mean step (100 episodes) 287.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1424\n",
      "timestep 489000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 259.492324\n",
      "max reward (100 episodes) 315.280556\n",
      "mean step (100 episodes) 278.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_490000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1429\n",
      "timestep 490000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 261.670867\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 286.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1434\n",
      "timestep 491000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 260.973022\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 295.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1438\n",
      "timestep 492000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 258.480550\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 307.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1443\n",
      "timestep 493000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 261.055405\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 288.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1447\n",
      "timestep 494000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 259.766585\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 301.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1451\n",
      "timestep 495000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 261.627799\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 294.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1455\n",
      "timestep 496000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 262.203339\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 290.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1460\n",
      "timestep 497000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 261.859676\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 292.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1464\n",
      "timestep 498000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 262.253399\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 293.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1467\n",
      "timestep 499000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 262.951518\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 294.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_500000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1472\n",
      "timestep 500000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000333\n",
      "mean reward (100 episodes) 263.024751\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 291.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/trajs_2.pkl!\n"
     ]
    }
   ],
   "source": [
    "config['hiddens'] = [256, 256]\n",
    "config['max_training_steps'] = 500000\n",
    "config['lr'] = 5e-4\n",
    "config['decay_steps'] = 1000000\n",
    "config['episode_counts_to_save'] = 500\n",
    "\n",
    "config['persistent_directory'] = './online/'\n",
    "config['checkpoint_path'] = './online/ckpts/'\n",
    "\n",
    "agent = QuantileAgent(name='LunarLander-v2', num_actions=4, config=config)  # 'Qbert-ram-v0', num_actions=6 \n",
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'max step')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = pd.Series(agent.eval_episode_rewards)\n",
    "steps = pd.Series(agent.eval_episode_steps)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 8))\n",
    "\n",
    "axes[0][0].plot(rewards.rolling(100, min_periods=20).mean())\n",
    "axes[0][0].set_title('mean reward')\n",
    "axes[0][1].plot(rewards.rolling(100, min_periods=20).max())\n",
    "axes[0][1].set_title('max reward')\n",
    "axes[1][0].plot(steps.rolling(100, min_periods=20).mean())\n",
    "axes[1][0].set_title('mean step')\n",
    "axes[1][1].plot(steps.rolling(100, min_periods=20).max())\n",
    "axes[1][1].set_title('max step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent_directory = './online/'\n",
    "files = os.listdir(persistent_directory)\n",
    "files = sorted([file for file in files if file.endswith('.pkl')])\n",
    "\n",
    "trajs = []\n",
    "for file in files:\n",
    "    path = persistent_directory + file\n",
    "    with open(path, 'rb') as f:\n",
    "        trajs.append(pickle.load(f))\n",
    "\n",
    "trajs = [traj for file in trajs for traj in file] \n",
    "# random.shuffle(trajs)\n",
    "\n",
    "with open(persistent_directory+'/trajs_qr_dqn.pkl', 'wb') as f:\n",
    "    pickle.dump(trajs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
